{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igOapoekt9YF",
        "outputId": "1217bb6f-5094-4892-aef4-c4a109955e15"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dgl in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "S_zbs5_Jt3L5"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import dgl.function as fn\n",
        "import torch.nn.functional as F\n",
        "import shutil\n",
        "from torch.utils.data import DataLoader\n",
        "import cloudpickle\n",
        "from dgl.nn import GraphConv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jOl7-0ct3L5"
      },
      "source": [
        "#### Set Path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this  segment involves directory and file operations. It creates directories, deletes directories, and extracts the contents of a ZIP file."
      ],
      "metadata": {
        "id": "dkDdNSjbu4Rz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "cqFqDvR0t3L6"
      },
      "outputs": [],
      "source": [
        "# Set the current directory as \"./\"\n",
        "current_dir = \"./\"\n",
        "\n",
        "# Set the checkpoint path by combining the current directory, the subdirectory \"save_models/model_checkpoints/\", and the filename \"checkpoint\"\n",
        "checkpoint_path = current_dir + \"save_models/model_checkpoints/\" + \"checkpoint\"\n",
        "\n",
        "# Create the checkpoint path directory if it doesn't exist\n",
        "os.makedirs(checkpoint_path, exist_ok=True)\n",
        "\n",
        "# Set the best model path by combining the current directory and the subdirectory \"save_models/best_model/\"\n",
        "best_model_path = current_dir + \"save_models/best_model/\"\n",
        "\n",
        "# Set the temporary data folder path by combining the current directory and the subdirectory \"data_temp/\"\n",
        "folder_data_temp = current_dir + \"data_temp/\"\n",
        "\n",
        "# Remove the temporary data folder and its contents if it exists, ignoring any errors that occur\n",
        "shutil.rmtree(folder_data_temp, ignore_errors=True)\n",
        "\n",
        "# Set the path to save as the combined path of the current directory and the filename \"graph_data.zip\"\n",
        "path_save = current_dir + \"graph_data.zip\"\n",
        "\n",
        "# Unpack the contents of the \"graph_data.zip\" file to the temporary data folder \"folder_data_temp\"\n",
        "shutil.unpack_archive(path_save, folder_data_temp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCuniGpqt3L6"
      },
      "source": [
        "#### Custom PyTorch Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the `DGLDatasetClass` class represents a classification dataset that loads DGL graphs and associated labels, masks\n",
        "\n",
        ", and global information from a binary file. It allows for retrieving specific items from the dataset based on index."
      ],
      "metadata": {
        "id": "wRrC6aNWv5Wa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "1z2DCX6Ft3L6"
      },
      "outputs": [],
      "source": [
        "\"\"\" Classification Dataset \"\"\"\n",
        "\n",
        "# Define a custom dataset class named DGLDatasetClass that extends the torch.utils.data.Dataset class.\n",
        "class DGLDatasetClass(torch.utils.data.Dataset):\n",
        "    # Constructor method that takes the address parameter.\n",
        "    def __init__(self, address):\n",
        "        # Append \".bin\" to the address and store it in the self.address attribute.\n",
        "        self.address = address + \".bin\"\n",
        "\n",
        "        # Load the graphs from the specified address using dgl.load_graphs() function.\n",
        "        # The loaded graphs and train_labels_masks_globals dictionary are stored in self.list_graphs and train_labels_masks_globals variables, respectively.\n",
        "        self.list_graphs, train_labels_masks_globals = dgl.load_graphs(self.address)\n",
        "\n",
        "        # Obtain the number of graphs in the dataset by getting the length of the self.list_graphs list.\n",
        "        num_graphs = len(self.list_graphs)\n",
        "\n",
        "        # Extract the \"labels\", \"masks\", and \"globals\" tensors from the train_labels_masks_globals dictionary.\n",
        "        # Reshape the tensors to have the shape (num_graphs, -1) and store them in self.labels, self.masks, and self.globals attributes, respectively.\n",
        "        self.labels = train_labels_masks_globals[\"labels\"].view(num_graphs, -1)\n",
        "        self.masks = train_labels_masks_globals[\"masks\"].view(num_graphs, -1)\n",
        "        self.globals = train_labels_masks_globals[\"globals\"].view(num_graphs, -1)\n",
        "\n",
        "    # Define the __len__() method that returns the number of graphs in the dataset.\n",
        "    def __len__(self):\n",
        "        return len(self.list_graphs)\n",
        "\n",
        "    # Define the __getitem__() method that returns the data at the specified index.\n",
        "    def __getitem__(self, idx):\n",
        "        # Return the graph, labels, masks, and globals corresponding to the given index.\n",
        "        return self.list_graphs[idx], self.labels[idx], self.masks[idx], self.globals[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oHNkibPt3L6"
      },
      "source": [
        "#### Defining Train, Validation, and Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the code creates instances of the `DGLDatasetClass` class for training, validation, and test sets. The `address` parameter is set differently for each set to load the corresponding dataset. Finally, the code prints the lengths of the datasets to indicate the number of graphs in each set."
      ],
      "metadata": {
        "id": "8-96IBOVwvNp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQxBdhe_t3L7",
        "outputId": "f240c96e-734f-460d-86c0-c6cfae832d8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1631 203 205\n"
          ]
        }
      ],
      "source": [
        "path_data_temp = folder_data_temp + \"scaffold\"+\"_\"+str(0)\n",
        "train_set = DGLDatasetClass(address=path_data_temp+\"_train\")\n",
        "val_set = DGLDatasetClass(address=path_data_temp+\"_val\")\n",
        "test_set = DGLDatasetClass(address=path_data_temp+\"_test\")\n",
        "\n",
        "print(len(train_set), len(val_set), len(test_set))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "this code snippet loads the train, validation, and test datasets, concatenates them into a single dataset, and then analyzes the graph properties such as the number of vertices, edges, and graphs. It also computes and prints the shape of the adjacency matrices for each graph."
      ],
      "metadata": {
        "id": "niTKFIOCkLNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the train, validation, and test datasets\n",
        "train_set = DGLDatasetClass(address=path_data_temp + \"_train\")\n",
        "val_set = DGLDatasetClass(address=path_data_temp + \"_val\")\n",
        "test_set = DGLDatasetClass(address=path_data_temp + \"_test\")\n",
        "\n",
        "# Concatenate the datasets\n",
        "dataset = torch.utils.data.ConcatDataset([train_set, val_set, test_set])\n",
        "\n",
        "# Get all the graphs in the dataset\n",
        "graphs = [data[0] for data in dataset]\n",
        "\n",
        "# Get the number of vertices, edges, and graphs\n",
        "num_vertices = [graph.number_of_nodes() for graph in graphs]\n",
        "num_edges = [graph.number_of_edges() for graph in graphs]\n",
        "num_graphs = len(dataset)\n",
        "\n",
        "print(\"Number of vertices:\", num_vertices)\n",
        "print(\"Number of edges:\", num_edges)\n",
        "print(\"Number of graphs:\", num_graphs)\n",
        "\n",
        "# Get the adjacency matrix shape\n",
        "adj_matrix = [graph.adjacency_matrix() for graph in graphs]\n",
        "adj_shape = [matrix.shape for matrix in adj_matrix]\n",
        "\n",
        "print(\"Adjacency matrix shape:\", adj_shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzUNgsBaDwA6",
        "outputId": "2e0f8a8c-342d-4b89-cc99-ee4504cffab4"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of vertices: [8, 2, 9, 4, 1, 10, 11, 4, 4, 5, 7, 3, 2, 5, 8, 4, 6, 5, 7, 2, 4, 4, 6, 8, 4, 2, 4, 6, 5, 8, 8, 5, 10, 6, 4, 5, 5, 3, 7, 1, 3, 2, 1, 4, 6, 4, 5, 1, 1, 5, 1, 1, 8, 6, 3, 6, 9, 10, 8, 3, 7, 4, 6, 8, 6, 8, 5, 2, 5, 7, 6, 5, 4, 4, 2, 4, 5, 6, 3, 3, 4, 9, 9, 8, 10, 4, 6, 3, 4, 5, 9, 10, 4, 11, 6, 2, 12, 4, 4, 5, 2, 2, 4, 5, 8, 2, 7, 3, 5, 9, 13, 12, 5, 3, 10, 7, 10, 3, 9, 6, 4, 8, 9, 8, 4, 4, 5, 6, 5, 4, 4, 4, 3, 2, 10, 7, 7, 48, 5, 6, 8, 10, 4, 11, 7, 7, 9, 5, 11, 9, 8, 9, 10, 11, 4, 6, 11, 7, 8, 7, 5, 10, 10, 2, 9, 5, 15, 10, 5, 6, 6, 14, 11, 7, 8, 3, 8, 10, 11, 9, 7, 11, 8, 7, 8, 12, 9, 6, 9, 8, 7, 7, 5, 14, 6, 2, 8, 4, 2, 6, 11, 8, 17, 8, 12, 12, 14, 14, 12, 3, 5, 3, 7, 10, 10, 10, 7, 9, 8, 8, 8, 9, 7, 6, 10, 7, 14, 10, 8, 11, 2, 3, 4, 2, 6, 2, 3, 2, 3, 3, 4, 2, 4, 3, 3, 3, 5, 3, 5, 10, 5, 19, 21, 9, 4, 7, 3, 12, 8, 8, 9, 8, 11, 3, 5, 7, 6, 5, 5, 6, 5, 7, 16, 13, 9, 9, 4, 5, 4, 6, 6, 6, 6, 6, 17, 16, 15, 11, 10, 7, 6, 7, 11, 19, 5, 11, 5, 5, 8, 9, 5, 5, 8, 5, 14, 2, 10, 6, 6, 7, 5, 10, 6, 6, 5, 7, 6, 4, 11, 4, 4, 8, 6, 9, 9, 19, 4, 10, 5, 7, 7, 15, 7, 9, 5, 4, 4, 5, 7, 11, 7, 7, 9, 5, 5, 5, 6, 5, 10, 9, 12, 13, 18, 5, 14, 3, 8, 8, 6, 6, 8, 8, 9, 6, 8, 14, 5, 12, 16, 12, 3, 4, 6, 21, 6, 4, 13, 5, 4, 4, 5, 5, 4, 5, 17, 10, 11, 11, 11, 10, 12, 10, 10, 5, 9, 6, 7, 7, 4, 6, 7, 16, 2, 2, 8, 8, 10, 6, 7, 5, 11, 12, 12, 5, 6, 6, 5, 6, 6, 8, 4, 5, 8, 18, 17, 16, 4, 11, 7, 8, 10, 8, 8, 10, 7, 8, 14, 17, 3, 5, 5, 2, 6, 4, 4, 17, 3, 6, 4, 35, 13, 23, 7, 12, 10, 5, 11, 3, 3, 4, 6, 11, 12, 11, 11, 14, 15, 15, 13, 8, 10, 9, 7, 11, 17, 15, 16, 10, 7, 6, 9, 9, 8, 6, 6, 14, 15, 5, 10, 11, 10, 5, 8, 7, 7, 11, 7, 7, 6, 12, 10, 7, 7, 7, 8, 7, 9, 13, 7, 8, 9, 9, 8, 10, 10, 13, 7, 10, 12, 8, 7, 10, 11, 7, 12, 8, 15, 4, 10, 3, 5, 6, 6, 4, 9, 5, 4, 5, 9, 3, 4, 3, 9, 14, 12, 14, 10, 14, 6, 7, 9, 7, 18, 14, 6, 5, 3, 5, 10, 8, 7, 11, 10, 9, 3, 4, 3, 3, 5, 13, 7, 5, 9, 15, 9, 8, 9, 5, 3, 4, 5, 18, 5, 8, 8, 13, 6, 9, 6, 6, 7, 6, 5, 8, 4, 3, 4, 5, 5, 7, 7, 6, 7, 6, 6, 6, 6, 8, 10, 10, 8, 11, 10, 6, 11, 4, 12, 5, 9, 9, 4, 4, 10, 10, 4, 7, 8, 8, 6, 3, 4, 4, 5, 4, 8, 16, 7, 19, 7, 9, 8, 8, 8, 3, 3, 3, 2, 4, 3, 2, 5, 7, 3, 13, 8, 4, 11, 17, 2, 3, 4, 4, 18, 12, 17, 7, 7, 4, 4, 5, 8, 9, 14, 14, 9, 32, 7, 6, 6, 4, 6, 7, 6, 16, 14, 8, 10, 17, 11, 14, 1, 7, 4, 10, 10, 5, 4, 6, 7, 3, 14, 12, 9, 11, 11, 14, 10, 16, 11, 12, 13, 3, 13, 7, 6, 9, 21, 21, 11, 6, 11, 4, 2, 3, 3, 11, 7, 15, 4, 3, 3, 8, 6, 7, 5, 13, 10, 10, 12, 9, 10, 11, 7, 8, 8, 8, 6, 6, 5, 11, 7, 13, 12, 6, 7, 7, 4, 8, 6, 10, 19, 7, 7, 9, 7, 8, 14, 10, 11, 11, 3, 8, 7, 11, 27, 4, 5, 13, 12, 11, 13, 11, 13, 12, 11, 9, 10, 7, 9, 10, 4, 8, 10, 10, 6, 17, 4, 7, 5, 12, 12, 6, 19, 14, 5, 9, 11, 12, 12, 13, 13, 13, 13, 14, 12, 13, 15, 12, 13, 13, 13, 7, 6, 2, 9, 5, 4, 9, 5, 6, 4, 17, 17, 17, 8, 11, 10, 13, 13, 17, 11, 10, 19, 8, 8, 9, 6, 7, 25, 11, 9, 5, 10, 8, 8, 7, 8, 11, 9, 10, 9, 8, 8, 3, 4, 12, 13, 11, 12, 9, 10, 8, 7, 8, 4, 5, 5, 6, 13, 9, 4, 3, 7, 6, 10, 10, 10, 10, 11, 12, 11, 11, 11, 10, 11, 10, 9, 11, 11, 10, 12, 8, 4, 8, 8, 7, 8, 12, 12, 13, 5, 6, 8, 7, 8, 9, 9, 9, 11, 43, 6, 6, 7, 3, 11, 14, 13, 12, 8, 5, 5, 13, 2, 4, 8, 11, 9, 4, 12, 10, 10, 8, 6, 9, 16, 15, 15, 14, 18, 15, 13, 18, 14, 11, 4, 13, 19, 4, 4, 7, 9, 9, 3, 6, 7, 3, 4, 4, 3, 7, 6, 8, 9, 11, 9, 10, 8, 5, 6, 7, 8, 6, 9, 8, 9, 8, 5, 5, 5, 15, 10, 16, 3, 5, 11, 7, 6, 10, 10, 10, 8, 9, 3, 2, 3, 7, 11, 8, 4, 17, 5, 10, 11, 11, 4, 6, 5, 7, 3, 9, 7, 12, 12, 1, 8, 6, 14, 13, 13, 12, 15, 16, 12, 9, 3, 11, 11, 11, 10, 6, 5, 10, 9, 9, 7, 7, 6, 9, 7, 6, 7, 8, 7, 5, 4, 3, 3, 3, 7, 4, 5, 4, 5, 7, 3, 5, 7, 4, 19, 8, 21, 7, 7, 10, 10, 9, 9, 10, 11, 13, 19, 19, 15, 7, 12, 10, 13, 13, 9, 8, 10, 11, 14, 11, 10, 7, 8, 3, 10, 11, 4, 9, 9, 6, 4, 12, 4, 11, 6, 6, 8, 4, 7, 6, 7, 6, 6, 4, 4, 5, 8, 7, 7, 5, 4, 9, 3, 3, 8, 9, 23, 13, 5, 11, 6, 24, 4, 7, 4, 13, 12, 14, 12, 13, 4, 4, 5, 9, 7, 7, 11, 15, 6, 21, 6, 7, 5, 6, 6, 7, 8, 10, 9, 11, 11, 12, 10, 11, 11, 8, 11, 11, 12, 10, 11, 3, 9, 4, 9, 10, 8, 10, 5, 12, 11, 10, 6, 10, 10, 21, 9, 5, 8, 4, 10, 7, 8, 2, 10, 6, 4, 3, 1, 3, 4, 3, 3, 2, 2, 6, 2, 11, 9, 8, 6, 4, 8, 10, 12, 8, 9, 5, 12, 6, 7, 8, 7, 3, 9, 5, 9, 10, 7, 8, 7, 5, 6, 12, 11, 6, 11, 4, 11, 12, 11, 8, 9, 8, 12, 7, 4, 5, 8, 7, 7, 11, 5, 6, 6, 7, 7, 10, 6, 10, 6, 7, 7, 7, 5, 10, 7, 7, 9, 8, 10, 8, 8, 5, 5, 8, 7, 8, 8, 10, 11, 10, 8, 7, 9, 8, 10, 10, 7, 8, 11, 10, 8, 11, 9, 8, 8, 10, 10, 8, 11, 7, 5, 20, 6, 6, 5, 5, 5, 5, 5, 6, 5, 10, 9, 8, 8, 6, 12, 7, 7, 14, 3, 2, 3, 3, 16, 6, 13, 6, 13, 3, 1, 5, 4, 5, 1, 3, 7, 5, 4, 2, 1, 5, 7, 10, 4, 4, 5, 2, 1, 1, 1, 3, 3, 3, 1, 9, 2, 5, 6, 1, 1, 9, 7, 2, 1, 2, 3, 5, 6, 6, 5, 1, 4, 2, 3, 2, 4, 3, 5, 3, 5, 7, 7, 4, 5, 2, 6, 3, 4, 4, 7, 4, 9, 7, 2, 1, 6, 3, 3, 6, 4, 4, 5, 2, 3, 21, 4, 3, 1, 5, 5, 5, 2, 2, 3, 4, 1, 6, 3, 3, 7, 9, 7, 5, 3, 2, 2, 1, 4, 21, 4, 7, 9, 8, 6, 9, 8, 8, 8, 8, 8, 6, 5, 7, 5, 8, 7, 7, 4, 11, 8, 9, 9, 10, 9, 10, 9, 9, 6, 17, 8, 3, 15, 4, 11, 7, 7, 7, 8, 8, 8, 9, 7, 11, 10, 12, 9, 14, 6, 4, 7, 32, 6, 5, 6, 8, 4, 8, 4, 7, 8, 8, 7, 8, 9, 8, 5, 7, 9, 12, 9, 8, 12, 10, 10, 12, 9, 10, 9, 10, 9, 12, 9, 12, 13, 8, 9, 11, 9, 10, 12, 9, 7, 5, 5, 13, 8, 6, 16, 19, 17, 16, 19, 14, 15, 19, 19, 15, 12, 13, 2, 4, 4, 12, 12, 12, 12, 8, 6, 5, 3, 10, 9, 5, 13, 11, 10, 11, 4, 4, 3, 16, 15, 9, 4, 3, 6, 17, 8, 7, 16, 12, 32, 34, 7, 8, 9, 9, 7, 7, 8, 18, 9, 9, 15, 10, 10, 11, 7, 6, 5, 4, 3, 4, 8, 7, 9, 9, 3, 11, 7, 4, 8, 8, 7, 7, 8, 6, 10, 9, 6, 5, 9, 9, 9, 9, 26, 6, 6, 7, 7, 8, 6, 10, 8, 11, 3, 5, 7, 5, 6, 4, 6, 5, 6, 4, 10, 8, 8, 8, 7, 6, 10, 1, 6, 9, 8, 12, 6, 5, 3, 16, 4, 6, 12, 11, 12, 11, 13, 2, 2, 10, 7, 3, 12, 7, 5, 6, 7, 5, 4, 7, 8, 10, 9, 15, 5, 12, 2, 7, 22, 22, 8, 8, 8, 8, 13, 8, 5, 7, 8, 20, 6, 4, 7, 5, 6, 6, 7, 5, 6, 4, 4, 9, 8, 5, 11, 7, 6, 7, 8, 9, 3, 4, 5, 3, 2, 5, 8, 10, 11, 36, 4, 5, 13, 10, 10, 9, 7, 9, 12, 11, 4, 4, 7, 10, 6, 5, 6, 7, 4, 10, 8, 11, 10, 7, 6, 7, 6, 7, 7, 5, 5, 5, 8, 9, 9, 10, 5, 5, 7, 10, 11, 11, 10, 5, 8, 4, 4, 7, 6, 5, 6, 4, 3, 9, 9, 4, 8, 8, 2, 3, 7, 10, 10, 13, 11, 8, 7, 7, 11, 18, 9, 9, 10, 5, 11, 7, 3, 7, 11, 5, 10, 5, 6, 11, 7, 11, 5, 10, 10, 9, 7, 4, 17, 8, 12, 13, 15, 18, 16, 19, 8, 9, 7, 13, 14, 9, 8, 8, 8, 8, 4, 4, 8, 4, 5, 4, 9, 17, 3, 8, 12, 10, 10, 4, 10, 9, 9, 9, 8, 7, 7, 9, 10, 10, 8, 9, 8, 9, 9, 10, 10, 6, 8, 7, 8, 9, 8, 9, 5, 6, 8, 8, 9, 10, 8, 9, 8, 9, 8, 8, 9, 8, 9, 9, 11, 10, 8, 5, 8, 7, 8, 10, 10, 9, 10, 8, 9, 11, 11, 11, 7, 7, 9, 10, 10, 6, 7, 7, 9, 8, 9, 9, 10, 7, 8, 9, 8, 8, 10, 8, 9, 7, 11, 9, 10, 8, 17, 8, 4, 13, 5, 8, 7, 8, 6, 11, 10, 9, 8, 9, 11, 8, 10, 8, 11, 5, 7, 6, 18, 17, 19, 19, 8, 10, 7, 5, 8, 6, 9, 11, 7, 4, 9, 6, 10, 3, 5, 7, 10, 4, 7, 4, 5, 1, 7, 13, 13, 11, 17, 10, 12, 10, 5, 4, 5, 3, 6, 6, 5, 9, 10, 13, 13, 13, 5, 2, 2, 2, 22, 6, 6, 11, 5, 6, 9, 8, 6, 12, 6, 9, 4, 9, 3, 6, 12, 10, 5, 9, 11, 8, 4, 8, 4, 6, 7, 11, 7, 9, 7, 10, 21]\n",
            "Number of edges: [14, 2, 16, 6, 0, 18, 20, 6, 6, 8, 12, 2, 2, 8, 14, 6, 10, 8, 12, 2, 6, 6, 10, 14, 6, 2, 6, 10, 8, 14, 14, 8, 16, 10, 6, 8, 8, 4, 12, 0, 4, 2, 0, 6, 10, 6, 8, 0, 0, 8, 0, 0, 14, 10, 4, 10, 16, 18, 14, 4, 12, 6, 10, 14, 10, 14, 8, 2, 8, 12, 10, 8, 6, 6, 2, 6, 8, 10, 4, 4, 6, 16, 16, 14, 18, 6, 10, 4, 6, 8, 16, 18, 6, 18, 10, 2, 18, 6, 6, 8, 2, 2, 6, 8, 14, 2, 12, 4, 8, 16, 24, 22, 8, 4, 16, 12, 18, 4, 12, 10, 6, 14, 16, 14, 6, 6, 8, 10, 8, 6, 6, 6, 2, 2, 18, 12, 12, 100, 8, 12, 14, 22, 6, 22, 14, 14, 18, 8, 20, 16, 14, 18, 20, 22, 6, 10, 20, 12, 14, 12, 8, 18, 22, 2, 16, 8, 28, 20, 8, 10, 12, 26, 20, 12, 12, 4, 14, 18, 22, 16, 12, 20, 14, 12, 14, 24, 18, 8, 18, 14, 12, 12, 8, 28, 10, 2, 14, 2, 2, 12, 24, 16, 36, 16, 22, 22, 30, 30, 26, 4, 8, 4, 12, 18, 18, 18, 12, 16, 16, 14, 14, 16, 12, 10, 18, 12, 26, 20, 14, 18, 2, 4, 6, 2, 10, 2, 4, 2, 4, 4, 6, 2, 6, 4, 4, 4, 8, 4, 10, 18, 8, 38, 42, 20, 6, 8, 4, 24, 16, 18, 20, 18, 24, 4, 10, 14, 10, 8, 8, 10, 8, 14, 34, 24, 16, 18, 6, 8, 6, 10, 10, 10, 10, 10, 36, 30, 32, 22, 16, 12, 10, 12, 22, 38, 8, 20, 10, 10, 16, 18, 10, 10, 14, 8, 28, 2, 16, 12, 12, 8, 8, 22, 10, 10, 10, 12, 10, 6, 22, 6, 6, 16, 12, 18, 18, 40, 6, 20, 8, 12, 14, 32, 14, 16, 8, 6, 6, 8, 14, 20, 12, 12, 20, 8, 8, 8, 12, 8, 18, 16, 24, 24, 32, 8, 30, 4, 14, 14, 10, 10, 14, 14, 16, 10, 18, 26, 8, 22, 30, 22, 4, 6, 10, 40, 10, 6, 28, 8, 6, 6, 8, 8, 6, 8, 22, 20, 20, 20, 20, 18, 26, 18, 22, 8, 16, 10, 12, 12, 6, 10, 14, 30, 2, 2, 16, 16, 22, 10, 12, 8, 20, 22, 22, 8, 10, 10, 8, 10, 10, 14, 6, 8, 16, 36, 34, 32, 6, 22, 14, 16, 20, 16, 12, 18, 12, 14, 28, 30, 4, 8, 6, 2, 10, 6, 6, 36, 4, 10, 6, 68, 28, 50, 14, 24, 18, 8, 20, 4, 4, 6, 12, 24, 26, 24, 24, 30, 32, 32, 28, 14, 18, 16, 10, 20, 32, 28, 30, 18, 14, 10, 18, 20, 18, 10, 10, 26, 28, 10, 20, 24, 22, 8, 14, 12, 12, 14, 12, 12, 10, 22, 18, 12, 12, 10, 14, 12, 12, 28, 12, 16, 18, 16, 14, 20, 20, 24, 14, 20, 26, 14, 12, 20, 22, 14, 24, 16, 30, 6, 18, 4, 8, 10, 10, 6, 16, 8, 6, 8, 16, 4, 6, 4, 18, 28, 24, 28, 20, 30, 10, 12, 16, 12, 30, 30, 12, 8, 4, 8, 16, 12, 14, 22, 20, 18, 4, 6, 4, 4, 8, 28, 12, 8, 20, 28, 16, 14, 16, 8, 4, 6, 8, 36, 8, 14, 14, 26, 10, 12, 10, 10, 12, 10, 8, 14, 6, 4, 6, 8, 8, 8, 12, 10, 12, 10, 10, 10, 10, 14, 16, 18, 14, 14, 22, 10, 20, 8, 26, 8, 18, 18, 6, 6, 20, 20, 6, 14, 16, 16, 10, 4, 6, 6, 8, 6, 14, 34, 12, 40, 14, 14, 14, 16, 16, 4, 4, 4, 2, 6, 4, 2, 8, 12, 4, 26, 14, 6, 22, 32, 2, 4, 6, 6, 36, 24, 36, 14, 12, 6, 8, 8, 16, 20, 28, 28, 14, 66, 14, 12, 12, 6, 12, 14, 12, 32, 30, 16, 18, 32, 26, 28, 0, 12, 6, 20, 20, 8, 6, 12, 14, 4, 26, 24, 18, 22, 22, 26, 20, 28, 20, 22, 24, 4, 26, 14, 12, 18, 42, 42, 24, 10, 22, 6, 2, 4, 4, 20, 12, 32, 6, 4, 4, 14, 10, 12, 8, 26, 20, 20, 24, 18, 20, 22, 14, 16, 14, 14, 10, 10, 10, 20, 14, 26, 24, 12, 14, 14, 6, 16, 10, 18, 38, 12, 12, 18, 14, 14, 28, 20, 22, 22, 4, 14, 12, 20, 52, 6, 10, 30, 28, 26, 30, 26, 30, 28, 22, 18, 18, 12, 16, 18, 8, 16, 22, 22, 10, 34, 6, 12, 8, 22, 22, 8, 40, 30, 8, 16, 24, 26, 26, 28, 28, 28, 28, 30, 26, 28, 32, 26, 28, 28, 28, 12, 10, 2, 16, 8, 6, 18, 8, 10, 6, 32, 32, 36, 14, 24, 22, 28, 28, 36, 24, 18, 40, 14, 16, 16, 10, 12, 52, 22, 16, 8, 18, 14, 14, 12, 14, 20, 16, 18, 16, 14, 14, 4, 6, 22, 24, 24, 26, 16, 18, 14, 12, 16, 8, 10, 8, 10, 28, 16, 6, 4, 12, 10, 20, 20, 20, 20, 22, 24, 22, 22, 22, 20, 22, 20, 18, 22, 22, 20, 24, 14, 6, 16, 16, 14, 16, 24, 24, 26, 8, 10, 14, 12, 14, 16, 14, 16, 16, 92, 10, 10, 14, 4, 22, 26, 26, 24, 14, 8, 8, 28, 2, 6, 18, 24, 20, 6, 20, 20, 20, 14, 10, 16, 32, 30, 26, 28, 36, 30, 26, 36, 28, 20, 6, 24, 38, 6, 6, 8, 18, 18, 4, 10, 12, 4, 6, 6, 4, 12, 10, 14, 16, 20, 16, 16, 14, 8, 10, 12, 14, 10, 16, 14, 16, 14, 10, 10, 10, 30, 18, 32, 4, 8, 16, 12, 10, 18, 20, 24, 14, 16, 4, 2, 4, 14, 26, 16, 8, 34, 8, 20, 22, 22, 8, 10, 8, 12, 4, 20, 12, 26, 22, 0, 14, 8, 30, 28, 28, 26, 32, 34, 26, 16, 4, 16, 22, 26, 18, 10, 8, 20, 16, 16, 12, 12, 10, 16, 12, 12, 14, 16, 12, 8, 6, 4, 4, 4, 12, 6, 8, 6, 8, 12, 4, 8, 12, 6, 40, 14, 40, 14, 14, 18, 18, 16, 16, 18, 20, 24, 38, 38, 30, 14, 24, 20, 24, 24, 16, 14, 20, 22, 28, 22, 20, 14, 14, 4, 20, 20, 6, 18, 16, 8, 6, 24, 6, 22, 12, 10, 16, 6, 12, 10, 12, 10, 10, 6, 6, 10, 14, 12, 12, 8, 6, 14, 4, 4, 14, 16, 46, 28, 8, 20, 12, 48, 6, 12, 6, 28, 26, 30, 26, 28, 6, 6, 8, 16, 12, 12, 22, 26, 12, 36, 10, 12, 10, 12, 12, 14, 14, 18, 16, 20, 20, 22, 18, 20, 20, 14, 20, 20, 22, 18, 20, 4, 16, 6, 16, 14, 14, 16, 10, 24, 22, 22, 12, 18, 14, 44, 20, 8, 16, 8, 14, 12, 16, 2, 18, 10, 6, 4, 0, 4, 6, 4, 4, 2, 2, 10, 2, 22, 16, 14, 10, 6, 10, 18, 26, 16, 18, 8, 24, 12, 12, 14, 12, 4, 12, 8, 18, 20, 12, 14, 12, 8, 10, 20, 24, 10, 20, 6, 22, 24, 20, 14, 16, 14, 22, 12, 6, 8, 16, 14, 14, 22, 8, 12, 12, 12, 12, 20, 10, 20, 10, 14, 14, 14, 8, 20, 14, 12, 18, 16, 20, 16, 14, 8, 8, 16, 14, 16, 16, 20, 22, 20, 16, 14, 18, 16, 20, 20, 14, 16, 22, 20, 16, 22, 18, 16, 16, 20, 20, 16, 22, 12, 8, 42, 10, 10, 8, 8, 8, 8, 8, 10, 8, 22, 18, 16, 16, 10, 26, 12, 12, 30, 4, 2, 4, 4, 28, 12, 24, 12, 24, 4, 0, 8, 0, 8, 0, 4, 10, 8, 6, 2, 0, 8, 12, 18, 4, 6, 8, 2, 0, 0, 0, 4, 4, 4, 0, 16, 2, 8, 10, 0, 0, 16, 12, 2, 0, 2, 4, 8, 10, 10, 8, 0, 6, 2, 4, 2, 6, 4, 8, 4, 8, 12, 12, 6, 8, 2, 10, 4, 6, 6, 12, 6, 16, 12, 2, 0, 10, 4, 4, 10, 6, 6, 8, 2, 4, 40, 6, 4, 0, 8, 8, 8, 2, 2, 4, 6, 0, 10, 4, 4, 12, 16, 12, 8, 4, 2, 2, 0, 6, 42, 6, 12, 16, 14, 10, 16, 14, 14, 14, 14, 16, 10, 8, 14, 10, 16, 14, 14, 6, 22, 14, 18, 20, 22, 20, 20, 20, 20, 10, 32, 14, 4, 32, 6, 22, 14, 14, 12, 12, 14, 14, 16, 14, 22, 22, 22, 18, 30, 12, 6, 12, 64, 10, 8, 8, 16, 6, 18, 6, 12, 16, 16, 12, 14, 20, 14, 8, 12, 16, 22, 16, 14, 18, 18, 16, 18, 16, 18, 16, 18, 16, 18, 16, 26, 24, 16, 18, 20, 16, 20, 26, 16, 14, 10, 8, 20, 18, 10, 30, 36, 32, 30, 36, 26, 28, 36, 36, 28, 24, 22, 2, 6, 6, 26, 26, 26, 24, 12, 12, 8, 4, 22, 20, 6, 26, 22, 20, 22, 6, 6, 4, 30, 28, 18, 6, 4, 10, 32, 14, 12, 32, 24, 68, 72, 12, 14, 16, 16, 12, 12, 14, 38, 16, 16, 32, 20, 18, 22, 10, 10, 6, 6, 4, 6, 14, 12, 16, 16, 4, 22, 12, 6, 14, 14, 12, 12, 14, 10, 18, 16, 10, 10, 18, 18, 18, 18, 56, 12, 12, 12, 14, 16, 10, 16, 16, 20, 4, 8, 8, 8, 10, 6, 10, 8, 10, 6, 20, 16, 16, 16, 14, 12, 18, 0, 8, 18, 16, 20, 10, 8, 4, 32, 6, 10, 22, 20, 20, 20, 24, 2, 2, 20, 14, 4, 24, 14, 10, 12, 14, 10, 2, 8, 16, 18, 16, 28, 8, 22, 2, 12, 46, 46, 14, 14, 16, 16, 26, 16, 10, 14, 16, 42, 10, 6, 12, 8, 10, 10, 12, 8, 10, 8, 8, 18, 16, 8, 20, 14, 10, 14, 16, 18, 4, 6, 4, 4, 2, 8, 14, 18, 20, 70, 6, 8, 26, 20, 22, 16, 14, 20, 24, 22, 6, 6, 12, 20, 10, 8, 10, 14, 6, 20, 16, 20, 18, 14, 12, 12, 10, 12, 12, 8, 8, 8, 14, 16, 16, 20, 8, 8, 12, 20, 22, 22, 20, 8, 12, 6, 6, 12, 10, 8, 10, 6, 4, 18, 18, 6, 16, 16, 2, 4, 14, 20, 20, 24, 22, 16, 12, 12, 24, 40, 18, 16, 18, 8, 20, 12, 4, 14, 20, 8, 20, 8, 10, 24, 14, 24, 8, 20, 20, 18, 14, 6, 36, 18, 26, 28, 32, 36, 32, 38, 14, 16, 12, 28, 30, 18, 14, 14, 14, 14, 6, 8, 16, 6, 8, 6, 16, 36, 4, 14, 26, 20, 20, 6, 18, 16, 18, 18, 14, 12, 12, 16, 18, 18, 14, 16, 14, 16, 16, 18, 18, 10, 14, 12, 14, 16, 14, 16, 8, 10, 14, 14, 16, 18, 14, 16, 14, 16, 14, 14, 16, 14, 16, 16, 20, 18, 14, 8, 14, 12, 14, 18, 18, 16, 18, 14, 16, 20, 20, 20, 12, 12, 16, 18, 18, 10, 12, 12, 16, 14, 16, 16, 18, 12, 14, 16, 14, 14, 16, 14, 16, 12, 20, 16, 20, 16, 34, 16, 6, 28, 8, 14, 12, 14, 10, 20, 18, 16, 14, 16, 20, 14, 18, 14, 24, 8, 12, 12, 36, 34, 38, 38, 16, 18, 12, 8, 14, 10, 18, 22, 10, 6, 18, 10, 20, 4, 8, 12, 16, 6, 12, 8, 8, 0, 14, 26, 26, 22, 36, 20, 24, 20, 8, 6, 8, 4, 6, 10, 8, 18, 18, 26, 26, 26, 8, 2, 2, 2, 44, 10, 10, 24, 8, 10, 16, 12, 10, 24, 10, 16, 6, 18, 4, 10, 26, 18, 8, 18, 24, 16, 6, 16, 6, 10, 12, 20, 12, 12, 12, 18, 44]\n",
            "Number of graphs: 2039\n",
            "Adjacency matrix shape: [(8, 8), (2, 2), (9, 9), (4, 4), (1, 1), (10, 10), (11, 11), (4, 4), (4, 4), (5, 5), (7, 7), (3, 3), (2, 2), (5, 5), (8, 8), (4, 4), (6, 6), (5, 5), (7, 7), (2, 2), (4, 4), (4, 4), (6, 6), (8, 8), (4, 4), (2, 2), (4, 4), (6, 6), (5, 5), (8, 8), (8, 8), (5, 5), (10, 10), (6, 6), (4, 4), (5, 5), (5, 5), (3, 3), (7, 7), (1, 1), (3, 3), (2, 2), (1, 1), (4, 4), (6, 6), (4, 4), (5, 5), (1, 1), (1, 1), (5, 5), (1, 1), (1, 1), (8, 8), (6, 6), (3, 3), (6, 6), (9, 9), (10, 10), (8, 8), (3, 3), (7, 7), (4, 4), (6, 6), (8, 8), (6, 6), (8, 8), (5, 5), (2, 2), (5, 5), (7, 7), (6, 6), (5, 5), (4, 4), (4, 4), (2, 2), (4, 4), (5, 5), (6, 6), (3, 3), (3, 3), (4, 4), (9, 9), (9, 9), (8, 8), (10, 10), (4, 4), (6, 6), (3, 3), (4, 4), (5, 5), (9, 9), (10, 10), (4, 4), (11, 11), (6, 6), (2, 2), (12, 12), (4, 4), (4, 4), (5, 5), (2, 2), (2, 2), (4, 4), (5, 5), (8, 8), (2, 2), (7, 7), (3, 3), (5, 5), (9, 9), (13, 13), (12, 12), (5, 5), (3, 3), (10, 10), (7, 7), (10, 10), (3, 3), (9, 9), (6, 6), (4, 4), (8, 8), (9, 9), (8, 8), (4, 4), (4, 4), (5, 5), (6, 6), (5, 5), (4, 4), (4, 4), (4, 4), (3, 3), (2, 2), (10, 10), (7, 7), (7, 7), (48, 48), (5, 5), (6, 6), (8, 8), (10, 10), (4, 4), (11, 11), (7, 7), (7, 7), (9, 9), (5, 5), (11, 11), (9, 9), (8, 8), (9, 9), (10, 10), (11, 11), (4, 4), (6, 6), (11, 11), (7, 7), (8, 8), (7, 7), (5, 5), (10, 10), (10, 10), (2, 2), (9, 9), (5, 5), (15, 15), (10, 10), (5, 5), (6, 6), (6, 6), (14, 14), (11, 11), (7, 7), (8, 8), (3, 3), (8, 8), (10, 10), (11, 11), (9, 9), (7, 7), (11, 11), (8, 8), (7, 7), (8, 8), (12, 12), (9, 9), (6, 6), (9, 9), (8, 8), (7, 7), (7, 7), (5, 5), (14, 14), (6, 6), (2, 2), (8, 8), (4, 4), (2, 2), (6, 6), (11, 11), (8, 8), (17, 17), (8, 8), (12, 12), (12, 12), (14, 14), (14, 14), (12, 12), (3, 3), (5, 5), (3, 3), (7, 7), (10, 10), (10, 10), (10, 10), (7, 7), (9, 9), (8, 8), (8, 8), (8, 8), (9, 9), (7, 7), (6, 6), (10, 10), (7, 7), (14, 14), (10, 10), (8, 8), (11, 11), (2, 2), (3, 3), (4, 4), (2, 2), (6, 6), (2, 2), (3, 3), (2, 2), (3, 3), (3, 3), (4, 4), (2, 2), (4, 4), (3, 3), (3, 3), (3, 3), (5, 5), (3, 3), (5, 5), (10, 10), (5, 5), (19, 19), (21, 21), (9, 9), (4, 4), (7, 7), (3, 3), (12, 12), (8, 8), (8, 8), (9, 9), (8, 8), (11, 11), (3, 3), (5, 5), (7, 7), (6, 6), (5, 5), (5, 5), (6, 6), (5, 5), (7, 7), (16, 16), (13, 13), (9, 9), (9, 9), (4, 4), (5, 5), (4, 4), (6, 6), (6, 6), (6, 6), (6, 6), (6, 6), (17, 17), (16, 16), (15, 15), (11, 11), (10, 10), (7, 7), (6, 6), (7, 7), (11, 11), (19, 19), (5, 5), (11, 11), (5, 5), (5, 5), (8, 8), (9, 9), (5, 5), (5, 5), (8, 8), (5, 5), (14, 14), (2, 2), (10, 10), (6, 6), (6, 6), (7, 7), (5, 5), (10, 10), (6, 6), (6, 6), (5, 5), (7, 7), (6, 6), (4, 4), (11, 11), (4, 4), (4, 4), (8, 8), (6, 6), (9, 9), (9, 9), (19, 19), (4, 4), (10, 10), (5, 5), (7, 7), (7, 7), (15, 15), (7, 7), (9, 9), (5, 5), (4, 4), (4, 4), (5, 5), (7, 7), (11, 11), (7, 7), (7, 7), (9, 9), (5, 5), (5, 5), (5, 5), (6, 6), (5, 5), (10, 10), (9, 9), (12, 12), (13, 13), (18, 18), (5, 5), (14, 14), (3, 3), (8, 8), (8, 8), (6, 6), (6, 6), (8, 8), (8, 8), (9, 9), (6, 6), (8, 8), (14, 14), (5, 5), (12, 12), (16, 16), (12, 12), (3, 3), (4, 4), (6, 6), (21, 21), (6, 6), (4, 4), (13, 13), (5, 5), (4, 4), (4, 4), (5, 5), (5, 5), (4, 4), (5, 5), (17, 17), (10, 10), (11, 11), (11, 11), (11, 11), (10, 10), (12, 12), (10, 10), (10, 10), (5, 5), (9, 9), (6, 6), (7, 7), (7, 7), (4, 4), (6, 6), (7, 7), (16, 16), (2, 2), (2, 2), (8, 8), (8, 8), (10, 10), (6, 6), (7, 7), (5, 5), (11, 11), (12, 12), (12, 12), (5, 5), (6, 6), (6, 6), (5, 5), (6, 6), (6, 6), (8, 8), (4, 4), (5, 5), (8, 8), (18, 18), (17, 17), (16, 16), (4, 4), (11, 11), (7, 7), (8, 8), (10, 10), (8, 8), (8, 8), (10, 10), (7, 7), (8, 8), (14, 14), (17, 17), (3, 3), (5, 5), (5, 5), (2, 2), (6, 6), (4, 4), (4, 4), (17, 17), (3, 3), (6, 6), (4, 4), (35, 35), (13, 13), (23, 23), (7, 7), (12, 12), (10, 10), (5, 5), (11, 11), (3, 3), (3, 3), (4, 4), (6, 6), (11, 11), (12, 12), (11, 11), (11, 11), (14, 14), (15, 15), (15, 15), (13, 13), (8, 8), (10, 10), (9, 9), (7, 7), (11, 11), (17, 17), (15, 15), (16, 16), (10, 10), (7, 7), (6, 6), (9, 9), (9, 9), (8, 8), (6, 6), (6, 6), (14, 14), (15, 15), (5, 5), (10, 10), (11, 11), (10, 10), (5, 5), (8, 8), (7, 7), (7, 7), (11, 11), (7, 7), (7, 7), (6, 6), (12, 12), (10, 10), (7, 7), (7, 7), (7, 7), (8, 8), (7, 7), (9, 9), (13, 13), (7, 7), (8, 8), (9, 9), (9, 9), (8, 8), (10, 10), (10, 10), (13, 13), (7, 7), (10, 10), (12, 12), (8, 8), (7, 7), (10, 10), (11, 11), (7, 7), (12, 12), (8, 8), (15, 15), (4, 4), (10, 10), (3, 3), (5, 5), (6, 6), (6, 6), (4, 4), (9, 9), (5, 5), (4, 4), (5, 5), (9, 9), (3, 3), (4, 4), (3, 3), (9, 9), (14, 14), (12, 12), (14, 14), (10, 10), (14, 14), (6, 6), (7, 7), (9, 9), (7, 7), (18, 18), (14, 14), (6, 6), (5, 5), (3, 3), (5, 5), (10, 10), (8, 8), (7, 7), (11, 11), (10, 10), (9, 9), (3, 3), (4, 4), (3, 3), (3, 3), (5, 5), (13, 13), (7, 7), (5, 5), (9, 9), (15, 15), (9, 9), (8, 8), (9, 9), (5, 5), (3, 3), (4, 4), (5, 5), (18, 18), (5, 5), (8, 8), (8, 8), (13, 13), (6, 6), (9, 9), (6, 6), (6, 6), (7, 7), (6, 6), (5, 5), (8, 8), (4, 4), (3, 3), (4, 4), (5, 5), (5, 5), (7, 7), (7, 7), (6, 6), (7, 7), (6, 6), (6, 6), (6, 6), (6, 6), (8, 8), (10, 10), (10, 10), (8, 8), (11, 11), (10, 10), (6, 6), (11, 11), (4, 4), (12, 12), (5, 5), (9, 9), (9, 9), (4, 4), (4, 4), (10, 10), (10, 10), (4, 4), (7, 7), (8, 8), (8, 8), (6, 6), (3, 3), (4, 4), (4, 4), (5, 5), (4, 4), (8, 8), (16, 16), (7, 7), (19, 19), (7, 7), (9, 9), (8, 8), (8, 8), (8, 8), (3, 3), (3, 3), (3, 3), (2, 2), (4, 4), (3, 3), (2, 2), (5, 5), (7, 7), (3, 3), (13, 13), (8, 8), (4, 4), (11, 11), (17, 17), (2, 2), (3, 3), (4, 4), (4, 4), (18, 18), (12, 12), (17, 17), (7, 7), (7, 7), (4, 4), (4, 4), (5, 5), (8, 8), (9, 9), (14, 14), (14, 14), (9, 9), (32, 32), (7, 7), (6, 6), (6, 6), (4, 4), (6, 6), (7, 7), (6, 6), (16, 16), (14, 14), (8, 8), (10, 10), (17, 17), (11, 11), (14, 14), (1, 1), (7, 7), (4, 4), (10, 10), (10, 10), (5, 5), (4, 4), (6, 6), (7, 7), (3, 3), (14, 14), (12, 12), (9, 9), (11, 11), (11, 11), (14, 14), (10, 10), (16, 16), (11, 11), (12, 12), (13, 13), (3, 3), (13, 13), (7, 7), (6, 6), (9, 9), (21, 21), (21, 21), (11, 11), (6, 6), (11, 11), (4, 4), (2, 2), (3, 3), (3, 3), (11, 11), (7, 7), (15, 15), (4, 4), (3, 3), (3, 3), (8, 8), (6, 6), (7, 7), (5, 5), (13, 13), (10, 10), (10, 10), (12, 12), (9, 9), (10, 10), (11, 11), (7, 7), (8, 8), (8, 8), (8, 8), (6, 6), (6, 6), (5, 5), (11, 11), (7, 7), (13, 13), (12, 12), (6, 6), (7, 7), (7, 7), (4, 4), (8, 8), (6, 6), (10, 10), (19, 19), (7, 7), (7, 7), (9, 9), (7, 7), (8, 8), (14, 14), (10, 10), (11, 11), (11, 11), (3, 3), (8, 8), (7, 7), (11, 11), (27, 27), (4, 4), (5, 5), (13, 13), (12, 12), (11, 11), (13, 13), (11, 11), (13, 13), (12, 12), (11, 11), (9, 9), (10, 10), (7, 7), (9, 9), (10, 10), (4, 4), (8, 8), (10, 10), (10, 10), (6, 6), (17, 17), (4, 4), (7, 7), (5, 5), (12, 12), (12, 12), (6, 6), (19, 19), (14, 14), (5, 5), (9, 9), (11, 11), (12, 12), (12, 12), (13, 13), (13, 13), (13, 13), (13, 13), (14, 14), (12, 12), (13, 13), (15, 15), (12, 12), (13, 13), (13, 13), (13, 13), (7, 7), (6, 6), (2, 2), (9, 9), (5, 5), (4, 4), (9, 9), (5, 5), (6, 6), (4, 4), (17, 17), (17, 17), (17, 17), (8, 8), (11, 11), (10, 10), (13, 13), (13, 13), (17, 17), (11, 11), (10, 10), (19, 19), (8, 8), (8, 8), (9, 9), (6, 6), (7, 7), (25, 25), (11, 11), (9, 9), (5, 5), (10, 10), (8, 8), (8, 8), (7, 7), (8, 8), (11, 11), (9, 9), (10, 10), (9, 9), (8, 8), (8, 8), (3, 3), (4, 4), (12, 12), (13, 13), (11, 11), (12, 12), (9, 9), (10, 10), (8, 8), (7, 7), (8, 8), (4, 4), (5, 5), (5, 5), (6, 6), (13, 13), (9, 9), (4, 4), (3, 3), (7, 7), (6, 6), (10, 10), (10, 10), (10, 10), (10, 10), (11, 11), (12, 12), (11, 11), (11, 11), (11, 11), (10, 10), (11, 11), (10, 10), (9, 9), (11, 11), (11, 11), (10, 10), (12, 12), (8, 8), (4, 4), (8, 8), (8, 8), (7, 7), (8, 8), (12, 12), (12, 12), (13, 13), (5, 5), (6, 6), (8, 8), (7, 7), (8, 8), (9, 9), (9, 9), (9, 9), (11, 11), (43, 43), (6, 6), (6, 6), (7, 7), (3, 3), (11, 11), (14, 14), (13, 13), (12, 12), (8, 8), (5, 5), (5, 5), (13, 13), (2, 2), (4, 4), (8, 8), (11, 11), (9, 9), (4, 4), (12, 12), (10, 10), (10, 10), (8, 8), (6, 6), (9, 9), (16, 16), (15, 15), (15, 15), (14, 14), (18, 18), (15, 15), (13, 13), (18, 18), (14, 14), (11, 11), (4, 4), (13, 13), (19, 19), (4, 4), (4, 4), (7, 7), (9, 9), (9, 9), (3, 3), (6, 6), (7, 7), (3, 3), (4, 4), (4, 4), (3, 3), (7, 7), (6, 6), (8, 8), (9, 9), (11, 11), (9, 9), (10, 10), (8, 8), (5, 5), (6, 6), (7, 7), (8, 8), (6, 6), (9, 9), (8, 8), (9, 9), (8, 8), (5, 5), (5, 5), (5, 5), (15, 15), (10, 10), (16, 16), (3, 3), (5, 5), (11, 11), (7, 7), (6, 6), (10, 10), (10, 10), (10, 10), (8, 8), (9, 9), (3, 3), (2, 2), (3, 3), (7, 7), (11, 11), (8, 8), (4, 4), (17, 17), (5, 5), (10, 10), (11, 11), (11, 11), (4, 4), (6, 6), (5, 5), (7, 7), (3, 3), (9, 9), (7, 7), (12, 12), (12, 12), (1, 1), (8, 8), (6, 6), (14, 14), (13, 13), (13, 13), (12, 12), (15, 15), (16, 16), (12, 12), (9, 9), (3, 3), (11, 11), (11, 11), (11, 11), (10, 10), (6, 6), (5, 5), (10, 10), (9, 9), (9, 9), (7, 7), (7, 7), (6, 6), (9, 9), (7, 7), (6, 6), (7, 7), (8, 8), (7, 7), (5, 5), (4, 4), (3, 3), (3, 3), (3, 3), (7, 7), (4, 4), (5, 5), (4, 4), (5, 5), (7, 7), (3, 3), (5, 5), (7, 7), (4, 4), (19, 19), (8, 8), (21, 21), (7, 7), (7, 7), (10, 10), (10, 10), (9, 9), (9, 9), (10, 10), (11, 11), (13, 13), (19, 19), (19, 19), (15, 15), (7, 7), (12, 12), (10, 10), (13, 13), (13, 13), (9, 9), (8, 8), (10, 10), (11, 11), (14, 14), (11, 11), (10, 10), (7, 7), (8, 8), (3, 3), (10, 10), (11, 11), (4, 4), (9, 9), (9, 9), (6, 6), (4, 4), (12, 12), (4, 4), (11, 11), (6, 6), (6, 6), (8, 8), (4, 4), (7, 7), (6, 6), (7, 7), (6, 6), (6, 6), (4, 4), (4, 4), (5, 5), (8, 8), (7, 7), (7, 7), (5, 5), (4, 4), (9, 9), (3, 3), (3, 3), (8, 8), (9, 9), (23, 23), (13, 13), (5, 5), (11, 11), (6, 6), (24, 24), (4, 4), (7, 7), (4, 4), (13, 13), (12, 12), (14, 14), (12, 12), (13, 13), (4, 4), (4, 4), (5, 5), (9, 9), (7, 7), (7, 7), (11, 11), (15, 15), (6, 6), (21, 21), (6, 6), (7, 7), (5, 5), (6, 6), (6, 6), (7, 7), (8, 8), (10, 10), (9, 9), (11, 11), (11, 11), (12, 12), (10, 10), (11, 11), (11, 11), (8, 8), (11, 11), (11, 11), (12, 12), (10, 10), (11, 11), (3, 3), (9, 9), (4, 4), (9, 9), (10, 10), (8, 8), (10, 10), (5, 5), (12, 12), (11, 11), (10, 10), (6, 6), (10, 10), (10, 10), (21, 21), (9, 9), (5, 5), (8, 8), (4, 4), (10, 10), (7, 7), (8, 8), (2, 2), (10, 10), (6, 6), (4, 4), (3, 3), (1, 1), (3, 3), (4, 4), (3, 3), (3, 3), (2, 2), (2, 2), (6, 6), (2, 2), (11, 11), (9, 9), (8, 8), (6, 6), (4, 4), (8, 8), (10, 10), (12, 12), (8, 8), (9, 9), (5, 5), (12, 12), (6, 6), (7, 7), (8, 8), (7, 7), (3, 3), (9, 9), (5, 5), (9, 9), (10, 10), (7, 7), (8, 8), (7, 7), (5, 5), (6, 6), (12, 12), (11, 11), (6, 6), (11, 11), (4, 4), (11, 11), (12, 12), (11, 11), (8, 8), (9, 9), (8, 8), (12, 12), (7, 7), (4, 4), (5, 5), (8, 8), (7, 7), (7, 7), (11, 11), (5, 5), (6, 6), (6, 6), (7, 7), (7, 7), (10, 10), (6, 6), (10, 10), (6, 6), (7, 7), (7, 7), (7, 7), (5, 5), (10, 10), (7, 7), (7, 7), (9, 9), (8, 8), (10, 10), (8, 8), (8, 8), (5, 5), (5, 5), (8, 8), (7, 7), (8, 8), (8, 8), (10, 10), (11, 11), (10, 10), (8, 8), (7, 7), (9, 9), (8, 8), (10, 10), (10, 10), (7, 7), (8, 8), (11, 11), (10, 10), (8, 8), (11, 11), (9, 9), (8, 8), (8, 8), (10, 10), (10, 10), (8, 8), (11, 11), (7, 7), (5, 5), (20, 20), (6, 6), (6, 6), (5, 5), (5, 5), (5, 5), (5, 5), (5, 5), (6, 6), (5, 5), (10, 10), (9, 9), (8, 8), (8, 8), (6, 6), (12, 12), (7, 7), (7, 7), (14, 14), (3, 3), (2, 2), (3, 3), (3, 3), (16, 16), (6, 6), (13, 13), (6, 6), (13, 13), (3, 3), (1, 1), (5, 5), (4, 4), (5, 5), (1, 1), (3, 3), (7, 7), (5, 5), (4, 4), (2, 2), (1, 1), (5, 5), (7, 7), (10, 10), (4, 4), (4, 4), (5, 5), (2, 2), (1, 1), (1, 1), (1, 1), (3, 3), (3, 3), (3, 3), (1, 1), (9, 9), (2, 2), (5, 5), (6, 6), (1, 1), (1, 1), (9, 9), (7, 7), (2, 2), (1, 1), (2, 2), (3, 3), (5, 5), (6, 6), (6, 6), (5, 5), (1, 1), (4, 4), (2, 2), (3, 3), (2, 2), (4, 4), (3, 3), (5, 5), (3, 3), (5, 5), (7, 7), (7, 7), (4, 4), (5, 5), (2, 2), (6, 6), (3, 3), (4, 4), (4, 4), (7, 7), (4, 4), (9, 9), (7, 7), (2, 2), (1, 1), (6, 6), (3, 3), (3, 3), (6, 6), (4, 4), (4, 4), (5, 5), (2, 2), (3, 3), (21, 21), (4, 4), (3, 3), (1, 1), (5, 5), (5, 5), (5, 5), (2, 2), (2, 2), (3, 3), (4, 4), (1, 1), (6, 6), (3, 3), (3, 3), (7, 7), (9, 9), (7, 7), (5, 5), (3, 3), (2, 2), (2, 2), (1, 1), (4, 4), (21, 21), (4, 4), (7, 7), (9, 9), (8, 8), (6, 6), (9, 9), (8, 8), (8, 8), (8, 8), (8, 8), (8, 8), (6, 6), (5, 5), (7, 7), (5, 5), (8, 8), (7, 7), (7, 7), (4, 4), (11, 11), (8, 8), (9, 9), (9, 9), (10, 10), (9, 9), (10, 10), (9, 9), (9, 9), (6, 6), (17, 17), (8, 8), (3, 3), (15, 15), (4, 4), (11, 11), (7, 7), (7, 7), (7, 7), (8, 8), (8, 8), (8, 8), (9, 9), (7, 7), (11, 11), (10, 10), (12, 12), (9, 9), (14, 14), (6, 6), (4, 4), (7, 7), (32, 32), (6, 6), (5, 5), (6, 6), (8, 8), (4, 4), (8, 8), (4, 4), (7, 7), (8, 8), (8, 8), (7, 7), (8, 8), (9, 9), (8, 8), (5, 5), (7, 7), (9, 9), (12, 12), (9, 9), (8, 8), (12, 12), (10, 10), (10, 10), (12, 12), (9, 9), (10, 10), (9, 9), (10, 10), (9, 9), (12, 12), (9, 9), (12, 12), (13, 13), (8, 8), (9, 9), (11, 11), (9, 9), (10, 10), (12, 12), (9, 9), (7, 7), (5, 5), (5, 5), (13, 13), (8, 8), (6, 6), (16, 16), (19, 19), (17, 17), (16, 16), (19, 19), (14, 14), (15, 15), (19, 19), (19, 19), (15, 15), (12, 12), (13, 13), (2, 2), (4, 4), (4, 4), (12, 12), (12, 12), (12, 12), (12, 12), (8, 8), (6, 6), (5, 5), (3, 3), (10, 10), (9, 9), (5, 5), (13, 13), (11, 11), (10, 10), (11, 11), (4, 4), (4, 4), (3, 3), (16, 16), (15, 15), (9, 9), (4, 4), (3, 3), (6, 6), (17, 17), (8, 8), (7, 7), (16, 16), (12, 12), (32, 32), (34, 34), (7, 7), (8, 8), (9, 9), (9, 9), (7, 7), (7, 7), (8, 8), (18, 18), (9, 9), (9, 9), (15, 15), (10, 10), (10, 10), (11, 11), (7, 7), (6, 6), (5, 5), (4, 4), (3, 3), (4, 4), (8, 8), (7, 7), (9, 9), (9, 9), (3, 3), (11, 11), (7, 7), (4, 4), (8, 8), (8, 8), (7, 7), (7, 7), (8, 8), (6, 6), (10, 10), (9, 9), (6, 6), (5, 5), (9, 9), (9, 9), (9, 9), (9, 9), (26, 26), (6, 6), (6, 6), (7, 7), (7, 7), (8, 8), (6, 6), (10, 10), (8, 8), (11, 11), (3, 3), (5, 5), (7, 7), (5, 5), (6, 6), (4, 4), (6, 6), (5, 5), (6, 6), (4, 4), (10, 10), (8, 8), (8, 8), (8, 8), (7, 7), (6, 6), (10, 10), (1, 1), (6, 6), (9, 9), (8, 8), (12, 12), (6, 6), (5, 5), (3, 3), (16, 16), (4, 4), (6, 6), (12, 12), (11, 11), (12, 12), (11, 11), (13, 13), (2, 2), (2, 2), (10, 10), (7, 7), (3, 3), (12, 12), (7, 7), (5, 5), (6, 6), (7, 7), (5, 5), (4, 4), (7, 7), (8, 8), (10, 10), (9, 9), (15, 15), (5, 5), (12, 12), (2, 2), (7, 7), (22, 22), (22, 22), (8, 8), (8, 8), (8, 8), (8, 8), (13, 13), (8, 8), (5, 5), (7, 7), (8, 8), (20, 20), (6, 6), (4, 4), (7, 7), (5, 5), (6, 6), (6, 6), (7, 7), (5, 5), (6, 6), (4, 4), (4, 4), (9, 9), (8, 8), (5, 5), (11, 11), (7, 7), (6, 6), (7, 7), (8, 8), (9, 9), (3, 3), (4, 4), (5, 5), (3, 3), (2, 2), (5, 5), (8, 8), (10, 10), (11, 11), (36, 36), (4, 4), (5, 5), (13, 13), (10, 10), (10, 10), (9, 9), (7, 7), (9, 9), (12, 12), (11, 11), (4, 4), (4, 4), (7, 7), (10, 10), (6, 6), (5, 5), (6, 6), (7, 7), (4, 4), (10, 10), (8, 8), (11, 11), (10, 10), (7, 7), (6, 6), (7, 7), (6, 6), (7, 7), (7, 7), (5, 5), (5, 5), (5, 5), (8, 8), (9, 9), (9, 9), (10, 10), (5, 5), (5, 5), (7, 7), (10, 10), (11, 11), (11, 11), (10, 10), (5, 5), (8, 8), (4, 4), (4, 4), (7, 7), (6, 6), (5, 5), (6, 6), (4, 4), (3, 3), (9, 9), (9, 9), (4, 4), (8, 8), (8, 8), (2, 2), (3, 3), (7, 7), (10, 10), (10, 10), (13, 13), (11, 11), (8, 8), (7, 7), (7, 7), (11, 11), (18, 18), (9, 9), (9, 9), (10, 10), (5, 5), (11, 11), (7, 7), (3, 3), (7, 7), (11, 11), (5, 5), (10, 10), (5, 5), (6, 6), (11, 11), (7, 7), (11, 11), (5, 5), (10, 10), (10, 10), (9, 9), (7, 7), (4, 4), (17, 17), (8, 8), (12, 12), (13, 13), (15, 15), (18, 18), (16, 16), (19, 19), (8, 8), (9, 9), (7, 7), (13, 13), (14, 14), (9, 9), (8, 8), (8, 8), (8, 8), (8, 8), (4, 4), (4, 4), (8, 8), (4, 4), (5, 5), (4, 4), (9, 9), (17, 17), (3, 3), (8, 8), (12, 12), (10, 10), (10, 10), (4, 4), (10, 10), (9, 9), (9, 9), (9, 9), (8, 8), (7, 7), (7, 7), (9, 9), (10, 10), (10, 10), (8, 8), (9, 9), (8, 8), (9, 9), (9, 9), (10, 10), (10, 10), (6, 6), (8, 8), (7, 7), (8, 8), (9, 9), (8, 8), (9, 9), (5, 5), (6, 6), (8, 8), (8, 8), (9, 9), (10, 10), (8, 8), (9, 9), (8, 8), (9, 9), (8, 8), (8, 8), (9, 9), (8, 8), (9, 9), (9, 9), (11, 11), (10, 10), (8, 8), (5, 5), (8, 8), (7, 7), (8, 8), (10, 10), (10, 10), (9, 9), (10, 10), (8, 8), (9, 9), (11, 11), (11, 11), (11, 11), (7, 7), (7, 7), (9, 9), (10, 10), (10, 10), (6, 6), (7, 7), (7, 7), (9, 9), (8, 8), (9, 9), (9, 9), (10, 10), (7, 7), (8, 8), (9, 9), (8, 8), (8, 8), (10, 10), (8, 8), (9, 9), (7, 7), (11, 11), (9, 9), (10, 10), (8, 8), (17, 17), (8, 8), (4, 4), (13, 13), (5, 5), (8, 8), (7, 7), (8, 8), (6, 6), (11, 11), (10, 10), (9, 9), (8, 8), (9, 9), (11, 11), (8, 8), (10, 10), (8, 8), (11, 11), (5, 5), (7, 7), (6, 6), (18, 18), (17, 17), (19, 19), (19, 19), (8, 8), (10, 10), (7, 7), (5, 5), (8, 8), (6, 6), (9, 9), (11, 11), (7, 7), (4, 4), (9, 9), (6, 6), (10, 10), (3, 3), (5, 5), (7, 7), (10, 10), (4, 4), (7, 7), (4, 4), (5, 5), (1, 1), (7, 7), (13, 13), (13, 13), (11, 11), (17, 17), (10, 10), (12, 12), (10, 10), (5, 5), (4, 4), (5, 5), (3, 3), (6, 6), (6, 6), (5, 5), (9, 9), (10, 10), (13, 13), (13, 13), (13, 13), (5, 5), (2, 2), (2, 2), (2, 2), (22, 22), (6, 6), (6, 6), (11, 11), (5, 5), (6, 6), (9, 9), (8, 8), (6, 6), (12, 12), (6, 6), (9, 9), (4, 4), (9, 9), (3, 3), (6, 6), (12, 12), (10, 10), (5, 5), (9, 9), (11, 11), (8, 8), (4, 4), (8, 8), (4, 4), (6, 6), (7, 7), (11, 11), (7, 7), (9, 9), (7, 7), (10, 10), (21, 21)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This  code focuses on analyzing the properties of a single graph rather than analyzing properties for all graphs in the dataset. It retrieves the first graph, calculates the number of vertices and edges, and computes the shape of the adjacency matrix."
      ],
      "metadata": {
        "id": "bIMnj7jBkuqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the train, validation, and test datasets\n",
        "train_set = DGLDatasetClass(address=path_data_temp + \"_train\")\n",
        "val_set = DGLDatasetClass(address=path_data_temp + \"_val\")\n",
        "test_set = DGLDatasetClass(address=path_data_temp + \"_test\")\n",
        "\n",
        "# Concatenate the datasets\n",
        "dataset = torch.utils.data.ConcatDataset([train_set, val_set, test_set])\n",
        "\n",
        "# Get the first graph in the dataset\n",
        "graph = dataset[0][0]\n",
        "\n",
        "# Get the number of vertices, edges, and graphs\n",
        "num_vertices = graph.number_of_nodes()\n",
        "num_edges = graph.number_of_edges()\n",
        "num_graphs = len(dataset)\n",
        "\n",
        "print(\"Number of vertices:\", num_vertices)\n",
        "print(\"Number of edges:\", num_edges)\n",
        "print(\"Number of graphs:\", num_graphs)\n",
        "\n",
        "# Get the adjacency matrix shape\n",
        "adj_matrix = graph.adjacency_matrix()\n",
        "adj_shape = adj_matrix.shape\n",
        "\n",
        "print(\"Adjacency matrix shape:\", adj_shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgPsW3ln_Ajl",
        "outputId": "03536a99-ace3-4a90-f834-aebc71e1409a"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of vertices: 8\n",
            "Number of edges: 14\n",
            "Number of graphs: 2039\n",
            "Adjacency matrix shape: (8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code snippet, the cumulative counts of vertices and edges are calculated for all graphs in the dataset. Additionally, the shape of the adjacency matrix is determined"
      ],
      "metadata": {
        "id": "t99l4lv5liiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the train, validation, and test datasets\n",
        "train_set = DGLDatasetClass(address=path_data_temp + \"_train\")\n",
        "val_set = DGLDatasetClass(address=path_data_temp + \"_val\")\n",
        "test_set = DGLDatasetClass(address=path_data_temp + \"_test\")\n",
        "\n",
        "# Concatenate the datasets\n",
        "dataset = torch.utils.data.ConcatDataset([train_set, val_set, test_set])\n",
        "\n",
        "# Get the total number of graphs\n",
        "num_graphs = len(dataset)\n",
        "\n",
        "# Initialize variables to store cumulative counts\n",
        "total_vertices = 0\n",
        "total_edges = 0\n",
        "adj_shape = None\n",
        "\n",
        "# Iterate over all graphs in the dataset\n",
        "for i in range(num_graphs):\n",
        "    graph = dataset[i][0]  # Get the graph\n",
        "    num_vertices = graph.number_of_nodes()  # Get the number of vertices\n",
        "    num_edges = graph.number_of_edges()  # Get the number of edges\n",
        "\n",
        "    # Update cumulative counts\n",
        "    total_vertices += num_vertices\n",
        "    total_edges += num_edges\n",
        "\n",
        "    if adj_shape is None:\n",
        "        adj_matrix = graph.adjacency_matrix()  # Get the adjacency matrix\n",
        "        adj_shape = adj_matrix.shape  # Get the shape of the adjacency matrix\n",
        "\n",
        "# Print the results\n",
        "print(\"Number of vertices:\", total_vertices)\n",
        "print(\"Number of edges:\", total_edges)\n",
        "print(\"Adjacency matrix shape:\", adj_shape)\n",
        "print(\"Number of graphs:\", num_graphs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCDLSodQBrxa",
        "outputId": "bcc9781c-1a6b-4fe4-c6f7-2ee0d8c62b67"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of vertices: 16420\n",
            "Number of edges: 30238\n",
            "Adjacency matrix shape: (8, 8)\n",
            "Number of graphs: 2039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code snippet, the focus is on a single dataset rather than concatenating multiple datasets.\n",
        "The code focuses on a single dataset and extracts information from the first graph in that dataset, including the number of vertices, edges, and the shape of the adjacency matrix. The results are then printed."
      ],
      "metadata": {
        "id": "usoIGskumcN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataset\n",
        "dataset = DGLDatasetClass(address=path_data_temp + \"_train\")\n",
        "\n",
        "# Get the first graph in the dataset\n",
        "graph = dataset[0][0]\n",
        "\n",
        "# Get the number of vertices, edges, and graphs\n",
        "num_vertices = graph.number_of_nodes()\n",
        "num_edges = graph.number_of_edges()\n",
        "num_graphs = len(dataset)\n",
        "\n",
        "print(\"Number of vertices:\", num_vertices)\n",
        "print(\"Number of edges:\", num_edges)\n",
        "print(\"Number of graphs:\", num_graphs)\n",
        "\n",
        "# Get the adjacency matrix shape\n",
        "adj_matrix = graph.adjacency_matrix()\n",
        "adj_shape = adj_matrix.shape\n",
        "\n",
        "print(\"Adjacency matrix shape:\", adj_shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyMOkRsq2LbZ",
        "outputId": "f0a8b145-8274-47f4-aa10-475dd1717b12"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of vertices: 8\n",
            "Number of edges: 14\n",
            "Number of graphs: 1631\n",
            "Adjacency matrix shape: (8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataset\n",
        "dataset = DGLDatasetClass(address=path_data_temp + \"_val\")\n",
        "\n",
        "# Get the first graph in the dataset\n",
        "graph = dataset[0][0]\n",
        "\n",
        "# Get the number of vertices, edges, and graphs\n",
        "num_vertices = graph.number_of_nodes()\n",
        "num_edges = graph.number_of_edges()\n",
        "num_graphs = len(dataset)\n",
        "\n",
        "print(\"Number of vertices:\", num_vertices)\n",
        "print(\"Number of edges:\", num_edges)\n",
        "print(\"Number of graphs:\", num_graphs)\n",
        "\n",
        "# Get the adjacency matrix shape\n",
        "adj_matrix = graph.adjacency_matrix()\n",
        "adj_shape = adj_matrix.shape\n",
        "\n",
        "print(\"Adjacency matrix shape:\", adj_shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a12c401a-f22e-4b93-b43a-560516acc0d4",
        "id": "euvO0T4c4Zpv"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of vertices: 11\n",
            "Number of edges: 20\n",
            "Number of graphs: 203\n",
            "Adjacency matrix shape: (11, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By loading the DGL dataset, accessing the first graph, and retrieving information such as the number of vertices, edges, and the shape of the adjacency matrix, the code provides insights into the structure of the graph stored in the dataset."
      ],
      "metadata": {
        "id": "6jcHYgcepuUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataset\n",
        "dataset = DGLDatasetClass(address=path_data_temp + \"_test\")\n",
        "\n",
        "# Get the first graph in the dataset\n",
        "graph = dataset[0][0]\n",
        "\n",
        "# Get the number of vertices, edges, and graphs\n",
        "num_vertices = graph.number_of_nodes()\n",
        "num_edges = graph.number_of_edges()\n",
        "num_graphs = len(dataset)\n",
        "\n",
        "print(\"Number of vertices:\", num_vertices)\n",
        "print(\"Number of edges:\", num_edges)\n",
        "print(\"Number of graphs:\", num_graphs)\n",
        "\n",
        "# Get the adjacency matrix shape\n",
        "adj_matrix = graph.adjacency_matrix()\n",
        "adj_shape = adj_matrix.shape\n",
        "\n",
        "print(\"Adjacency matrix shape:\", adj_shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08d3f3a-80a3-40ff-da03-d4a20e74587b",
        "id": "hoRqOmj64hZu"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of vertices: 8\n",
            "Number of edges: 14\n",
            "Number of graphs: 205\n",
            "Adjacency matrix shape: (8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code accesses the global features from the train, validation, and test sets and prints them. Here's how it works:\n",
        "\n",
        "1. `train_globals = [globals for _, _, _, globals in train_set]`: This line retrieves the global features from the train set and assigns them to the `train_globals` list. Each global feature corresponds to a molecule in the train set.\n",
        "2. `val_globals = [globals for _, _, _, globals in val_set]`: This line retrieves the global features from the validation set and assigns them to the `val_globals` list. Each global feature corresponds to a molecule in the validation set.\n",
        "3. `test_globals = [globals for _, _, _, globals in test_set]`: This line retrieves the global features from the test set and assigns them to the `test_globals` list. Each global feature corresponds to a molecule in the test set.\n",
        "\n",
        "4. The following lines print the global features:\n",
        "   - `print(\"Global Features for Train Set:\")`: Prints a header indicating the train set global features are being displayed.\n",
        "   - `for i, globals in enumerate(train_globals):`: Iterates over the train_globals list.\n",
        "     - `print(f\"Molecule {i+1}: {globals}\")`: Prints the global features for each molecule in the train set.\n",
        "   - `print()`: Prints an empty line for separation.\n",
        "   - `print(\"Global Features for Validation Set:\")`: Prints a header indicating the validation set global features are being displayed.\n",
        "   - `for i, globals in enumerate(val_globals):`: Iterates over the val_globals list.\n",
        "     - `print(f\"Molecule {i+1}: {globals}\")`: Prints the global features for each molecule in the validation set.\n",
        "   - `print()`: Prints an empty line for separation.\n",
        "   - `print(\"Global Features for Test Set:\")`: Prints a header indicating the test set global features are being displayed.\n",
        "   - `for i, globals in enumerate(test_globals):`: Iterates over the test_globals list.\n",
        "     - `print(f\"Molecule {i+1}: {globals}\")`: Prints the global features for each molecule in the test set.\n",
        "\n",
        "By accessing the global features using the tuple unpacking syntax (`for _, _, _, globals in ...`), the code retrieves and displays the global features for each molecule in the train, validation, and test sets."
      ],
      "metadata": {
        "id": "f2PI574dn7Du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the global features\n",
        "train_globals = [globals for _, _, _, globals in train_set]\n",
        "val_globals = [globals for _, _, _, globals in val_set]\n",
        "test_globals = [globals for _, _, _, globals in test_set]\n",
        "\n",
        "# Print the global features\n",
        "print(\"Global Features for Train Set:\")\n",
        "for i, globals in enumerate(train_globals):\n",
        "    print(f\"Molecule {i+1}: {globals}\")\n",
        "print()\n",
        "\n",
        "print(\"Global Features for Validation Set:\")\n",
        "for i, globals in enumerate(val_globals):\n",
        "    print(f\"Molecule {i+1}: {globals}\")\n",
        "print()\n",
        "\n",
        "print(\"Global Features for Test Set:\")\n",
        "for i, globals in enumerate(test_globals):\n",
        "    print(f\"Molecule {i+1}: {globals}\")\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9L_ua4syivN",
        "outputId": "e15696b0-6616-4953-d8bc-3f3f623c9456"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        1.6663e-01, 4.4802e-01])\n",
            "Molecule 59: tensor([2.6808e-01, 4.7353e-01, 8.0538e-01, 8.4260e-01, 8.2146e-01, 7.4952e-01,\n",
            "        8.6490e-01, 8.2449e-01, 9.2169e-01, 8.8927e-01, 9.6814e-01, 9.5265e-01,\n",
            "        9.7655e-01, 9.6591e-01, 9.2343e-01, 8.9984e-01, 6.8936e-07, 9.5752e-01,\n",
            "        8.1364e-01, 4.6245e-01, 9.2584e-11, 5.4760e-01, 6.5828e-01, 2.2144e-01,\n",
            "        3.4911e-01, 7.6285e-01, 7.2636e-01, 6.4321e-01, 6.1096e-01, 9.5991e-01,\n",
            "        8.1504e-01, 7.7515e-01, 7.3211e-01, 1.0000e+00, 8.2715e-01, 6.2646e-01,\n",
            "        4.8585e-01, 7.8158e-01, 7.1258e-01, 5.2736e-01, 7.1258e-01, 8.1447e-01,\n",
            "        1.7704e-02, 8.1864e-01, 1.0918e-01, 4.6122e-01, 2.7139e-01, 7.4463e-01,\n",
            "        7.6618e-01, 7.0728e-01, 6.9483e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 8.2272e-01, 7.3166e-01, 4.9077e-01,\n",
            "        5.6952e-08, 5.8913e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 8.6508e-01,\n",
            "        6.0286e-01, 4.5831e-01, 9.9618e-01, 8.3941e-01, 1.7356e-22, 8.9828e-01,\n",
            "        9.2251e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 6.7541e-01, 9.3918e-01,\n",
            "        3.8409e-01, 4.9815e-01, 6.1441e-01, 8.9647e-01, 3.9730e-01, 1.6710e-01,\n",
            "        1.9057e-01, 9.9937e-01, 9.1683e-01, 7.4637e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 8.7833e-01,\n",
            "        7.6148e-01, 9.8787e-01, 8.9660e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.9398e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.4782e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 4.2493e-01])\n",
            "Molecule 60: tensor([1.3012e-02, 7.3973e-01, 9.7136e-01, 9.7981e-01, 9.7836e-01, 9.6751e-01,\n",
            "        9.8601e-01, 9.8308e-01, 9.8700e-01, 9.8181e-01, 9.9167e-01, 9.8800e-01,\n",
            "        9.9245e-01, 9.8957e-01, 9.4905e-01, 9.4223e-01, 6.8936e-07, 9.8557e-01,\n",
            "        1.5575e-01, 7.9284e-01, 9.9573e-01, 5.4760e-01, 5.4557e-01, 4.3175e-01,\n",
            "        5.7634e-01, 9.6765e-01, 7.3009e-02, 6.1271e-02, 7.2556e-02, 9.8115e-01,\n",
            "        6.6798e-01, 9.6831e-01, 9.6018e-01, 1.0000e+00, 9.8113e-01, 9.7998e-01,\n",
            "        9.1774e-01, 9.7241e-01, 7.6519e-01, 5.1657e-01, 7.6519e-01, 8.7308e-01,\n",
            "        7.1287e-02, 8.8203e-01, 1.0135e-01, 4.7183e-01, 9.9041e-01, 9.7140e-01,\n",
            "        9.7042e-01, 7.0728e-01, 8.0633e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 9.1034e-01, 7.3166e-01, 6.2081e-01,\n",
            "        5.6952e-08, 9.8881e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 9.8570e-01,\n",
            "        7.7674e-01, 4.5831e-01, 9.9830e-01, 8.3941e-01, 1.7356e-22, 9.6111e-01,\n",
            "        8.1960e-01, 6.3417e-01, 4.6098e-10, 1.5707e-01, 9.9920e-01, 8.9315e-01,\n",
            "        5.3105e-01, 2.2068e-01, 6.1441e-01, 9.3350e-01, 5.8173e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.9549e-01, 4.5231e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 7.9980e-01,\n",
            "        9.0501e-01, 9.8787e-01, 9.9933e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.8976e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.0491e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 9.4294e-01, 9.8352e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.0000e+00, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 1.0000e+00,\n",
            "        1.6663e-01, 1.4268e-02])\n",
            "Molecule 61: tensor([3.0742e-01, 4.7701e-01, 7.8619e-01, 8.2882e-01, 8.0573e-01, 6.8953e-01,\n",
            "        8.3646e-01, 7.8915e-01, 9.5334e-01, 9.3386e-01, 9.5751e-01, 9.3669e-01,\n",
            "        9.7381e-01, 9.6175e-01, 9.2343e-01, 8.9984e-01, 6.8936e-07, 9.8050e-01,\n",
            "        5.4804e-01, 4.6245e-01, 9.2584e-11, 5.4760e-01, 6.6689e-01, 2.2144e-01,\n",
            "        3.4911e-01, 7.2590e-01, 7.3741e-01, 6.3838e-01, 5.9110e-01, 9.5991e-01,\n",
            "        8.2450e-01, 7.4282e-01, 6.9132e-01, 1.0000e+00, 7.9610e-01, 4.6967e-01,\n",
            "        4.8928e-01, 7.5029e-01, 6.9765e-01, 5.3391e-01, 6.9765e-01, 7.6872e-01,\n",
            "        1.4502e-02, 7.6798e-01, 1.0972e-01, 4.5479e-01, 5.3604e-01, 7.0901e-01,\n",
            "        7.2847e-01, 7.0728e-01, 5.0000e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 6.7960e-01, 7.3166e-01, 3.4646e-01,\n",
            "        5.6952e-08, 2.1430e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 8.3614e-01,\n",
            "        6.0286e-01, 4.5831e-01, 9.9618e-01, 8.3941e-01, 1.7356e-22, 8.9828e-01,\n",
            "        8.1960e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 7.5164e-01, 8.8387e-01,\n",
            "        3.8409e-01, 4.9325e-01, 6.1441e-01, 8.9647e-01, 3.9730e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9955e-01, 9.4784e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 6.6539e-01,\n",
            "        7.6148e-01, 9.9019e-01, 9.4780e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.7412e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.4974e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.4667e-01])\n",
            "Molecule 62: tensor([5.6779e-01, 2.9389e-01, 5.1464e-01, 6.5422e-01, 6.1056e-01, 4.2428e-01,\n",
            "        7.1431e-01, 6.4530e-01, 8.8840e-01, 8.4328e-01, 9.6561e-01, 9.4884e-01,\n",
            "        9.7804e-01, 9.6816e-01, 6.1012e-01, 7.0447e-01, 6.8936e-07, 8.7702e-01,\n",
            "        8.6235e-01, 4.8101e-01, 6.2889e-01, 5.4760e-01, 4.7787e-01, 8.0815e-01,\n",
            "        7.5225e-13, 4.2304e-01, 8.5773e-01, 7.8800e-01, 7.3200e-01, 9.6375e-01,\n",
            "        9.2123e-01, 4.7032e-01, 3.6843e-01, 1.0000e+00, 5.0944e-01, 1.7783e-01,\n",
            "        2.9270e-01, 4.9645e-01, 6.3709e-01, 2.4512e-01, 6.3709e-01, 1.2549e-01,\n",
            "        4.2461e-01, 1.0935e-01, 4.8058e-01, 7.4208e-01, 7.6149e-01, 4.9999e-01,\n",
            "        4.1896e-01, 4.3608e-01, 1.2405e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 1.6844e-01, 4.7447e-01, 3.3458e-02,\n",
            "        5.6952e-08, 5.2057e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 5.4216e-01,\n",
            "        1.3143e-01, 4.6822e-01, 9.8503e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 7.5164e-01, 8.7895e-01,\n",
            "        5.3105e-01, 2.2068e-01, 6.1441e-01, 5.8544e-01, 2.3495e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9968e-01, 9.2067e-01, 3.0449e-02, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 2.4391e-01,\n",
            "        4.6290e-01, 9.9200e-01, 9.2733e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 2.3404e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 9.5694e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.0797e-01])\n",
            "Molecule 63: tensor([6.4821e-01, 4.6465e-01, 7.2080e-01, 7.4181e-01, 7.5693e-01, 6.1469e-01,\n",
            "        7.3681e-01, 7.8534e-01, 8.8316e-01, 8.8193e-01, 9.5351e-01, 9.5092e-01,\n",
            "        9.7478e-01, 9.7660e-01, 9.3216e-01, 8.2282e-01, 1.0000e+00, 8.9571e-01,\n",
            "        5.4804e-01, 4.3833e-01, 8.5516e-01, 6.8522e-01, 5.5287e-01, 2.3915e-11,\n",
            "        3.4911e-01, 7.0405e-01, 8.5095e-01, 7.3912e-01, 5.9888e-01, 9.4404e-01,\n",
            "        8.8687e-01, 6.6622e-01, 6.8833e-01, 1.0000e+00, 7.2834e-01, 3.3570e-01,\n",
            "        3.4188e-01, 6.8945e-01, 9.6845e-01, 4.7938e-01, 9.6845e-01, 7.5702e-01,\n",
            "        9.3911e-02, 7.5494e-01, 8.7015e-02, 5.0842e-01, 6.0085e-01, 6.3063e-01,\n",
            "        7.0629e-01, 4.3608e-01, 3.0517e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 6.7960e-01, 4.7447e-01, 4.9077e-01,\n",
            "        5.6952e-08, 5.2057e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 7.5824e-01,\n",
            "        3.4705e-01, 5.7614e-21, 9.9791e-01, 8.2143e-01, 1.7356e-22, 8.9828e-01,\n",
            "        8.1960e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 6.4999e-01, 8.3166e-01,\n",
            "        7.0876e-01, 2.2068e-01, 6.1441e-01, 8.9201e-01, 7.3008e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.1456e-01, 2.1696e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.8575e-01, 6.5924e-01,\n",
            "        7.6148e-01, 9.8787e-01, 8.5739e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.9509e-01, 5.3014e-05, 9.1542e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.3033e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.7943e-01])\n",
            "Molecule 64: tensor([5.8697e-01, 2.6716e-01, 5.0634e-01, 6.0269e-01, 6.8389e-01, 4.3446e-01,\n",
            "        6.5121e-01, 8.0008e-01, 8.1583e-01, 9.2518e-01, 9.3657e-01, 9.8332e-01,\n",
            "        9.6429e-01, 9.9059e-01, 8.4435e-01, 5.2530e-01, 1.0000e+00, 8.6243e-01,\n",
            "        1.5575e-01, 7.8467e-01, 6.4433e-01, 5.4760e-01, 6.5252e-01, 5.8741e-01,\n",
            "        7.5225e-13, 5.7585e-01, 8.5773e-01, 8.3669e-01, 7.8364e-01, 9.7202e-01,\n",
            "        9.8193e-01, 4.7032e-01, 5.4646e-01, 1.0000e+00, 5.7370e-01, 2.4043e-01,\n",
            "        3.0576e-01, 5.6377e-01, 9.6653e-01, 2.3727e-01, 9.6653e-01, 1.2550e-01,\n",
            "        3.3035e-01, 1.0935e-01, 1.0443e-01, 7.5006e-01, 8.6848e-01, 5.9104e-01,\n",
            "        5.7533e-01, 4.3608e-01, 7.9832e-02, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 3.0707e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 1.1745e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 5.6470e-01,\n",
            "        1.3143e-01, 5.7614e-21, 9.9558e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1226e-01, 6.1316e-01, 4.6098e-10, 1.0000e+00, 4.8573e-01, 9.6170e-01,\n",
            "        2.4365e-01, 3.9646e-01, 6.1441e-01, 5.6307e-01, 7.4638e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9901e-01, 9.0809e-01, 4.1468e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.9425e-01, 5.5534e-01,\n",
            "        2.4530e-01, 9.8407e-01, 8.5379e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.6383e-02, 5.3014e-05, 9.8586e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.9999e-01, 5.3014e-05, 9.9865e-01, 9.2542e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.9039e-01])\n",
            "Molecule 65: tensor([6.1202e-01, 3.3506e-01, 5.7774e-01, 5.8653e-01, 6.0229e-01, 4.7004e-01,\n",
            "        6.4470e-01, 6.2390e-01, 8.5877e-01, 8.4487e-01, 9.4429e-01, 9.3435e-01,\n",
            "        9.6970e-01, 9.6713e-01, 9.2222e-01, 9.0333e-01, 6.8936e-07, 9.8181e-01,\n",
            "        3.5595e-01, 1.4801e-01, 9.2584e-11, 5.4760e-01, 5.9683e-01, 2.2144e-01,\n",
            "        6.5065e-01, 5.6863e-01, 9.1306e-01, 8.3509e-01, 7.4914e-01, 9.5378e-01,\n",
            "        9.4242e-01, 5.2333e-01, 5.4772e-01, 1.0000e+00, 5.8964e-01, 2.2323e-01,\n",
            "        3.0126e-01, 5.6066e-01, 4.3308e-01, 2.4511e-01, 4.3308e-01, 1.5162e-01,\n",
            "        3.2122e-01, 1.3558e-01, 1.0553e-01, 7.4209e-01, 1.9490e-01, 4.8121e-01,\n",
            "        5.6908e-01, 8.4234e-01, 3.0517e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 4.9226e-01, 8.5589e-01, 3.4646e-01,\n",
            "        5.6952e-08, 5.2057e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 6.0867e-01,\n",
            "        6.1929e-01, 7.3202e-01, 9.9566e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 9.0550e-08, 4.6098e-10, 1.0000e+00, 5.8667e-01, 6.9689e-01,\n",
            "        5.0808e-01, 2.2068e-01, 6.1441e-01, 8.6154e-01, 5.7075e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9957e-01, 8.5896e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.8549e-01, 7.2105e-01,\n",
            "        4.6290e-01, 9.9037e-01, 7.2889e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.3111e-01, 5.3014e-05, 9.9536e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.0459e-01, 2.0287e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.1801e-01])\n",
            "Molecule 66: tensor([5.9256e-01, 6.0220e-01, 8.6204e-01, 8.7176e-01, 8.7831e-01, 8.0089e-01,\n",
            "        8.7809e-01, 8.6147e-01, 9.2933e-01, 9.2237e-01, 9.6953e-01, 9.7090e-01,\n",
            "        9.7994e-01, 9.7842e-01, 9.4736e-01, 8.9623e-01, 6.8936e-07, 9.8557e-01,\n",
            "        5.4804e-01, 1.4801e-01, 6.4433e-01, 6.9603e-01, 6.3547e-01, 2.3915e-11,\n",
            "        8.5199e-01, 8.5060e-01, 5.9240e-01, 4.4975e-01, 3.9408e-01, 9.4725e-01,\n",
            "        7.7331e-01, 8.2881e-01, 8.4049e-01, 1.0000e+00, 8.7380e-01, 6.3813e-01,\n",
            "        4.4833e-01, 8.4798e-01, 8.4036e-01, 5.3370e-01, 8.4036e-01, 7.6788e-01,\n",
            "        4.4238e-01, 7.6705e-01, 1.1638e-01, 4.5499e-01, 6.7272e-01, 7.9644e-01,\n",
            "        8.5581e-01, 4.3608e-01, 6.9483e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 8.2272e-01, 4.7447e-01, 6.2081e-01,\n",
            "        5.6952e-08, 4.6631e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 9.0167e-01,\n",
            "        5.8601e-01, 5.7614e-21, 9.9812e-01, 8.3941e-01, 1.7356e-22, 9.6111e-01,\n",
            "        9.2106e-01, 9.0550e-08, 4.6098e-10, 1.0000e+00, 7.5164e-01, 7.0754e-01,\n",
            "        7.0876e-01, 4.3011e-01, 6.1441e-01, 9.1765e-01, 8.5528e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.5577e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.8549e-01, 7.3462e-01,\n",
            "        9.0501e-01, 9.8787e-01, 9.4780e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.0974e-01, 5.3014e-05, 9.9617e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.4517e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 9.4294e-01, 9.8352e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.0000e+00, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 2.4802e-01])\n",
            "Molecule 67: tensor([6.1795e-01, 6.1529e-01, 8.6628e-01, 8.7649e-01, 8.6030e-01, 7.9133e-01,\n",
            "        8.6973e-01, 8.3057e-01, 9.4273e-01, 9.1883e-01, 9.6836e-01, 9.5299e-01,\n",
            "        9.7930e-01, 9.7006e-01, 9.6121e-01, 8.9623e-01, 1.0000e+00, 5.9915e-01,\n",
            "        6.8321e-01, 2.5099e-11, 8.5516e-01, 8.6048e-01, 4.7787e-01, 2.3915e-11,\n",
            "        5.7634e-01, 8.2506e-01, 7.5470e-01, 6.0150e-01, 4.7321e-01, 9.4725e-01,\n",
            "        6.5725e-01, 8.2881e-01, 8.1014e-01, 1.0000e+00, 8.6584e-01, 5.7579e-01,\n",
            "        4.3722e-01, 8.2428e-01, 9.7050e-01, 5.3509e-01, 9.7050e-01, 7.7829e-01,\n",
            "        5.6036e-01, 7.7864e-01, 8.2248e-02, 4.5363e-01, 5.6964e-01, 7.5785e-01,\n",
            "        8.2935e-01, 4.3608e-01, 6.9483e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 8.2272e-01, 4.7447e-01, 6.2081e-01,\n",
            "        5.6952e-08, 3.3567e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 9.0167e-01,\n",
            "        5.8601e-01, 5.7614e-21, 9.9889e-01, 8.3941e-01, 1.7356e-22, 9.6111e-01,\n",
            "        9.2106e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 6.7541e-01, 7.2806e-01,\n",
            "        7.0876e-01, 4.7310e-01, 6.1441e-01, 9.3165e-01, 5.8173e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9957e-01, 9.4739e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 7.4310e-01,\n",
            "        9.0501e-01, 9.9037e-01, 9.2918e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.0974e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.4943e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 9.4294e-01, 9.8352e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.0000e+00, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 4.5815e-01])\n",
            "Molecule 68: tensor([5.4777e-01, 4.6055e-01, 7.2080e-01, 7.2655e-01, 6.9031e-01, 6.0880e-01,\n",
            "        7.4153e-01, 6.7633e-01, 8.9050e-01, 8.4616e-01, 9.5540e-01, 9.3353e-01,\n",
            "        9.7188e-01, 9.5883e-01, 9.5334e-01, 8.9984e-01, 1.0000e+00, 5.9915e-01,\n",
            "        6.8321e-01, 2.5099e-11, 8.5516e-01, 7.9111e-01, 1.0887e-06, 2.3915e-11,\n",
            "        3.4911e-01, 6.5675e-01, 8.5095e-01, 7.3912e-01, 6.5004e-01, 9.4404e-01,\n",
            "        8.0770e-01, 6.6622e-01, 6.3541e-01, 1.0000e+00, 7.0993e-01, 3.0593e-01,\n",
            "        3.4590e-01, 6.5090e-01, 9.6723e-01, 5.3545e-01, 9.6723e-01, 7.5459e-01,\n",
            "        4.9875e-01, 7.5222e-01, 8.4630e-02, 4.5327e-01, 2.7465e-01, 5.4848e-01,\n",
            "        6.5761e-01, 7.0728e-01, 5.0000e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 6.7960e-01, 7.3166e-01, 4.9077e-01,\n",
            "        5.6952e-08, 1.1745e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 7.5824e-01,\n",
            "        6.0286e-01, 4.5831e-01, 9.9813e-01, 8.3941e-01, 1.7356e-22, 8.9828e-01,\n",
            "        8.1960e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 4.8573e-01, 8.2708e-01,\n",
            "        5.4413e-01, 2.2068e-01, 6.1441e-01, 9.1752e-01, 3.9730e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.1456e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 7.3388e-01,\n",
            "        7.6148e-01, 9.8787e-01, 8.5739e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.7412e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1873e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.0830e-01])\n",
            "Molecule 69: tensor([5.9256e-01, 6.0220e-01, 8.6204e-01, 8.7176e-01, 8.5488e-01, 8.0089e-01,\n",
            "        8.7809e-01, 8.4114e-01, 9.2933e-01, 8.9997e-01, 9.6953e-01, 9.5475e-01,\n",
            "        9.7994e-01, 9.7102e-01, 9.5765e-01, 8.9623e-01, 1.0000e+00, 9.1886e-01,\n",
            "        6.8321e-01, 2.5099e-11, 7.7320e-01, 8.6048e-01, 4.7787e-01, 2.3915e-11,\n",
            "        5.7634e-01, 8.2506e-01, 5.9240e-01, 4.4975e-01, 3.9408e-01, 9.4725e-01,\n",
            "        6.5725e-01, 8.2881e-01, 8.1014e-01, 1.0000e+00, 8.6584e-01, 6.1367e-01,\n",
            "        4.3722e-01, 8.2428e-01, 9.7037e-01, 5.3370e-01, 9.7037e-01, 7.6788e-01,\n",
            "        2.7276e-01, 7.6705e-01, 8.2508e-02, 4.5499e-01, 6.0664e-01, 7.5846e-01,\n",
            "        8.2935e-01, 4.3608e-01, 6.9483e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 8.2272e-01, 4.7447e-01, 6.2081e-01,\n",
            "        5.6952e-08, 4.6631e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 9.0167e-01,\n",
            "        5.8601e-01, 5.7614e-21, 9.9889e-01, 8.3941e-01, 1.7356e-22, 9.6111e-01,\n",
            "        9.2106e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 6.7541e-01, 7.2806e-01,\n",
            "        8.3086e-01, 2.2068e-01, 6.1441e-01, 9.3165e-01, 5.8173e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.5693e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 7.4310e-01,\n",
            "        9.0501e-01, 9.8787e-01, 9.4780e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.0974e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.4124e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 9.4294e-01, 9.8352e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.0000e+00, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 4.2600e-01])\n",
            "Molecule 70: tensor([6.2711e-01, 3.5411e-01, 5.8140e-01, 5.8512e-01, 6.0091e-01, 4.6575e-01,\n",
            "        6.3983e-01, 6.3098e-01, 8.5456e-01, 8.1933e-01, 9.4820e-01, 9.3204e-01,\n",
            "        9.6877e-01, 9.5955e-01, 9.3185e-01, 8.2878e-01, 1.0000e+00, 9.0616e-01,\n",
            "        5.4804e-01, 1.4801e-01, 7.7320e-01, 5.6654e-01, 5.5287e-01, 2.3915e-11,\n",
            "        6.5065e-01, 5.7582e-01, 9.1306e-01, 8.3509e-01, 7.4914e-01, 9.5378e-01,\n",
            "        9.3976e-01, 5.2333e-01, 5.5945e-01, 1.0000e+00, 5.8775e-01, 1.9033e-01,\n",
            "        2.7214e-01, 5.5518e-01, 9.6592e-01, 2.3727e-01, 9.6592e-01, 1.2849e-01,\n",
            "        1.0699e-01, 1.1233e-01, 8.7788e-02, 7.5006e-01, 4.3117e-01, 4.6650e-01,\n",
            "        5.7640e-01, 7.0728e-01, 1.9367e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 3.0707e-01, 7.3166e-01, 3.4646e-01,\n",
            "        5.6952e-08, 5.2057e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 6.0867e-01,\n",
            "        3.6613e-01, 4.5831e-01, 9.9795e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 6.1316e-01, 4.6098e-10, 1.0000e+00, 4.8573e-01, 8.2708e-01,\n",
            "        3.8409e-01, 4.7157e-01, 6.1441e-01, 8.5371e-01, 5.7075e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 8.9012e-01, 2.0367e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.8549e-01, 6.5144e-01,\n",
            "        4.6290e-01, 9.8787e-01, 7.9991e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.1986e-01, 5.3014e-05, 9.9338e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1069e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9997e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.4836e-01])\n",
            "Molecule 71: tensor([6.3846e-01, 4.8111e-01, 7.5545e-01, 7.6347e-01, 7.7441e-01, 6.6443e-01,\n",
            "        7.8686e-01, 7.7585e-01, 8.9740e-01, 8.7096e-01, 9.6029e-01, 9.4773e-01,\n",
            "        9.7683e-01, 9.7003e-01, 9.3216e-01, 8.2282e-01, 1.0000e+00, 9.8403e-01,\n",
            "        6.8321e-01, 2.5099e-11, 7.7320e-01, 6.9603e-01, 5.5287e-01, 2.3915e-11,\n",
            "        7.7261e-01, 7.4599e-01, 8.7482e-01, 7.8800e-01, 6.6897e-01, 9.5020e-01,\n",
            "        8.7687e-01, 7.0653e-01, 7.3327e-01, 1.0000e+00, 7.6849e-01, 4.1017e-01,\n",
            "        3.4987e-01, 7.3213e-01, 9.6887e-01, 4.8405e-01, 9.6887e-01, 7.6787e-01,\n",
            "        1.9136e-01, 7.6704e-01, 8.5572e-02, 5.0382e-01, 6.7655e-01, 6.5212e-01,\n",
            "        7.5012e-01, 4.3608e-01, 3.0517e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 4.9226e-01, 4.7447e-01, 4.9077e-01,\n",
            "        5.6952e-08, 2.1430e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 8.0080e-01,\n",
            "        3.4705e-01, 5.7614e-21, 9.9881e-01, 1.4598e-01, 1.7356e-22, 8.9828e-01,\n",
            "        8.1960e-01, 6.1316e-01, 4.6098e-10, 1.0000e+00, 5.8667e-01, 7.2806e-01,\n",
            "        6.9593e-01, 4.7157e-01, 6.1441e-01, 8.9201e-01, 7.4236e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.3197e-01, 2.0367e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.8549e-01, 6.6318e-01,\n",
            "        7.6148e-01, 9.8787e-01, 8.9660e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.9509e-01, 5.3014e-05, 9.9382e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.3333e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9997e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 3.5387e-01])\n",
            "Molecule 72: tensor([6.1566e-01, 5.4469e-01, 8.0112e-01, 7.5860e-01, 7.2618e-01, 6.7620e-01,\n",
            "        7.5344e-01, 6.9008e-01, 9.0206e-01, 8.6204e-01, 9.5559e-01, 9.3381e-01,\n",
            "        9.7225e-01, 9.5939e-01, 9.6901e-01, 8.9984e-01, 1.0000e+00, 4.5585e-01,\n",
            "        1.9674e-02, 6.0025e-01, 7.9756e-01, 4.0889e-01, 1.0887e-06, 2.3915e-11,\n",
            "        3.4911e-01, 7.5563e-01, 6.8122e-01, 4.7203e-01, 3.6750e-01, 9.4404e-01,\n",
            "        7.7049e-01, 7.4282e-01, 7.5062e-01, 1.0000e+00, 7.8861e-01, 3.3509e-01,\n",
            "        3.6961e-01, 7.0967e-01, 9.6733e-01, 5.3545e-01, 9.6733e-01, 7.5459e-01,\n",
            "        4.3855e-01, 7.5222e-01, 4.4468e-02, 4.5327e-01, 3.2709e-01, 5.5291e-01,\n",
            "        7.5873e-01, 7.0728e-01, 5.0000e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 6.7960e-01, 7.3166e-01, 7.2707e-01,\n",
            "        5.6952e-08, 1.1745e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 8.3614e-01,\n",
            "        6.0286e-01, 4.5831e-01, 9.9813e-01, 8.3941e-01, 9.7790e-01, 8.9828e-01,\n",
            "        8.1960e-01, 8.6609e-01, 4.6098e-10, 1.5707e-01, 3.9594e-01, 5.7070e-01,\n",
            "        7.2506e-01, 4.5257e-01, 6.1441e-01, 9.4157e-01, 3.9730e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.1302e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.9601e-01, 0.0000e+00, 9.7969e-13, 7.9145e-01,\n",
            "        7.6148e-01, 9.8787e-01, 8.0470e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.7412e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 8.9882e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.0000e+00, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.8713e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.3104e-01])\n",
            "Molecule 73: tensor([6.3767e-01, 6.0587e-01, 8.4687e-01, 8.3202e-01, 8.0938e-01, 7.5979e-01,\n",
            "        8.1864e-01, 7.6739e-01, 9.1738e-01, 8.8327e-01, 9.6057e-01, 9.4128e-01,\n",
            "        9.7864e-01, 9.6905e-01, 9.6684e-01, 8.9623e-01, 1.0000e+00, 8.1452e-01,\n",
            "        1.9674e-02, 4.9525e-01, 8.5516e-01, 5.8471e-01, 1.0887e-06, 2.3915e-11,\n",
            "        5.7634e-01, 8.0684e-01, 6.0096e-01, 4.4008e-01, 3.3731e-01, 9.3471e-01,\n",
            "        6.3159e-01, 8.0372e-01, 7.9981e-01, 1.0000e+00, 8.3891e-01, 4.9561e-01,\n",
            "        4.1708e-01, 7.8506e-01, 9.6948e-01, 5.3509e-01, 9.6948e-01, 7.5690e-01,\n",
            "        6.4871e-02, 7.5481e-01, 7.1782e-02, 4.5363e-01, 3.9178e-01, 6.6998e-01,\n",
            "        8.1086e-01, 4.3608e-01, 6.9483e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 8.2272e-01, 4.7447e-01, 7.2707e-01,\n",
            "        5.6952e-08, 2.1430e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 8.8128e-01,\n",
            "        5.8601e-01, 4.8885e-01, 9.9889e-01, 8.3941e-01, 1.7356e-22, 9.6111e-01,\n",
            "        9.2106e-01, 7.7898e-01, 4.6098e-10, 1.5707e-01, 3.9594e-01, 7.1084e-01,\n",
            "        8.4653e-01, 2.2068e-01, 6.1441e-01, 9.4163e-01, 5.8173e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.3258e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.9203e-01, 0.0000e+00, 9.7969e-13, 8.0085e-01,\n",
            "        9.0501e-01, 9.8787e-01, 8.6090e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.0974e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.2689e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 9.4294e-01, 9.8352e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9997e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.0000e+00, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.0446e-01])\n",
            "Molecule 74: tensor([5.8739e-01, 6.0628e-01, 8.6204e-01, 8.5194e-01, 8.3215e-01, 7.9815e-01,\n",
            "        8.5740e-01, 8.1509e-01, 9.2158e-01, 8.8912e-01, 9.6163e-01, 9.4287e-01,\n",
            "        9.7485e-01, 9.6333e-01, 9.6427e-01, 8.9623e-01, 1.0000e+00, 9.6910e-01,\n",
            "        1.5575e-01, 3.3660e-01, 8.5516e-01, 5.8471e-01, 1.0887e-06, 2.3915e-11,\n",
            "        5.7634e-01, 8.3180e-01, 7.5470e-01, 6.5202e-01, 5.5903e-01, 9.4145e-01,\n",
            "        6.3159e-01, 8.2881e-01, 8.2366e-01, 1.0000e+00, 8.6424e-01, 6.0880e-01,\n",
            "        4.5289e-01, 8.1492e-01, 9.6942e-01, 5.3509e-01, 9.6942e-01, 7.6884e-01,\n",
            "        1.0500e-01, 7.6812e-01, 7.2199e-02, 4.5363e-01, 5.2943e-01, 7.1909e-01,\n",
            "        8.3613e-01, 4.3608e-01, 6.9483e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 8.2272e-01, 4.7447e-01, 7.2707e-01,\n",
            "        5.6952e-08, 4.6631e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 9.0167e-01,\n",
            "        5.8601e-01, 4.8885e-01, 9.9889e-01, 8.3941e-01, 1.7356e-22, 9.6111e-01,\n",
            "        9.2106e-01, 7.7898e-01, 4.6098e-10, 1.5707e-01, 3.9594e-01, 8.9454e-01,\n",
            "        7.2122e-01, 2.2068e-01, 6.1441e-01, 9.4163e-01, 5.8173e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9901e-01, 9.5583e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.9203e-01, 0.0000e+00, 9.7969e-13, 8.0085e-01,\n",
            "        9.0501e-01, 9.8407e-01, 9.2543e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.0974e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1263e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 9.4294e-01, 9.8352e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9997e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.0000e+00, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 4.2466e-01])\n",
            "Molecule 75: tensor([6.2711e-01, 3.4800e-01, 5.8140e-01, 6.3514e-01, 5.8981e-01, 4.6575e-01,\n",
            "        6.7847e-01, 6.0526e-01, 8.8124e-01, 8.3354e-01, 9.6505e-01, 9.4801e-01,\n",
            "        9.7366e-01, 9.6154e-01, 9.3291e-01, 8.2878e-01, 1.0000e+00, 9.0489e-01,\n",
            "        5.4804e-01, 1.4801e-01, 7.7320e-01, 5.6654e-01, 6.0209e-01, 2.3915e-11,\n",
            "        7.5225e-13, 5.0140e-01, 8.4555e-01, 7.3356e-01, 6.4096e-01, 9.5921e-01,\n",
            "        9.0747e-01, 5.2333e-01, 4.6455e-01, 1.0000e+00, 5.6917e-01, 1.7335e-01,\n",
            "        2.6431e-01, 5.2012e-01, 9.6652e-01, 2.3728e-01, 9.6652e-01, 1.2550e-01,\n",
            "        3.3747e-02, 1.0935e-01, 9.2421e-02, 7.5006e-01, 4.3851e-01, 4.5973e-01,\n",
            "        4.9863e-01, 7.0728e-01, 1.9367e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 3.0707e-01, 7.3166e-01, 2.0751e-01,\n",
            "        5.6952e-08, 5.2057e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 6.0867e-01,\n",
            "        3.6613e-01, 5.1115e-01, 9.9795e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 5.8667e-01, 8.8860e-01,\n",
            "        3.8409e-01, 2.2068e-01, 6.1441e-01, 8.5371e-01, 2.3495e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9955e-01, 8.9532e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 5.7851e-01,\n",
            "        4.6290e-01, 9.9019e-01, 8.5739e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.1986e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.3384e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.7550e-01])\n",
            "Molecule 76: tensor([6.4022e-01, 3.3240e-01, 5.3065e-01, 5.7797e-01, 5.2844e-01, 4.0575e-01,\n",
            "        6.2468e-01, 5.4680e-01, 8.5452e-01, 7.9758e-01, 9.4793e-01, 9.2238e-01,\n",
            "        9.6977e-01, 9.5563e-01, 9.2041e-01, 8.2878e-01, 1.0000e+00, 9.0489e-01,\n",
            "        5.4804e-01, 1.4801e-01, 8.5516e-01, 5.6654e-01, 5.5287e-01, 2.3915e-11,\n",
            "        7.5225e-13, 4.4661e-01, 8.5773e-01, 7.3142e-01, 6.1789e-01, 9.5378e-01,\n",
            "        9.0747e-01, 4.7032e-01, 4.1426e-01, 1.0000e+00, 5.0181e-01, 1.2240e-01,\n",
            "        2.5453e-01, 4.6147e-01, 9.6532e-01, 2.3727e-01, 9.6532e-01, 1.2550e-01,\n",
            "        2.4280e-01, 1.0935e-01, 8.9690e-02, 7.5006e-01, 3.7663e-01, 3.9467e-01,\n",
            "        4.4280e-01, 7.0728e-01, 1.9367e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 3.0707e-01, 7.3166e-01, 2.0751e-01,\n",
            "        5.6952e-08, 1.6146e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 5.4216e-01,\n",
            "        3.6613e-01, 4.5831e-01, 9.9795e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 4.8573e-01, 9.0173e-01,\n",
            "        3.8409e-01, 2.2068e-01, 6.1441e-01, 8.5371e-01, 2.3495e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.1456e-01, 3.0449e-02, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 5.6206e-01,\n",
            "        4.6290e-01, 9.8787e-01, 8.5739e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.1986e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.3068e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.3846e-01])\n",
            "Molecule 77: tensor([6.5613e-01, 3.8606e-01, 6.3930e-01, 6.1116e-01, 5.6391e-01, 5.1089e-01,\n",
            "        6.5332e-01, 5.7769e-01, 8.6203e-01, 8.0761e-01, 9.4846e-01, 9.2318e-01,\n",
            "        9.6899e-01, 9.5445e-01, 9.6122e-01, 9.0333e-01, 1.0000e+00, 8.1452e-01,\n",
            "        1.9674e-02, 1.6119e-01, 8.5516e-01, 5.8471e-01, 1.0887e-06, 2.3915e-11,\n",
            "        7.5225e-13, 5.7591e-01, 8.3347e-01, 6.7747e-01, 5.5297e-01, 9.5378e-01,\n",
            "        8.9160e-01, 5.7417e-01, 5.5768e-01, 1.0000e+00, 6.2455e-01, 1.9773e-01,\n",
            "        2.8608e-01, 5.4335e-01, 9.6574e-01, 2.3727e-01, 9.6574e-01, 1.5162e-01,\n",
            "        2.6153e-01, 1.3558e-01, 7.4489e-02, 7.5006e-01, 1.6885e-01, 4.1873e-01,\n",
            "        5.7473e-01, 8.4234e-01, 3.0517e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 4.9226e-01, 8.5589e-01, 4.9077e-01,\n",
            "        5.6952e-08, 5.2057e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 6.7047e-01,\n",
            "        6.1929e-01, 8.6862e-01, 9.9795e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 7.7898e-01, 4.6098e-10, 1.5707e-01, 3.9594e-01, 8.1511e-01,\n",
            "        3.8409e-01, 2.2068e-01, 6.1441e-01, 9.1738e-01, 2.3495e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 8.8910e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.9203e-01, 0.0000e+00, 9.7969e-13, 7.8609e-01,\n",
            "        4.6290e-01, 9.8787e-01, 7.2889e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.3111e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.7758e-01, 2.0287e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9997e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.8104e-01])\n",
            "Molecule 78: tensor([5.0481e-01, 5.8331e-01, 8.5308e-01, 8.5488e-01, 8.3552e-01, 7.4566e-01,\n",
            "        8.4167e-01, 7.9557e-01, 9.5477e-01, 9.3589e-01, 9.6588e-01, 9.4926e-01,\n",
            "        9.7461e-01, 9.6297e-01, 9.6661e-01, 8.9984e-01, 1.0000e+00, 8.1452e-01,\n",
            "        1.9674e-02, 1.6119e-01, 8.5516e-01, 8.6749e-01, 1.0887e-06, 2.3915e-11,\n",
            "        3.4911e-01, 8.0691e-01, 7.1569e-01, 4.9066e-01, 3.7309e-01, 9.5991e-01,\n",
            "        7.8970e-01, 8.0372e-01, 7.9123e-01, 1.0000e+00, 8.5189e-01, 4.5549e-01,\n",
            "        4.2354e-01, 7.9435e-01, 9.6854e-01, 5.3128e-01, 9.6854e-01, 7.8618e-01,\n",
            "        1.7528e-01, 7.8740e-01, 7.2873e-02, 4.5737e-01, 5.0874e-01, 7.1461e-01,\n",
            "        8.1094e-01, 7.0728e-01, 5.0000e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 6.7960e-01, 7.3166e-01, 6.2081e-01,\n",
            "        5.6952e-08, 1.1745e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 8.8857e-01,\n",
            "        6.0286e-01, 7.1872e-01, 9.9813e-01, 8.3941e-01, 1.7356e-22, 8.9828e-01,\n",
            "        8.1960e-01, 7.7898e-01, 4.6098e-10, 1.5707e-01, 3.9594e-01, 9.6785e-01,\n",
            "        3.8409e-01, 4.5257e-01, 6.1441e-01, 9.3156e-01, 3.9730e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9955e-01, 9.4694e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.9203e-01, 0.0000e+00, 9.7969e-13, 7.9359e-01,\n",
            "        7.6148e-01, 9.9019e-01, 9.0173e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.7412e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.4849e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9997e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 4.7959e-01])\n",
            "Molecule 79: tensor([6.5613e-01, 3.8812e-01, 6.3930e-01, 5.6519e-01, 5.1488e-01, 5.1089e-01,\n",
            "        6.1341e-01, 5.3478e-01, 8.3633e-01, 7.7352e-01, 9.3741e-01, 9.0678e-01,\n",
            "        9.6001e-01, 9.4078e-01, 9.6132e-01, 9.4626e-01, 1.0000e+00, 8.1452e-01,\n",
            "        1.9674e-02, 3.1588e-01, 8.6260e-01, 5.8561e-17, 1.0887e-06, 2.3915e-11,\n",
            "        7.5225e-13, 5.8297e-01, 7.2818e-01, 5.5198e-01, 4.4779e-01, 9.4725e-01,\n",
            "        8.8526e-01, 5.7417e-01, 5.7308e-01, 1.0000e+00, 6.2217e-01, 1.9531e-01,\n",
            "        2.8499e-01, 5.2935e-01, 9.6485e-01, 2.3727e-01, 9.6485e-01, 1.5747e-01,\n",
            "        1.4933e-01, 1.4152e-01, 6.9888e-02, 7.5006e-01, 5.7152e-02, 3.7393e-01,\n",
            "        5.8193e-01, 9.0949e-01, 5.0000e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 6.7960e-01, 9.1805e-01, 6.2081e-01,\n",
            "        5.6952e-08, 5.2057e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 6.7047e-01,\n",
            "        7.9669e-01, 7.4860e-01, 9.9881e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 7.7898e-01, 4.6098e-10, 1.5707e-01, 2.7397e-01, 7.1084e-01,\n",
            "        3.8409e-01, 4.8060e-01, 6.1441e-01, 9.3333e-01, 2.3495e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9901e-01, 8.8570e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.9203e-01, 0.0000e+00, 9.7969e-13, 8.6583e-01,\n",
            "        4.6290e-01, 9.8407e-01, 6.2958e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.4783e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 7.5337e-01, 2.0287e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9997e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 3.9519e-01])\n",
            "Molecule 80: tensor([4.2307e-01, 4.2645e-01, 7.4279e-01, 7.8196e-01, 7.5251e-01, 6.7513e-01,\n",
            "        8.2217e-01, 7.7167e-01, 9.1419e-01, 8.7883e-01, 9.5486e-01, 9.3273e-01,\n",
            "        9.7707e-01, 9.6668e-01, 9.3330e-01, 8.2282e-01, 1.0000e+00, 9.8487e-01,\n",
            "        6.8321e-01, 1.7021e-01, 7.7320e-01, 3.8158e-01, 6.3964e-01, 2.3915e-11,\n",
            "        3.4911e-01, 6.9289e-01, 8.4017e-01, 7.8800e-01, 7.6167e-01, 9.5544e-01,\n",
            "        8.1744e-01, 7.0653e-01, 6.6259e-01, 1.0000e+00, 7.5673e-01, 5.1736e-01,\n",
            "        4.3913e-01, 7.0707e-01, 9.4025e-01, 5.5149e-01, 9.4025e-01, 9.2063e-01,\n",
            "        1.3513e-01, 9.3112e-01, 1.5130e-01, 4.3751e-01, 6.4898e-01, 6.4576e-01,\n",
            "        6.9467e-01, 4.3608e-01, 3.0517e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 4.9226e-01, 4.7447e-01, 3.4646e-01,\n",
            "        5.6952e-08, 3.3567e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 8.0080e-01,\n",
            "        3.4705e-01, 4.8885e-01, 9.8503e-01, 8.3941e-01, 1.7356e-22, 8.9828e-01,\n",
            "        6.1801e-01, 7.8931e-01, 4.6098e-10, 1.5707e-01, 6.8542e-01, 9.2405e-01,\n",
            "        3.9866e-01, 5.0060e-01, 6.1441e-01, 8.9201e-01, 3.9730e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9968e-01, 9.1851e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 6.0007e-01,\n",
            "        7.6148e-01, 9.9213e-01, 8.9660e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.9509e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.4167e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 9.6071e-01,\n",
            "        1.6663e-01, 2.2233e-01])\n",
            "Molecule 81: tensor([5.6317e-01, 2.8788e-01, 5.1072e-01, 5.5504e-01, 5.0416e-01, 4.2860e-01,\n",
            "        6.3336e-01, 5.5610e-01, 8.5360e-01, 7.9636e-01, 9.3395e-01, 9.0167e-01,\n",
            "        9.7300e-01, 9.6053e-01, 9.0875e-01, 8.2878e-01, 1.0000e+00, 9.9300e-01,\n",
            "        3.2886e-01, 1.7021e-01, 7.7320e-01, 3.8158e-01, 6.0209e-01, 2.3915e-11,\n",
            "        7.5225e-13, 4.4661e-01, 8.9420e-01, 8.3669e-01, 7.8364e-01, 9.5378e-01,\n",
            "        9.0747e-01, 4.7032e-01, 4.1426e-01, 1.0000e+00, 5.0181e-01, 2.0204e-01,\n",
            "        3.2234e-01, 4.6147e-01, 9.3417e-01, 2.4512e-01, 9.3417e-01, 1.2570e-01,\n",
            "        3.0097e-01, 1.0955e-01, 1.5927e-01, 7.4208e-01, 3.1045e-01, 3.9300e-01,\n",
            "        4.4280e-01, 7.0728e-01, 1.9367e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 3.0707e-01, 7.3166e-01, 2.0751e-01,\n",
            "        5.6952e-08, 5.2057e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 5.4216e-01,\n",
            "        3.6613e-01, 7.4860e-01, 9.9566e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 5.0636e-01, 8.7024e-01,\n",
            "        3.9866e-01, 2.2068e-01, 6.1441e-01, 8.5371e-01, 2.3495e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9968e-01, 8.3082e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 5.8655e-01,\n",
            "        4.6290e-01, 9.9213e-01, 7.2889e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.1986e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1314e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.0509e-01])\n",
            "Molecule 82: tensor([6.5043e-01, 3.3240e-01, 5.3065e-01, 5.7797e-01, 5.2844e-01, 4.0463e-01,\n",
            "        6.2468e-01, 5.4680e-01, 8.5606e-01, 7.9963e-01, 9.4635e-01, 9.2003e-01,\n",
            "        9.6763e-01, 9.5237e-01, 9.2041e-01, 8.2878e-01, 1.0000e+00, 9.0489e-01,\n",
            "        5.4804e-01, 1.4801e-01, 8.5516e-01, 5.6654e-01, 5.5287e-01, 2.3915e-11,\n",
            "        7.5225e-13, 4.4661e-01, 8.5773e-01, 7.3142e-01, 6.1789e-01, 9.5378e-01,\n",
            "        9.0747e-01, 4.7032e-01, 4.1426e-01, 1.0000e+00, 5.0181e-01, 1.2240e-01,\n",
            "        2.6102e-01, 4.6147e-01, 9.6582e-01, 2.3727e-01, 9.6582e-01, 1.2552e-01,\n",
            "        1.1488e-02, 1.0937e-01, 8.9386e-02, 7.5006e-01, 3.7663e-01, 3.9467e-01,\n",
            "        4.4280e-01, 7.0728e-01, 1.9367e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 3.0707e-01, 7.3166e-01, 2.0751e-01,\n",
            "        5.6952e-08, 1.6146e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 5.4216e-01,\n",
            "        3.6613e-01, 4.5831e-01, 9.9795e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 4.8573e-01, 9.0173e-01,\n",
            "        3.8409e-01, 2.2068e-01, 6.1441e-01, 8.5371e-01, 2.3495e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.1456e-01, 3.0449e-02, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 5.6206e-01,\n",
            "        4.6290e-01, 9.8787e-01, 8.5739e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.1986e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.3212e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.3846e-01])\n",
            "Molecule 83: tensor([5.2208e-01, 4.6055e-01, 7.2080e-01, 7.2655e-01, 6.9031e-01, 6.0782e-01,\n",
            "        7.4519e-01, 6.8055e-01, 8.8604e-01, 8.4007e-01, 9.5198e-01, 9.2842e-01,\n",
            "        9.6908e-01, 9.5458e-01, 9.4760e-01, 8.9984e-01, 1.0000e+00, 8.0744e-01,\n",
            "        6.8321e-01, 2.5099e-11, 9.0520e-01, 6.9603e-01, 1.0887e-06, 2.3915e-11,\n",
            "        3.4911e-01, 6.5675e-01, 8.0979e-01, 6.8522e-01, 5.9888e-01, 9.4404e-01,\n",
            "        8.0770e-01, 6.6622e-01, 6.3541e-01, 1.0000e+00, 7.0993e-01, 3.0593e-01,\n",
            "        3.5395e-01, 6.5090e-01, 9.6673e-01, 5.1441e-01, 9.6673e-01, 7.5564e-01,\n",
            "        4.9043e-01, 7.5340e-01, 8.4925e-02, 4.7395e-01, 3.0443e-01, 5.4912e-01,\n",
            "        6.5761e-01, 7.0728e-01, 5.0000e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 6.7960e-01, 7.3166e-01, 4.9077e-01,\n",
            "        5.6952e-08, 1.1745e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 7.5824e-01,\n",
            "        6.0286e-01, 4.5831e-01, 9.9802e-01, 8.3941e-01, 1.7356e-22, 8.9828e-01,\n",
            "        8.1960e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 3.7305e-01, 9.0578e-01,\n",
            "        5.4413e-01, 2.2068e-01, 6.1441e-01, 9.1752e-01, 3.9730e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9901e-01, 9.4496e-01, 3.0449e-02, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 7.2836e-01,\n",
            "        7.6148e-01, 9.8407e-01, 8.9660e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.7412e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.2173e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.0900e-01])\n",
            "Molecule 84: tensor([5.7198e-01, 3.0471e-01, 5.1464e-01, 5.1068e-01, 4.5780e-01, 4.2315e-01,\n",
            "        5.9199e-01, 5.1216e-01, 8.2331e-01, 7.5651e-01, 9.3076e-01, 8.9697e-01,\n",
            "        9.6211e-01, 9.4399e-01, 9.3381e-01, 9.0333e-01, 1.0000e+00, 9.8557e-01,\n",
            "        3.2886e-01, 2.5099e-11, 7.7320e-01, 5.6654e-01, 4.7787e-01, 2.3915e-11,\n",
            "        7.5225e-13, 4.5442e-01, 9.2217e-01, 8.7689e-01, 8.2963e-01, 9.4725e-01,\n",
            "        9.0196e-01, 4.7032e-01, 4.3099e-01, 1.0000e+00, 4.9903e-01, 1.6904e-01,\n",
            "        2.9601e-01, 4.4675e-01, 9.3200e-01, 2.4511e-01, 9.3200e-01, 1.5096e-01,\n",
            "        6.0651e-01, 1.3491e-01, 1.0411e-01, 7.4209e-01, 1.2743e-01, 3.4958e-01,\n",
            "        4.5071e-01, 8.4234e-01, 3.0517e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 4.9226e-01, 8.5589e-01, 3.4646e-01,\n",
            "        5.6952e-08, 5.2057e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 5.4216e-01,\n",
            "        6.1929e-01, 8.6862e-01, 9.9566e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 3.9594e-01, 8.0767e-01,\n",
            "        3.8409e-01, 2.2068e-01, 6.1441e-01, 8.9626e-01, 2.3495e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 8.6050e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 7.2994e-01,\n",
            "        4.6290e-01, 9.8787e-01, 7.2251e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.3111e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.3332e-01, 2.0287e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.3365e-01])\n",
            "Molecule 85: tensor([5.2312e-01, 4.6130e-01, 7.7722e-01, 7.9212e-01, 7.6401e-01, 7.1563e-01,\n",
            "        8.3167e-01, 7.8327e-01, 9.1015e-01, 8.7322e-01, 9.5891e-01, 9.3879e-01,\n",
            "        9.7615e-01, 9.6530e-01, 9.4216e-01, 8.9984e-01, 1.0000e+00, 9.9456e-01,\n",
            "        5.2461e-01, 1.7021e-01, 7.7320e-01, 3.8158e-01, 6.0209e-01, 2.3915e-11,\n",
            "        3.4911e-01, 7.3614e-01, 8.6505e-01, 8.2846e-01, 7.7464e-01, 9.5544e-01,\n",
            "        8.0770e-01, 7.4282e-01, 7.1226e-01, 1.0000e+00, 7.9364e-01, 5.4969e-01,\n",
            "        4.4474e-01, 7.3733e-01, 9.4192e-01, 4.8551e-01, 9.4192e-01, 7.6888e-01,\n",
            "        6.5597e-01, 7.6816e-01, 1.1873e-01, 5.0238e-01, 4.5805e-01, 6.6334e-01,\n",
            "        7.3890e-01, 7.0728e-01, 5.0000e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 6.7960e-01, 7.3166e-01, 4.9077e-01,\n",
            "        5.6952e-08, 4.6631e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 8.3614e-01,\n",
            "        6.0286e-01, 7.4860e-01, 9.9553e-01, 8.3941e-01, 1.7356e-22, 8.9828e-01,\n",
            "        8.1960e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 5.9820e-01, 8.8537e-01,\n",
            "        5.3105e-01, 2.2068e-01, 6.1441e-01, 9.1752e-01, 3.9730e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.4555e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 7.3929e-01,\n",
            "        7.6148e-01, 9.8787e-01, 9.2348e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.7412e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.0228e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 4.8695e-01])\n",
            "Molecule 86: tensor([6.7093e-01, 4.3839e-01, 6.9138e-01, 6.3484e-01, 6.4964e-01, 5.5471e-01,\n",
            "        6.6587e-01, 6.3810e-01, 8.6918e-01, 8.4619e-01, 9.5004e-01, 9.3619e-01,\n",
            "        9.7000e-01, 9.6275e-01, 9.6122e-01, 9.0333e-01, 1.0000e+00, 9.0548e-01,\n",
            "        1.9674e-02, 1.6119e-01, 7.8581e-01, 5.8471e-01, 1.0887e-06, 2.3915e-11,\n",
            "        6.5065e-01, 6.8682e-01, 8.6180e-01, 6.8148e-01, 5.2413e-01, 9.5378e-01,\n",
            "        9.2899e-01, 6.2199e-01, 6.8322e-01, 1.0000e+00, 6.9556e-01, 2.5011e-01,\n",
            "        2.9706e-01, 6.2977e-01, 9.6699e-01, 2.3727e-01, 9.6699e-01, 1.6813e-01,\n",
            "        2.3515e-01, 1.5239e-01, 7.0992e-02, 7.5006e-01, 2.6344e-01, 4.8684e-01,\n",
            "        6.8976e-01, 8.4234e-01, 3.0517e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 4.9226e-01, 8.5589e-01, 6.2081e-01,\n",
            "        5.6952e-08, 5.2057e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 7.2563e-01,\n",
            "        6.1929e-01, 8.6862e-01, 9.9795e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 7.7898e-01, 4.6098e-10, 1.5707e-01, 4.8499e-01, 8.1511e-01,\n",
            "        3.8409e-01, 4.3671e-01, 6.1441e-01, 9.1738e-01, 5.7075e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 8.8910e-01, 2.2942e-01, 1.0314e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.9203e-01, 0.0000e+00, 9.8549e-01, 7.8609e-01,\n",
            "        4.6290e-01, 9.8787e-01, 7.2889e-01, 1.6047e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.3111e-01, 5.3014e-05, 9.9384e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 8.7368e-01, 2.0287e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9997e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.8713e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.1834e-01])\n",
            "Molecule 87: tensor([6.0320e-01, 6.0220e-01, 8.6204e-01, 8.7176e-01, 8.7831e-01, 7.9873e-01,\n",
            "        8.7531e-01, 8.5839e-01, 9.3391e-01, 9.2724e-01, 9.6830e-01, 9.6979e-01,\n",
            "        9.8104e-01, 9.7959e-01, 9.4736e-01, 8.9623e-01, 6.8936e-07, 9.6263e-01,\n",
            "        7.0082e-01, 1.4801e-01, 7.8581e-01, 3.8158e-01, 6.6689e-01, 2.3915e-11,\n",
            "        8.5199e-01, 8.5060e-01, 7.5470e-01, 6.5202e-01, 5.5903e-01, 9.4725e-01,\n",
            "        7.7331e-01, 8.2881e-01, 8.4049e-01, 1.0000e+00, 8.7380e-01, 6.3813e-01,\n",
            "        4.5728e-01, 8.4798e-01, 8.3640e-01, 5.3509e-01, 8.3640e-01, 7.6888e-01,\n",
            "        4.4164e-01, 7.6817e-01, 1.1643e-01, 4.5363e-01, 6.7272e-01, 7.9644e-01,\n",
            "        8.5581e-01, 4.3608e-01, 6.9483e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 8.2272e-01, 4.7447e-01, 6.2081e-01,\n",
            "        5.6952e-08, 4.6631e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 9.0167e-01,\n",
            "        5.8601e-01, 5.7614e-21, 9.9812e-01, 8.3941e-01, 1.7356e-22, 9.6111e-01,\n",
            "        9.2106e-01, 9.0550e-08, 4.6098e-10, 1.0000e+00, 6.7541e-01, 8.2006e-01,\n",
            "        7.2122e-01, 4.3011e-01, 6.1441e-01, 9.1765e-01, 8.5528e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.5577e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.8549e-01, 7.3462e-01,\n",
            "        9.0501e-01, 9.8787e-01, 9.4780e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.0974e-01, 5.3014e-05, 9.9618e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.4363e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 9.4294e-01, 9.8352e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.0000e+00, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 2.4802e-01])\n",
            "Molecule 88: tensor([5.7198e-01, 2.9889e-01, 5.1464e-01, 5.6553e-01, 5.1524e-01, 4.2315e-01,\n",
            "        6.3835e-01, 5.6147e-01, 8.5427e-01, 7.9725e-01, 9.4249e-01, 9.1430e-01,\n",
            "        9.7061e-01, 9.5690e-01, 9.0813e-01, 9.0333e-01, 6.8936e-07, 9.5348e-01,\n",
            "        3.5595e-01, 4.6245e-01, 9.2584e-11, 5.4760e-01, 5.4557e-01, 4.3175e-01,\n",
            "        7.5225e-13, 4.3872e-01, 8.9420e-01, 8.3669e-01, 7.8364e-01, 9.5378e-01,\n",
            "        9.1143e-01, 4.7032e-01, 4.0169e-01, 1.0000e+00, 5.0389e-01, 1.7311e-01,\n",
            "        2.9812e-01, 4.6734e-01, 3.5042e-01, 2.4511e-01, 3.5042e-01, 1.5096e-01,\n",
            "        4.5612e-02, 1.3491e-01, 1.1417e-01, 7.4209e-01, 1.6338e-01, 4.0979e-01,\n",
            "        4.3481e-01, 8.4234e-01, 3.0517e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 4.9226e-01, 8.5589e-01, 2.0751e-01,\n",
            "        5.6952e-08, 5.2057e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 5.4216e-01,\n",
            "        6.1929e-01, 7.3202e-01, 9.9566e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 5.8667e-01, 8.1280e-01,\n",
            "        3.8409e-01, 2.2068e-01, 6.1441e-01, 8.6154e-01, 2.3495e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9957e-01, 8.6438e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 6.5370e-01,\n",
            "        4.6290e-01, 9.9037e-01, 7.9991e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.3111e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1242e-01, 2.0287e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.4750e-01])\n",
            "Molecule 89: tensor([4.8026e-01, 4.0569e-01, 6.6947e-01, 7.0748e-01, 6.6913e-01, 5.7051e-01,\n",
            "        7.3568e-01, 6.6962e-01, 8.8911e-01, 8.4426e-01, 9.5002e-01, 9.2550e-01,\n",
            "        9.7320e-01, 9.6083e-01, 9.3349e-01, 8.9984e-01, 6.8936e-07, 8.9993e-01,\n",
            "        5.4804e-01, 3.1199e-01, 6.6805e-01, 5.4760e-01, 5.4557e-01, 4.3175e-01,\n",
            "        3.4911e-01, 5.9722e-01, 8.6180e-01, 7.8800e-01, 7.3200e-01, 9.4404e-01,\n",
            "        8.2450e-01, 6.2199e-01, 5.6553e-01, 1.0000e+00, 6.6176e-01, 3.1199e-01,\n",
            "        3.6383e-01, 6.1846e-01, 5.7841e-01, 5.3545e-01, 5.7841e-01, 7.5459e-01,\n",
            "        3.9494e-02, 7.5222e-01, 1.1060e-01, 4.5327e-01, 2.5648e-01, 5.4378e-01,\n",
            "        5.9664e-01, 7.0728e-01, 5.0000e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 6.7960e-01, 7.3166e-01, 3.4646e-01,\n",
            "        5.6952e-08, 1.1745e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 7.0806e-01,\n",
            "        6.0286e-01, 4.5831e-01, 9.9618e-01, 8.3941e-01, 1.7356e-22, 8.9828e-01,\n",
            "        8.1960e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 5.8667e-01, 8.1280e-01,\n",
            "        5.4413e-01, 2.2068e-01, 6.1441e-01, 8.9647e-01, 3.9730e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9957e-01, 8.9506e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 6.6539e-01,\n",
            "        7.6148e-01, 9.9037e-01, 8.5739e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.7412e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.3141e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.4778e-01])\n",
            "Molecule 90: tensor([3.2218e-01, 5.3509e-01, 8.1137e-01, 8.0474e-01, 7.7831e-01, 7.3777e-01,\n",
            "        8.2687e-01, 7.7740e-01, 9.2038e-01, 8.8745e-01, 9.6143e-01, 9.4257e-01,\n",
            "        9.7695e-01, 9.6651e-01, 9.4191e-01, 9.4223e-01, 6.8936e-07, 9.9782e-01,\n",
            "        1.5575e-01, 3.1199e-01, 9.2584e-11, 5.4760e-01, 5.4557e-01, 4.3175e-01,\n",
            "        5.9031e-01, 7.6503e-01, 7.2636e-01, 6.4321e-01, 6.1096e-01, 9.3471e-01,\n",
            "        6.6798e-01, 7.7515e-01, 7.4809e-01, 1.0000e+00, 8.1195e-01, 5.4896e-01,\n",
            "        4.6920e-01, 7.6483e-01, 6.6961e-01, 7.3297e-01, 6.6961e-01, 7.6894e-01,\n",
            "        7.1027e-02, 7.6822e-01, 1.0077e-01, 2.5787e-01, 2.2786e-01, 6.8119e-01,\n",
            "        7.6838e-01, 8.4234e-01, 8.0633e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 8.2272e-01, 8.5589e-01, 6.2081e-01,\n",
            "        5.6952e-08, 4.6631e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 8.5609e-01,\n",
            "        7.8694e-01, 4.5831e-01, 9.9618e-01, 8.3941e-01, 1.7356e-22, 9.6111e-01,\n",
            "        9.2106e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 5.8667e-01, 8.1280e-01,\n",
            "        3.8409e-01, 7.0832e-01, 6.1441e-01, 9.3442e-01, 5.8173e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9957e-01, 9.1532e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 7.8695e-01,\n",
            "        8.4853e-01, 9.9037e-01, 8.9394e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 9.1655e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1103e-01, 2.0287e-02,\n",
            "        1.0000e+00, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.0000e+00, 1.0000e+00, 9.4294e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 3.5438e-01])\n",
            "Molecule 91: tensor([6.0046e-01, 3.3506e-01, 5.7774e-01, 5.8653e-01, 5.3754e-01, 4.7004e-01,\n",
            "        6.4593e-01, 5.6966e-01, 8.5876e-01, 8.0323e-01, 9.4411e-01, 9.1671e-01,\n",
            "        9.7130e-01, 9.5795e-01, 9.3381e-01, 9.0333e-01, 1.0000e+00, 9.8444e-01,\n",
            "        3.2886e-01, 2.5099e-11, 7.7320e-01, 6.9603e-01, 4.7787e-01, 2.3915e-11,\n",
            "        7.5225e-13, 5.0901e-01, 8.8347e-01, 7.8800e-01, 6.9648e-01, 9.5378e-01,\n",
            "        9.0196e-01, 5.2333e-01, 4.8110e-01, 1.0000e+00, 5.6658e-01, 1.9986e-01,\n",
            "        2.9077e-01, 5.0584e-01, 9.3524e-01, 2.4511e-01, 9.3524e-01, 1.5162e-01,\n",
            "        6.6312e-01, 1.3558e-01, 1.0107e-01, 7.4209e-01, 1.5652e-01, 4.1376e-01,\n",
            "        5.0636e-01, 8.4234e-01, 3.0517e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 4.9226e-01, 8.5589e-01, 3.4646e-01,\n",
            "        5.6952e-08, 5.2057e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 6.0867e-01,\n",
            "        6.1929e-01, 8.6862e-01, 9.9566e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 5.0636e-01, 7.9998e-01,\n",
            "        3.8409e-01, 2.2068e-01, 6.1441e-01, 8.9626e-01, 2.3495e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9957e-01, 8.6311e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 7.2994e-01,\n",
            "        4.6290e-01, 9.9037e-01, 7.2889e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.3111e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.9755e-01, 2.0287e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.1421e-01])\n",
            "Molecule 92: tensor([4.4185e-01, 3.7369e-01, 6.1478e-01, 6.4625e-01, 6.0187e-01, 5.2735e-01,\n",
            "        6.9218e-01, 6.2047e-01, 8.6020e-01, 8.0517e-01, 9.4066e-01, 9.1158e-01,\n",
            "        9.6541e-01, 9.4900e-01, 9.2343e-01, 8.9984e-01, 6.8936e-07, 8.9276e-01,\n",
            "        5.4804e-01, 4.6245e-01, 6.6805e-01, 5.4760e-01, 5.4557e-01, 2.2144e-01,\n",
            "        3.4911e-01, 5.4677e-01, 8.3347e-01, 7.8800e-01, 7.6465e-01, 9.3674e-01,\n",
            "        8.2450e-01, 5.7417e-01, 5.1800e-01, 1.0000e+00, 6.0335e-01, 2.7470e-01,\n",
            "        3.6323e-01, 5.6537e-01, 5.4917e-01, 5.3545e-01, 5.4917e-01, 7.5459e-01,\n",
            "        1.8183e-02, 7.5222e-01, 1.1151e-01, 4.5327e-01, 2.1225e-01, 4.8087e-01,\n",
            "        5.4498e-01, 7.0728e-01, 5.0000e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 6.7960e-01, 7.3166e-01, 3.4646e-01,\n",
            "        5.6952e-08, 1.1745e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 6.5053e-01,\n",
            "        6.0286e-01, 4.5831e-01, 9.9618e-01, 8.3941e-01, 1.7356e-22, 8.9828e-01,\n",
            "        8.1960e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 4.8573e-01, 8.2006e-01,\n",
            "        5.4413e-01, 2.2068e-01, 6.1441e-01, 8.9647e-01, 3.9730e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 8.9311e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 6.6539e-01,\n",
            "        7.6148e-01, 9.8787e-01, 8.5379e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.7412e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.9952e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.7580e-01])\n",
            "Molecule 93: tensor([1.9608e-05, 5.0959e-01, 7.7722e-01, 8.0880e-01, 8.6394e-01, 7.0656e-01,\n",
            "        7.9575e-01, 7.3985e-01, 8.9937e-01, 8.5833e-01, 9.5428e-01, 9.3186e-01,\n",
            "        9.7038e-01, 9.5655e-01, 9.5435e-01, 9.6815e-01, 6.8936e-07, 9.9960e-01,\n",
            "        1.5575e-01, 4.6245e-01, 9.2584e-11, 5.4760e-01, 5.4557e-01, 2.2144e-01,\n",
            "        3.4911e-01, 7.8261e-01, 7.2636e-01, 6.4321e-01, 6.1096e-01, 9.2683e-01,\n",
            "        9.0881e-01, 7.7515e-01, 7.7526e-01, 1.0000e+00, 8.7843e-01, 6.9846e-01,\n",
            "        5.3727e-01, 8.6000e-01, 6.4010e-01, 1.0000e+00, 6.4010e-01, 9.9999e-01,\n",
            "        3.2429e-10, 9.9699e-01, 1.0065e-01, 5.2840e-07, 5.8103e-03, 5.9651e-01,\n",
            "        7.8625e-01, 7.0728e-01, 8.0633e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 9.1034e-01, 7.3166e-01, 7.2707e-01,\n",
            "        5.6952e-08, 4.6631e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 8.2512e-01,\n",
            "        8.8338e-01, 4.5831e-01, 9.9618e-01, 8.3941e-01, 1.7356e-22, 9.9306e-01,\n",
            "        8.1960e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 4.8573e-01, 8.9315e-01,\n",
            "        5.2022e-01, 4.9325e-01, 6.1441e-01, 9.6895e-01, 5.8173e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.1378e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 9.8565e-01, 6.9527e-13, 0.0000e+00, 9.7969e-13, 7.3712e-01,\n",
            "        8.4853e-01, 9.8787e-01, 8.9122e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 9.2216e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.5097e-01, 2.0287e-02,\n",
            "        1.0000e+00, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.0000e+00, 1.0000e+00, 9.4294e-01, 9.8352e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 1.4579e-01])\n",
            "Molecule 94: tensor([4.8928e-01, 4.2233e-01, 7.3739e-01, 7.7987e-01, 7.5014e-01, 6.8233e-01,\n",
            "        8.2773e-01, 7.7845e-01, 9.0644e-01, 8.6809e-01, 9.5931e-01, 9.3939e-01,\n",
            "        9.7602e-01, 9.6511e-01, 9.2343e-01, 8.9984e-01, 6.8936e-07, 9.5675e-01,\n",
            "        5.4804e-01, 7.0465e-01, 9.2584e-11, 5.4760e-01, 5.9683e-01, 2.2144e-01,\n",
            "        3.4911e-01, 6.8711e-01, 7.9826e-01, 7.8800e-01, 7.6167e-01, 9.5544e-01,\n",
            "        8.2450e-01, 7.0653e-01, 6.5261e-01, 1.0000e+00, 7.5797e-01, 5.1980e-01,\n",
            "        4.1983e-01, 7.1119e-01, 6.6502e-01, 4.8551e-01, 6.6502e-01, 7.6888e-01,\n",
            "        1.0562e-02, 7.6816e-01, 1.3309e-01, 5.0238e-01, 4.7156e-01, 6.6018e-01,\n",
            "        6.8877e-01, 7.0728e-01, 5.0000e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 6.7960e-01, 7.3166e-01, 3.4646e-01,\n",
            "        5.6952e-08, 4.6631e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 8.0080e-01,\n",
            "        6.0286e-01, 5.1115e-01, 9.9553e-01, 8.3941e-01, 1.7356e-22, 8.9828e-01,\n",
            "        8.1960e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 6.6938e-01, 8.9315e-01,\n",
            "        5.3105e-01, 2.2068e-01, 6.1441e-01, 8.9647e-01, 3.9730e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.4602e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 6.6539e-01,\n",
            "        7.6148e-01, 9.8787e-01, 9.4501e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.7412e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1090e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.2185e-01])\n",
            "Molecule 95: tensor([6.6454e-01, 5.1775e-01, 7.9275e-01, 7.9263e-01, 8.0525e-01, 6.9919e-01,\n",
            "        7.9106e-01, 8.2844e-01, 8.9869e-01, 8.9696e-01, 9.5907e-01, 9.5656e-01,\n",
            "        9.7505e-01, 9.7683e-01, 9.5733e-01, 8.2282e-01, 1.0000e+00, 9.0656e-01,\n",
            "        1.5575e-01, 4.4963e-01, 7.7320e-01, 7.9320e-01, 4.7787e-01, 2.3915e-11,\n",
            "        3.4911e-01, 7.8262e-01, 8.2948e-01, 6.9198e-01, 5.4310e-01, 9.5020e-01,\n",
            "        8.7514e-01, 7.4282e-01, 7.7308e-01, 1.0000e+00, 8.0469e-01, 4.4818e-01,\n",
            "        3.7534e-01, 7.5560e-01, 9.6911e-01, 4.7816e-01, 9.6911e-01, 7.6799e-01,\n",
            "        3.6330e-01, 7.6717e-01, 7.5027e-02, 5.0961e-01, 6.8348e-01, 6.8635e-01,\n",
            "        7.8643e-01, 4.3608e-01, 3.0517e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 6.7960e-01, 4.7447e-01, 6.2081e-01,\n",
            "        5.6952e-08, 1.1745e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 8.3614e-01,\n",
            "        3.4705e-01, 4.8885e-01, 9.9791e-01, 8.2143e-01, 1.7356e-22, 8.9828e-01,\n",
            "        8.1960e-01, 7.7898e-01, 4.6098e-10, 1.5707e-01, 6.6658e-01, 8.1996e-01,\n",
            "        6.9593e-01, 2.2068e-01, 6.1441e-01, 9.1467e-01, 7.3008e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 9.3138e-01, 2.1696e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.9203e-01, 0.0000e+00, 9.8575e-01, 7.3438e-01,\n",
            "        7.6148e-01, 9.8787e-01, 8.5739e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.9509e-01, 5.3014e-05, 9.1008e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.2973e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9997e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.2127e-01])\n",
            "Molecule 96: tensor([6.2711e-01, 3.5411e-01, 5.8140e-01, 6.1162e-01, 6.3166e-01, 4.6575e-01,\n",
            "        6.3879e-01, 7.0648e-01, 8.5030e-01, 8.5046e-01, 9.4680e-01, 9.4440e-01,\n",
            "        9.6670e-01, 9.6886e-01, 9.2041e-01, 8.2878e-01, 1.0000e+00, 8.9571e-01,\n",
            "        5.4804e-01, 4.3833e-01, 7.7320e-01, 6.8522e-01, 5.5287e-01, 2.3915e-11,\n",
            "        7.5225e-13, 5.6866e-01, 8.8347e-01, 7.8800e-01, 6.9648e-01, 9.5378e-01,\n",
            "        9.4497e-01, 5.2333e-01, 5.4619e-01, 1.0000e+00, 5.9153e-01, 1.9397e-01,\n",
            "        2.7377e-01, 5.5360e-01, 9.6614e-01, 2.3727e-01, 9.6614e-01, 2.4683e-01,\n",
            "        2.0163e-01, 2.3412e-01, 8.9224e-02, 7.5006e-01, 4.5215e-01, 5.0579e-01,\n",
            "        5.6765e-01, 7.0728e-01, 1.9367e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 4.9226e-01, 7.3166e-01, 3.4646e-01,\n",
            "        5.6952e-08, 1.6146e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 6.0867e-01,\n",
            "        3.6613e-01, 4.5831e-01, 9.9558e-01, 8.2143e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 6.4999e-01, 8.9611e-01,\n",
            "        3.8409e-01, 2.2068e-01, 6.1441e-01, 8.5371e-01, 5.5423e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 8.9012e-01, 2.1696e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.8575e-01, 6.4738e-01,\n",
            "        4.6290e-01, 9.8787e-01, 7.9991e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.1986e-01, 5.3014e-05, 9.1421e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1250e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.6762e-01])\n",
            "Molecule 97: tensor([5.9153e-01, 5.7260e-01, 8.1902e-01, 7.9771e-01, 7.7034e-01, 7.2910e-01,\n",
            "        7.9056e-01, 7.3367e-01, 8.9945e-01, 8.5844e-01, 9.5354e-01, 9.3075e-01,\n",
            "        9.7003e-01, 9.5602e-01, 9.6131e-01, 9.4223e-01, 1.0000e+00, 8.1947e-01,\n",
            "        3.2886e-01, 3.5707e-01, 8.4726e-01, 5.8471e-01, 1.0887e-06, 2.3915e-11,\n",
            "        5.7634e-01, 7.7396e-01, 6.7069e-01, 5.3514e-01, 4.3029e-01, 9.2683e-01,\n",
            "        6.4269e-01, 7.7515e-01, 7.6571e-01, 1.0000e+00, 8.0967e-01, 4.6007e-01,\n",
            "        4.0028e-01, 7.5436e-01, 9.6869e-01, 5.4417e-01, 9.6869e-01, 7.5459e-01,\n",
            "        9.3760e-02, 7.5222e-01, 7.2909e-02, 4.4471e-01, 1.5789e-01, 6.3016e-01,\n",
            "        7.7745e-01, 7.0728e-01, 8.0633e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 9.1034e-01, 7.3166e-01, 7.2707e-01,\n",
            "        5.6952e-08, 2.1430e-01, 9.4955e-01, 1.1424e-21, 9.6593e-01, 8.5609e-01,\n",
            "        7.7674e-01, 4.8530e-01, 9.9889e-01, 8.3941e-01, 1.7356e-22, 9.6111e-01,\n",
            "        9.2106e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 3.7305e-01, 7.2806e-01,\n",
            "        7.3330e-01, 2.2068e-01, 6.1441e-01, 9.4299e-01, 5.8173e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9901e-01, 9.3121e-01, 2.2942e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 8.3850e-01,\n",
            "        9.0501e-01, 9.8407e-01, 8.5739e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.8976e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.9957e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 9.4294e-01, 9.8352e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.0000e+00, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 4.8309e-01])\n",
            "Molecule 98: tensor([6.5613e-01, 3.8984e-01, 6.3930e-01, 6.0556e-01, 6.2098e-01, 5.1089e-01,\n",
            "        6.4739e-01, 6.3833e-01, 8.6053e-01, 8.2644e-01, 9.4785e-01, 9.3160e-01,\n",
            "        9.6864e-01, 9.5938e-01, 9.5721e-01, 8.2878e-01, 1.0000e+00, 8.0127e-01,\n",
            "        1.5575e-01, 1.6119e-01, 8.5516e-01, 5.8471e-01, 1.0887e-06, 2.3915e-11,\n",
            "        6.5065e-01, 6.3743e-01, 8.7265e-01, 7.3555e-01, 6.0774e-01, 9.5378e-01,\n",
            "        9.3309e-01, 5.7417e-01, 6.2993e-01, 1.0000e+00, 6.4380e-01, 2.1835e-01,\n",
            "        2.9516e-01, 5.9085e-01, 9.6599e-01, 2.3727e-01, 9.6599e-01, 1.2849e-01,\n",
            "        3.5579e-01, 1.1233e-01, 7.5663e-02, 7.5006e-01, 4.1797e-01, 4.7045e-01,\n",
            "        6.3933e-01, 7.0728e-01, 1.9367e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 3.0707e-01, 7.3166e-01, 4.9077e-01,\n",
            "        5.6952e-08, 5.2057e-02, 9.4955e-01, 1.1424e-21, 9.6593e-01, 6.7047e-01,\n",
            "        3.6613e-01, 7.1872e-01, 9.9795e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 7.7898e-01, 4.6098e-10, 1.0000e+00, 3.9594e-01, 8.1511e-01,\n",
            "        3.8409e-01, 4.7157e-01, 6.1441e-01, 8.9179e-01, 5.7075e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9937e-01, 8.8910e-01, 2.0367e-01, 1.0946e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.9203e-01, 0.0000e+00, 9.8549e-01, 7.2812e-01,\n",
            "        4.6290e-01, 9.8787e-01, 7.2889e-01, 1.7166e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.1986e-01, 5.3014e-05, 9.9330e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.0248e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9998e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.0000e+00, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.8713e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.0925e-01])\n",
            "Molecule 99: tensor([4.1063e-02, 4.5786e-01, 7.1554e-01, 7.6222e-01, 7.3025e-01, 7.6137e-01,\n",
            "        8.1482e-01, 7.6276e-01, 7.7805e-01, 6.9873e-01, 8.1151e-01, 7.3096e-01,\n",
            "        8.0262e-01, 7.1441e-01, 4.0749e-10, 4.7375e-01, 6.8936e-07, 5.7790e-01,\n",
            "        1.9674e-02, 9.8052e-01, 9.2522e-01, 5.8561e-17, 6.5200e-01, 8.6199e-01,\n",
            "        7.5225e-13, 7.0146e-01, 2.0161e-02, 2.2320e-02, 2.5942e-02, 4.9776e-01,\n",
            "        4.9875e-01, 7.4282e-01, 6.7892e-01, 1.0000e+00, 7.5921e-01, 8.6574e-01,\n",
            "        7.9442e-01, 7.4785e-01, 7.5879e-01, 2.2288e-01, 7.5879e-01, 5.3464e-02,\n",
            "        6.5386e-01, 4.0964e-02, 6.2327e-01, 7.6472e-01, 9.1343e-01, 7.8640e-01,\n",
            "        7.0348e-01, 4.3608e-01, 1.2405e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        9.6401e-01, 4.8299e-15, 6.1776e-01, 1.6844e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 8.3334e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 7.8744e-01,\n",
            "        3.6632e-01, 7.1438e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1932e-01, 7.7898e-01, 4.6098e-10, 1.5707e-01, 7.1132e-01, 9.2618e-01,\n",
            "        9.6470e-01, 2.7501e-02, 6.1441e-01, 2.8290e-01, 1.3217e-01, 1.6710e-01,\n",
            "        4.0799e-01, 8.7862e-24, 3.8782e-01, 9.4582e-01, 9.4876e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.1443e-01, 9.9661e-01, 0.0000e+00, 9.7969e-13, 7.7311e-01,\n",
            "        1.2049e-11, 9.6753e-01, 5.7467e-01, 9.2923e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 2.0050e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.3606e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 9.6402e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 9.9991e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 2.7110e-01])\n",
            "Molecule 100: tensor([5.1739e-01, 3.0896e-01, 4.2762e-01, 5.7168e-01, 5.2176e-01, 4.9645e-01,\n",
            "        6.8804e-01, 6.1587e-01, 6.6056e-01, 5.5852e-01, 7.5791e-01, 6.6253e-01,\n",
            "        7.7031e-01, 6.7229e-01, 4.0749e-10, 2.4211e-01, 6.8936e-07, 2.1615e-01,\n",
            "        1.9674e-02, 9.4342e-01, 9.6461e-01, 5.4715e-01, 5.3771e-01, 6.4300e-01,\n",
            "        3.6353e-01, 4.1112e-01, 1.7621e-01, 2.0535e-01, 2.6416e-01, 7.6460e-01,\n",
            "        7.8703e-01, 4.7032e-01, 3.7262e-01, 1.0000e+00, 4.5880e-01, 5.4519e-01,\n",
            "        5.2640e-01, 4.8643e-01, 7.6955e-01, 1.6592e-01, 7.6955e-01, 5.8908e-02,\n",
            "        7.0629e-01, 4.5832e-02, 6.5540e-01, 8.2323e-01, 7.9710e-01, 5.5307e-01,\n",
            "        4.0683e-01, 6.1316e-02, 1.2405e-01, 9.9995e-01, 9.1873e-01, 9.3704e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 1.6844e-01, 5.5287e-02, 9.8237e-02,\n",
            "        5.6952e-08, 1.1745e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 4.9654e-01,\n",
            "        3.4481e-01, 7.1440e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 7.9395e-01, 4.6098e-10, 1.5707e-01, 5.7948e-01, 9.2746e-01,\n",
            "        7.6221e-01, 2.7501e-02, 6.1441e-01, 1.7613e-01, 1.3393e-01, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 7.7979e-01, 8.7436e-01, 3.6527e-01, 5.3014e-05,\n",
            "        7.3059e-01, 2.8678e-01, 9.9382e-01, 0.0000e+00, 9.7969e-13, 6.1655e-01,\n",
            "        5.8571e-01, 9.3864e-01, 7.7351e-01, 2.5614e-01, 2.9949e-06, 9.8604e-01,\n",
            "        5.3014e-05, 2.1264e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.9994e-01, 5.3014e-05, 9.9865e-01, 9.3762e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 7.1316e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.1776e-01])\n",
            "Molecule 101: tensor([1.5214e-01, 6.7883e-01, 7.8651e-01, 7.1968e-01, 8.1901e-01, 7.6602e-01,\n",
            "        6.4946e-01, 8.4415e-01, 6.6721e-01, 8.7048e-01, 5.8215e-01, 8.9602e-01,\n",
            "        5.5844e-01, 9.2189e-01, 8.8409e-01, 8.2282e-01, 6.8936e-07, 5.9551e-01,\n",
            "        8.9286e-01, 1.7344e-01, 9.5832e-01, 4.9717e-01, 5.9088e-01, 6.9808e-01,\n",
            "        4.0535e-01, 8.5763e-01, 9.4525e-01, 9.6010e-01, 9.4418e-01, 7.3367e-01,\n",
            "        5.2673e-01, 7.7515e-01, 8.6913e-01, 1.0000e+00, 7.9958e-01, 7.6174e-01,\n",
            "        6.3395e-01, 8.0531e-01, 5.2339e-01, 6.8933e-01, 5.2339e-01, 8.8787e-01,\n",
            "        6.8955e-03, 8.9759e-01, 1.6431e-01, 3.0153e-01, 2.0687e-02, 7.4734e-01,\n",
            "        8.6243e-01, 9.0949e-01, 9.7841e-01, 9.9386e-22, 9.5785e-01, 9.3704e-01,\n",
            "        3.4723e-02, 9.2731e-01, 3.8583e-01, 9.9804e-01, 8.5589e-01, 9.8148e-01,\n",
            "        5.6952e-08, 8.3334e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 8.3614e-01,\n",
            "        8.1233e-01, 8.4735e-01, 9.8168e-01, 9.1095e-01, 9.7781e-01, 8.9828e-01,\n",
            "        8.2274e-01, 8.8370e-01, 4.6098e-10, 1.0000e+00, 2.5092e-01, 2.8836e-01,\n",
            "        5.3775e-01, 7.0052e-01, 6.1441e-01, 7.7302e-01, 9.8785e-01, 1.6710e-01,\n",
            "        9.9722e-01, 8.7862e-24, 5.9083e-01, 8.7634e-01, 1.0073e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.5194e-01, 9.8101e-01, 0.0000e+00, 9.9659e-01, 9.6552e-01,\n",
            "        8.9185e-01, 2.8631e-09, 7.4635e-02, 1.5080e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 9.6213e-01, 5.3014e-05, 9.8633e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 6.7902e-01, 2.4227e-02,\n",
            "        1.0000e+00, 3.3236e-10, 9.6420e-10, 1.0000e+00, 5.8371e-13, 9.7471e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.0000e+00, 1.0000e+00, 8.9595e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 9.8705e-01, 5.9826e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 8.9864e-01, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 1.0000e+00,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.0000e+00, 1.0000e+00, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 1.0247e-01])\n",
            "Molecule 102: tensor([4.7298e-01, 8.6009e-01, 7.3831e-01, 7.5998e-01, 7.2774e-01, 7.9689e-01,\n",
            "        7.8573e-01, 7.2794e-01, 7.2380e-01, 6.3225e-01, 7.5754e-01, 6.6208e-01,\n",
            "        7.7269e-01, 6.7534e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 4.2420e-01,\n",
            "        3.3252e-01, 8.1629e-01, 9.2584e-11, 5.5601e-01, 8.0688e-01, 7.5261e-01,\n",
            "        3.6353e-01, 6.9278e-01, 1.9723e-01, 2.2337e-01, 2.8417e-01, 1.6162e-01,\n",
            "        8.4000e-02, 7.7515e-01, 6.9149e-01, 1.0000e+00, 6.7002e-01, 7.0795e-01,\n",
            "        5.4488e-01, 7.6525e-01, 8.5523e-01, 1.5279e-01, 8.5523e-01, 4.1956e-01,\n",
            "        4.4831e-01, 4.1264e-01, 6.9677e-01, 8.3683e-01, 9.4272e-01, 8.1368e-01,\n",
            "        6.9465e-01, 4.3608e-01, 3.0517e-01, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        9.6401e-01, 9.2731e-01, 9.8904e-01, 3.0707e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 5.8913e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 7.4236e-01,\n",
            "        3.4913e-01, 5.7614e-21, 3.6088e-15, 1.4598e-01, 9.7781e-01, 1.1809e-10,\n",
            "        3.1226e-01, 8.0774e-01, 4.6098e-10, 1.5707e-01, 9.7221e-01, 1.1231e-01,\n",
            "        6.9125e-01, 9.4670e-01, 8.8518e-01, 1.8288e-01, 3.7451e-01, 1.6710e-01,\n",
            "        8.1121e-01, 8.7862e-24, 5.3012e-01, 3.0449e-02, 9.8440e-01, 5.3014e-05,\n",
            "        7.3111e-01, 3.1443e-01, 6.9527e-13, 0.0000e+00, 9.7969e-13, 1.9716e-01,\n",
            "        3.2914e-01, 2.8631e-09, 7.3925e-01, 9.8998e-01, 2.9949e-06, 9.9344e-01,\n",
            "        5.3014e-05, 3.0878e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.1232e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.4231e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 7.1316e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 9.6402e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.0000e+00,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 9.9991e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 1.6023e-01])\n",
            "Molecule 103: tensor([7.2465e-01, 3.9943e-02, 6.3582e-02, 1.5658e-01, 1.7018e-01, 9.2020e-02,\n",
            "        2.8625e-01, 3.3616e-01, 3.6885e-01, 4.3006e-01, 5.8592e-01, 6.7641e-01,\n",
            "        7.2389e-01, 8.2022e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.3118e-01, 1.5706e-01, 9.8612e-01, 3.3947e-01, 5.3009e-01, 7.5232e-01,\n",
            "        7.5225e-13, 8.6656e-02, 6.5094e-01, 7.8800e-01, 7.3200e-01, 9.6375e-01,\n",
            "        9.7951e-01, 8.0716e-02, 7.0422e-02, 1.0000e+00, 9.2892e-02, 1.1821e-01,\n",
            "        2.6606e-01, 1.1197e-01, 1.0967e-02, 9.7184e-02, 1.0967e-02, 1.9837e-02,\n",
            "        9.1668e-01, 1.2907e-02, 8.3886e-01, 8.9503e-01, 7.8837e-01, 1.5492e-01,\n",
            "        8.4348e-02, 6.1316e-02, 5.1530e-02, 9.9995e-01, 9.1873e-01, 9.3704e-01,\n",
            "        3.4723e-02, 8.6504e-01, 8.3758e-02, 8.4739e-02, 5.5287e-02, 7.2855e-03,\n",
            "        5.6952e-08, 5.2057e-02, 8.9543e-01, 9.8000e-01, 9.4279e-01, 1.3232e-01,\n",
            "        8.7215e-03, 5.7614e-21, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1932e-01, 9.0550e-08, 4.6098e-10, 1.0000e+00, 5.8437e-01, 8.2070e-01,\n",
            "        1.3190e-01, 1.9737e-01, 3.9661e-01, 1.2446e-01, 2.2992e-01, 1.6710e-01,\n",
            "        1.9057e-01, 9.8764e-01, 8.6050e-01, 4.4851e-01, 1.0099e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.8505e-01, 1.5083e-01,\n",
            "        2.8149e-01, 9.3953e-01, 8.7943e-01, 1.1298e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.4930e-03, 5.3014e-05, 9.6031e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.9982e-01, 5.3014e-05, 9.9865e-01, 9.0628e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 9.9998e-01, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 1.0000e+00, 4.7036e-08,\n",
            "        1.6663e-01, 7.6117e-01])\n",
            "Molecule 104: tensor([5.0840e-03, 4.3248e-01, 5.9864e-01, 6.7575e-01, 6.3411e-01, 6.9032e-01,\n",
            "        7.9784e-01, 7.4234e-01, 8.4239e-01, 7.8150e-01, 9.2443e-01, 8.8769e-01,\n",
            "        9.4686e-01, 9.2080e-01, 4.0749e-10, 5.1130e-01, 6.8936e-07, 9.5745e-01,\n",
            "        5.2365e-01, 9.1541e-01, 9.2584e-11, 6.5157e-01, 4.6477e-01, 8.9560e-01,\n",
            "        7.5225e-13, 6.0762e-01, 3.8598e-02, 3.7765e-02, 4.4268e-02, 8.4139e-01,\n",
            "        5.8590e-01, 6.6622e-01, 5.8853e-01, 1.0000e+00, 5.1351e-01, 4.1953e-01,\n",
            "        3.9509e-01, 6.6047e-01, 6.5349e-01, 1.4338e-01, 6.5349e-01, 3.0329e-01,\n",
            "        4.7106e-01, 2.9336e-01, 6.9012e-01, 8.4662e-01, 1.3773e-01, 6.2988e-01,\n",
            "        6.0730e-01, 6.1316e-02, 6.9483e-01, 1.0000e+00, 9.5785e-01, 9.8620e-01,\n",
            "        3.4723e-02, 8.6504e-01, 8.3758e-02, 6.7960e-01, 5.5287e-02, 4.9077e-01,\n",
            "        5.6952e-08, 4.6631e-01, 8.9543e-01, 9.9653e-01, 9.6593e-01, 6.8966e-01,\n",
            "        1.2390e-01, 5.7614e-21, 3.6088e-15, 9.4323e-01, 1.7356e-22, 1.1809e-10,\n",
            "        9.2394e-01, 8.0774e-01, 4.6098e-10, 1.5707e-01, 4.6715e-01, 6.9595e-01,\n",
            "        9.3547e-01, 4.6555e-01, 9.9534e-01, 3.1354e-01, 4.0455e-01, 1.6710e-01,\n",
            "        8.0837e-01, 9.9959e-01, 2.5414e-01, 9.1639e-01, 2.9623e-01, 5.3014e-05,\n",
            "        1.4266e-16, 2.8678e-01, 9.8495e-01, 0.0000e+00, 9.7969e-13, 8.7962e-01,\n",
            "        4.6290e-01, 9.9071e-01, 2.1506e-01, 4.7158e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 4.5175e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 9.1165e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.0122e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 9.2413e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 8.9864e-01, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.0000e+00, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 9.6071e-01,\n",
            "        1.6663e-01, 2.2673e-01])\n",
            "Molecule 105: tensor([8.2212e-01, 4.8121e-01, 2.8599e-01, 2.0781e-01, 2.2424e-01, 2.3721e-01,\n",
            "        1.5792e-01, 2.6860e-01, 1.7713e-01, 4.0116e-01, 1.9452e-01, 4.8563e-01,\n",
            "        2.0285e-01, 4.8912e-01, 8.7574e-01, 7.9871e-01, 6.8936e-07, 7.3558e-01,\n",
            "        1.3722e-01, 1.1461e-01, 9.3106e-01, 5.6633e-01, 1.0887e-06, 3.3331e-01,\n",
            "        3.3637e-01, 2.8699e-01, 9.0607e-01, 8.4429e-01, 7.7285e-01, 1.6747e-01,\n",
            "        4.7876e-01, 2.6018e-01, 3.1136e-01, 1.0000e+00, 2.1751e-01, 9.8952e-02,\n",
            "        3.0625e-01, 2.1695e-01, 4.0398e-01, 8.4572e-01, 4.0398e-01, 5.3318e-01,\n",
            "        3.6183e-02, 5.1267e-01, 3.9349e-02, 1.4142e-01, 1.4254e-01, 1.6631e-01,\n",
            "        2.8196e-01, 7.0728e-01, 8.0633e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 8.2272e-01, 7.3166e-01, 7.2707e-01,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 2.5274e-01,\n",
            "        6.0271e-01, 4.6698e-01, 9.9562e-01, 9.1527e-01, 9.9156e-01, 1.1809e-10,\n",
            "        5.9058e-01, 7.6918e-01, 4.6098e-10, 1.5707e-01, 3.5090e-01, 1.2202e-01,\n",
            "        4.3969e-01, 1.7164e-01, 3.9661e-01, 8.3648e-01, 5.2114e-01, 1.6710e-01,\n",
            "        3.9103e-01, 8.7862e-24, 2.3061e-01, 4.2597e-01, 4.5896e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.1443e-01, 9.8441e-01, 0.0000e+00, 9.7969e-13, 5.0418e-01,\n",
            "        4.8055e-01, 9.4722e-01, 2.8811e-01, 6.0617e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.3787e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 7.2257e-01, 1.8018e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 9.9996e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.6021e-01])\n",
            "Molecule 106: tensor([6.6504e-02, 7.2442e-01, 7.7792e-01, 7.2549e-01, 7.4135e-01, 7.6247e-01,\n",
            "        7.1973e-01, 7.4207e-01, 7.8974e-01, 8.6418e-01, 7.8356e-01, 8.7248e-01,\n",
            "        7.9740e-01, 9.0720e-01, 9.4800e-01, 8.1667e-01, 6.8936e-07, 2.1859e-01,\n",
            "        4.7487e-01, 2.5099e-11, 8.3134e-01, 9.4735e-01, 5.9677e-01, 1.6919e-01,\n",
            "        7.4807e-01, 7.8034e-01, 5.4577e-01, 4.2996e-01, 5.1804e-01, 4.5627e-01,\n",
            "        2.7268e-01, 7.7515e-01, 7.9136e-01, 1.0000e+00, 7.1421e-01, 5.0916e-01,\n",
            "        4.5455e-01, 7.6967e-01, 6.7612e-01, 3.2892e-01, 6.7612e-01, 8.6767e-01,\n",
            "        8.9616e-01, 8.7628e-01, 1.6725e-01, 6.5762e-01, 1.4336e-01, 6.9970e-01,\n",
            "        7.8413e-01, 8.4234e-01, 8.7595e-01, 9.9386e-22, 9.7155e-01, 9.6456e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 9.1034e-01, 7.3166e-01, 8.0827e-01,\n",
            "        5.6952e-08, 3.3567e-01, 0.0000e+00, 9.9653e-01, 9.4279e-01, 8.0080e-01,\n",
            "        8.9129e-01, 9.2951e-01, 3.6088e-15, 9.1627e-01, 9.8003e-01, 9.6111e-01,\n",
            "        6.1801e-01, 7.9907e-01, 4.6098e-10, 1.0000e+00, 7.7384e-01, 2.0403e-01,\n",
            "        2.2192e-01, 1.9837e-01, 8.8518e-01, 8.9224e-01, 8.6111e-01, 1.6710e-01,\n",
            "        4.2847e-01, 9.8692e-01, 8.0338e-01, 3.0449e-02, 7.2395e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.5194e-01, 6.9527e-13, 0.0000e+00, 9.8575e-01, 7.2424e-01,\n",
            "        8.4768e-01, 2.8631e-09, 8.1127e-01, 6.6516e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.9210e-01, 5.3014e-05, 9.3936e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 8.6732e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 9.4294e-01, 9.8352e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 8.9864e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.8691e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.0000e+00, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 1.0000e+00,\n",
            "        1.0000e+00, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 3.3947e-01])\n",
            "Molecule 107: tensor([3.4497e-01, 2.5661e-01, 6.7207e-01, 7.3070e-01, 7.4633e-01, 5.7906e-01,\n",
            "        7.0226e-01, 7.2653e-01, 8.5182e-01, 9.0205e-01, 6.9216e-01, 8.1981e-01,\n",
            "        6.7658e-01, 8.5529e-01, 9.3362e-01, 6.9481e-01, 6.8936e-07, 3.9930e-01,\n",
            "        1.9674e-02, 6.1469e-01, 7.8353e-01, 8.8877e-01, 5.9848e-01, 3.1549e-01,\n",
            "        5.7634e-01, 6.7214e-01, 6.5094e-01, 4.4008e-01, 3.3731e-01, 9.8225e-01,\n",
            "        8.2908e-01, 6.2199e-01, 6.4595e-01, 1.0000e+00, 7.3727e-01, 5.9735e-01,\n",
            "        5.9107e-01, 6.5978e-01, 5.1579e-01, 3.6400e-01, 5.1579e-01, 8.4800e-01,\n",
            "        6.6575e-01, 8.5519e-01, 3.0000e-01, 6.2259e-01, 2.6372e-01, 6.1845e-01,\n",
            "        6.7359e-01, 6.1316e-02, 8.0633e-01, 9.9386e-22, 9.7155e-01, 9.6456e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 8.2272e-01, 5.5287e-02, 7.2707e-01,\n",
            "        5.6952e-08, 3.3567e-01, 0.0000e+00, 9.9907e-01, 9.6593e-01, 7.4236e-01,\n",
            "        7.6478e-01, 7.0739e-01, 9.8611e-01, 8.6070e-01, 9.7781e-01, 9.6111e-01,\n",
            "        8.2545e-01, 6.3417e-01, 4.6098e-10, 1.0000e+00, 2.7105e-01, 6.5895e-01,\n",
            "        4.1565e-01, 4.6219e-01, 3.9661e-01, 8.4976e-01, 8.6703e-01, 1.6710e-01,\n",
            "        4.0799e-01, 9.9560e-01, 9.4348e-01, 6.2765e-01, 2.5837e-02, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.8575e-01, 9.0311e-01,\n",
            "        8.4768e-01, 9.3484e-01, 8.9920e-01, 4.5566e-02, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 6.7706e-01, 5.3014e-05, 9.4665e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.5542e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.0000e+00, 7.1316e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.0000e+00, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 1.0000e+00,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.7483e-02])\n",
            "Molecule 108: tensor([3.7449e-01, 2.4007e-01, 6.5916e-01, 6.9785e-01, 7.1489e-01, 6.0116e-01,\n",
            "        6.9374e-01, 7.1894e-01, 7.1745e-01, 8.1962e-01, 6.5613e-01, 7.9876e-01,\n",
            "        6.9995e-01, 8.6553e-01, 9.2292e-01, 6.9481e-01, 6.8936e-07, 5.9037e-01,\n",
            "        1.9674e-02, 6.1469e-01, 8.6125e-01, 8.2473e-01, 5.5287e-01, 4.5319e-01,\n",
            "        5.7634e-01, 6.7809e-01, 7.7284e-01, 6.2186e-01, 5.2413e-01, 9.7994e-01,\n",
            "        7.7887e-01, 6.2199e-01, 6.5936e-01, 1.0000e+00, 7.2811e-01, 6.8001e-01,\n",
            "        5.9967e-01, 6.5042e-01, 5.2292e-01, 9.6885e-01, 5.2292e-01, 9.9014e-01,\n",
            "        6.8082e-01, 9.7638e-01, 1.7761e-01, 5.8992e-01, 2.5832e-01, 5.8256e-01,\n",
            "        6.7965e-01, 6.1316e-02, 8.7595e-01, 9.9386e-22, 9.7155e-01, 9.6456e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 9.1034e-01, 5.5287e-02, 8.0827e-01,\n",
            "        5.6952e-08, 4.6631e-01, 0.0000e+00, 9.9907e-01, 9.6593e-01, 7.4236e-01,\n",
            "        8.7061e-01, 7.0739e-01, 9.8611e-01, 8.5084e-01, 9.7781e-01, 9.6200e-01,\n",
            "        6.2875e-01, 7.9907e-01, 4.6098e-10, 1.0000e+00, 2.7105e-01, 3.6697e-01,\n",
            "        5.7454e-01, 5.0979e-01, 3.9661e-01, 8.9186e-01, 8.6951e-01, 1.6710e-01,\n",
            "        4.0799e-01, 9.8334e-01, 9.4223e-01, 6.2351e-01, 2.5837e-02, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7891e-01, 0.0000e+00, 9.8575e-01, 9.2530e-01,\n",
            "        8.4683e-01, 2.8631e-09, 8.5739e-01, 4.5566e-02, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.5273e-01, 5.3014e-05, 9.4585e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.4754e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.0000e+00, 7.1316e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 8.8512e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 1.0000e+00,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.1538e-02])\n",
            "Molecule 109: tensor([4.6031e-01, 9.7168e-02, 2.2618e-01, 2.7133e-01, 2.9051e-01, 2.0081e-01,\n",
            "        3.2753e-01, 3.7808e-01, 4.9075e-01, 6.6718e-01, 4.8346e-01, 6.8823e-01,\n",
            "        5.6785e-01, 8.0545e-01, 8.8165e-01, 7.0447e-01, 6.8936e-07, 3.9930e-01,\n",
            "        1.9674e-02, 3.3878e-01, 9.2799e-01, 5.3860e-01, 5.9848e-01, 3.1549e-01,\n",
            "        7.5225e-13, 2.5160e-01, 8.8039e-01, 7.1761e-01, 5.4310e-01, 9.7994e-01,\n",
            "        9.1888e-01, 2.1432e-01, 2.3589e-01, 1.0000e+00, 2.5374e-01, 1.6207e-01,\n",
            "        3.3846e-01, 2.3953e-01, 3.0947e-01, 7.1830e-01, 3.0947e-01, 8.3473e-01,\n",
            "        6.1196e-01, 8.4081e-01, 2.2220e-01, 2.7260e-01, 1.1715e-01, 2.2919e-01,\n",
            "        2.4668e-01, 4.3608e-01, 5.0000e-01, 9.9386e-22, 9.7155e-01, 9.6456e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 3.0707e-01, 4.7447e-01, 4.9077e-01,\n",
            "        5.6952e-08, 1.1745e-01, 0.0000e+00, 9.9907e-01, 9.6593e-01, 2.6921e-01,\n",
            "        6.0090e-01, 7.0739e-01, 9.8611e-01, 1.4598e-01, 9.7781e-01, 8.9828e-01,\n",
            "        6.2875e-01, 6.3417e-01, 4.6098e-10, 1.0000e+00, 2.7105e-01, 2.2396e-01,\n",
            "        4.1565e-01, 2.3052e-01, 3.9661e-01, 5.8544e-01, 7.6172e-01, 1.6710e-01,\n",
            "        4.0799e-01, 9.8334e-01, 8.8129e-01, 4.4851e-01, 2.5837e-02, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.8575e-01, 8.6676e-01,\n",
            "        4.6290e-01, 2.8631e-09, 7.2251e-01, 4.5566e-02, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.0130e-01, 5.3014e-05, 9.4599e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1683e-01, 2.0287e-02,\n",
            "        1.0000e+00, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.0000e+00, 1.0000e+00, 7.9714e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.0000e+00, 7.1316e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 1.0000e+00,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 3.3268e-01])\n",
            "Molecule 110: tensor([8.5828e-01, 3.2431e-01, 4.8013e-01, 4.5813e-01, 4.8053e-01, 3.9559e-01,\n",
            "        3.9606e-01, 5.3162e-01, 3.6728e-01, 5.8190e-01, 4.3987e-01, 6.4086e-01,\n",
            "        4.4625e-01, 5.6952e-01, 8.3260e-01, 6.5613e-01, 6.8936e-07, 8.7688e-01,\n",
            "        1.5930e-01, 6.1469e-01, 9.0684e-01, 5.8561e-17, 4.6492e-01, 6.1750e-01,\n",
            "        6.1295e-01, 4.7008e-01, 9.7443e-01, 9.6813e-01, 9.2381e-01, 6.8907e-01,\n",
            "        7.4098e-01, 4.1623e-01, 4.5216e-01, 1.0000e+00, 5.8598e-01, 5.6430e-01,\n",
            "        5.4739e-01, 4.1363e-01, 4.4643e-01, 8.7196e-01, 4.4643e-01, 4.3700e-01,\n",
            "        1.0332e-01, 4.2965e-01, 4.0935e-02, 1.1306e-01, 5.7015e-02, 4.2663e-01,\n",
            "        4.6689e-01, 9.0949e-01, 8.0633e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 6.7960e-01, 8.5589e-01, 7.2707e-01,\n",
            "        5.6952e-08, 6.9263e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 4.9654e-01,\n",
            "        6.3942e-01, 6.8153e-01, 3.6088e-15, 9.0234e-01, 9.7781e-01, 1.1809e-10,\n",
            "        6.2375e-01, 8.6563e-01, 4.6098e-10, 9.9995e-01, 1.3944e-01, 3.4099e-01,\n",
            "        5.8716e-01, 6.9220e-01, 1.2027e-01, 7.2846e-01, 5.2094e-01, 1.6710e-01,\n",
            "        5.9399e-01, 8.7862e-24, 4.9035e-01, 8.8837e-01, 1.5748e-01, 5.3014e-05,\n",
            "        6.9955e-01, 9.0674e-01, 9.8384e-01, 7.0981e-01, 9.7969e-13, 8.0327e-01,\n",
            "        4.8055e-01, 2.8631e-09, 4.4400e-01, 2.4660e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.4234e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1979e-01, 1.9330e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 1.0000e+00, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 8.3841e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 9.9996e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 2.8723e-01])\n",
            "Molecule 111: tensor([8.6640e-01, 2.7920e-01, 4.2551e-01, 4.5093e-01, 4.7335e-01, 3.4061e-01,\n",
            "        4.2360e-01, 5.7890e-01, 3.7481e-01, 6.4617e-01, 4.8751e-01, 7.2669e-01,\n",
            "        4.7494e-01, 6.3447e-01, 7.3830e-01, 6.5613e-01, 6.8936e-07, 9.4380e-01,\n",
            "        3.4782e-01, 6.1469e-01, 9.0614e-01, 5.8561e-17, 1.0887e-06, 5.1827e-01,\n",
            "        6.1295e-01, 4.1877e-01, 9.3945e-01, 9.1540e-01, 8.0464e-01, 8.4676e-01,\n",
            "        8.2217e-01, 3.6230e-01, 3.9346e-01, 1.0000e+00, 5.3882e-01, 4.9647e-01,\n",
            "        5.3585e-01, 3.6683e-01, 4.3321e-01, 8.7196e-01, 4.3321e-01, 4.3700e-01,\n",
            "        2.0358e-01, 4.2965e-01, 4.4367e-02, 1.1306e-01, 1.0567e-01, 3.8337e-01,\n",
            "        4.1476e-01, 8.4234e-01, 6.9483e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 6.7960e-01, 7.3166e-01, 6.2081e-01,\n",
            "        5.6952e-08, 5.8913e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 4.5099e-01,\n",
            "        6.3942e-01, 4.6640e-01, 9.9415e-01, 1.4598e-01, 9.7781e-01, 1.1809e-10,\n",
            "        6.2375e-01, 7.6918e-01, 4.6098e-10, 1.5707e-01, 2.8953e-01, 3.2955e-01,\n",
            "        4.3900e-01, 8.9215e-01, 1.2027e-01, 7.2846e-01, 5.1532e-01, 1.6710e-01,\n",
            "        4.2847e-01, 8.7862e-24, 7.0139e-01, 8.7901e-01, 7.6856e-02, 5.3014e-05,\n",
            "        6.9955e-01, 8.1875e-01, 9.8384e-01, 7.0981e-01, 9.7969e-13, 7.9242e-01,\n",
            "        4.7304e-01, 2.8631e-09, 6.8912e-01, 1.0927e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.7940e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.2236e-01, 1.8512e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 1.0000e+00, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.0000e+00, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 1.0000e+00,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.7702e-01])\n",
            "Molecule 112: tensor([7.9786e-01, 1.3204e-01, 2.3985e-01, 3.1046e-01, 2.5919e-01, 2.1365e-01,\n",
            "        3.0708e-01, 2.3631e-01, 2.8099e-01, 1.9270e-01, 3.8175e-01, 2.7250e-01,\n",
            "        3.9917e-01, 2.8360e-01, 4.0749e-10, 5.1130e-01, 6.8936e-07, 4.1463e-01,\n",
            "        7.7012e-01, 4.8637e-01, 8.6705e-01, 6.6747e-01, 1.0887e-06, 5.1827e-01,\n",
            "        3.4911e-01, 1.8400e-01, 9.4398e-01, 9.5052e-01, 9.0413e-01, 7.7507e-01,\n",
            "        8.0268e-01, 2.1432e-01, 1.6455e-01, 1.0000e+00, 3.1345e-01, 3.9652e-01,\n",
            "        4.6868e-01, 2.1372e-01, 3.5643e-01, 8.7268e-01, 3.5643e-01, 4.3682e-01,\n",
            "        3.8008e-01, 4.2947e-01, 6.4540e-01, 1.1228e-01, 2.0951e-01, 2.2394e-01,\n",
            "        1.7950e-01, 4.3608e-01, 3.0517e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 3.0707e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 4.6631e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 2.5274e-01,\n",
            "        3.5789e-01, 4.6640e-01, 9.8503e-01, 1.4598e-01, 9.7781e-01, 1.1809e-10,\n",
            "        8.2274e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 1.5672e-01, 7.3547e-01,\n",
            "        4.2469e-01, 4.9912e-01, 1.2027e-01, 5.6501e-01, 2.3769e-01, 1.6710e-01,\n",
            "        4.2847e-01, 8.7862e-24, 6.3852e-01, 7.5405e-01, 1.4894e-01, 5.3014e-05,\n",
            "        6.9955e-01, 6.0336e-01, 6.9527e-13, 7.0981e-01, 9.7969e-13, 7.0714e-01,\n",
            "        1.2049e-11, 2.8631e-09, 8.0888e-01, 1.1842e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 2.9211e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 8.9051e-01, 5.3014e-05, 9.9865e-01, 9.2482e-01, 2.1719e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.7146e-01])\n",
            "Molecule 113: tensor([8.3796e-01, 2.1167e-01, 2.5448e-01, 2.4146e-01, 2.5946e-01, 1.9307e-01,\n",
            "        2.0667e-01, 3.4435e-01, 2.4539e-01, 4.1439e-01, 3.0200e-01, 3.9756e-01,\n",
            "        2.8640e-01, 3.3078e-01, 7.4264e-01, 6.5613e-01, 6.8936e-07, 5.3637e-01,\n",
            "        5.2240e-01, 4.8369e-01, 9.0116e-01, 5.8561e-17, 4.7966e-01, 3.2546e-01,\n",
            "        5.9151e-01, 2.5851e-01, 9.7443e-01, 9.6711e-01, 8.6406e-01, 7.3367e-01,\n",
            "        8.5658e-01, 2.1432e-01, 2.5023e-01, 1.0000e+00, 3.3083e-01, 2.7887e-01,\n",
            "        4.8100e-01, 2.0504e-01, 3.1583e-01, 8.7267e-01, 3.1583e-01, 4.3698e-01,\n",
            "        5.6089e-01, 4.2963e-01, 3.9993e-02, 1.1228e-01, 4.0615e-02, 1.8785e-01,\n",
            "        2.5354e-01, 8.4234e-01, 6.9483e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 4.9226e-01, 7.3166e-01, 6.2081e-01,\n",
            "        5.6952e-08, 3.3567e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 2.6921e-01,\n",
            "        6.0303e-01, 4.6640e-01, 3.6088e-15, 9.0234e-01, 9.7781e-01, 1.1809e-10,\n",
            "        3.1226e-01, 8.7165e-01, 4.6098e-10, 1.5707e-01, 6.0306e-26, 5.9181e-01,\n",
            "        2.7253e-01, 6.6925e-01, 1.2027e-01, 7.2846e-01, 3.4786e-01, 1.6710e-01,\n",
            "        4.2847e-01, 9.8415e-01, 4.9035e-01, 7.6150e-01, 1.0923e-01, 5.3014e-05,\n",
            "        6.9955e-01, 8.0296e-01, 6.9527e-13, 7.0981e-01, 9.7969e-13, 7.4227e-01,\n",
            "        4.8055e-01, 2.8631e-09, 4.4400e-01, 1.6402e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.7940e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 7.0567e-01, 1.9911e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.0000e+00, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 9.9996e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.4692e-01])\n",
            "Molecule 114: tensor([8.3821e-01, 2.3625e-01, 3.5812e-01, 4.0426e-01, 4.2646e-01, 2.9705e-01,\n",
            "        3.9259e-01, 5.5158e-01, 3.3304e-01, 6.1785e-01, 4.5489e-01, 6.9732e-01,\n",
            "        4.3690e-01, 5.7325e-01, 7.3830e-01, 6.5613e-01, 6.8936e-07, 7.4011e-01,\n",
            "        5.2240e-01, 6.1469e-01, 9.0116e-01, 4.0889e-01, 1.0887e-06, 5.1827e-01,\n",
            "        3.4911e-01, 3.5957e-01, 9.2515e-01, 9.1890e-01, 8.4012e-01, 8.4676e-01,\n",
            "        8.6426e-01, 3.0986e-01, 3.3559e-01, 1.0000e+00, 4.8185e-01, 4.8605e-01,\n",
            "        5.1714e-01, 3.1791e-01, 4.0188e-01, 8.7267e-01, 4.0188e-01, 4.3698e-01,\n",
            "        4.4387e-02, 4.2963e-01, 4.6668e-02, 1.1228e-01, 1.5033e-01, 3.2203e-01,\n",
            "        3.5492e-01, 4.3608e-01, 5.0000e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 4.9226e-01, 4.7447e-01, 4.9077e-01,\n",
            "        5.6952e-08, 5.8913e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 3.8484e-01,\n",
            "        3.5789e-01, 4.6640e-01, 9.9415e-01, 1.4598e-01, 9.7781e-01, 1.1809e-10,\n",
            "        6.2375e-01, 7.6918e-01, 4.6098e-10, 1.5707e-01, 2.8953e-01, 5.7971e-01,\n",
            "        2.7253e-01, 8.0812e-01, 1.2027e-01, 7.2846e-01, 3.4237e-01, 1.6710e-01,\n",
            "        4.2847e-01, 8.7862e-24, 7.0139e-01, 8.2736e-01, 1.0923e-01, 5.3014e-05,\n",
            "        6.9955e-01, 6.0336e-01, 6.9527e-13, 7.0981e-01, 9.7969e-13, 7.9242e-01,\n",
            "        4.7304e-01, 2.8631e-09, 6.8912e-01, 1.6402e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.3435e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 4.8853e-01, 5.3014e-05, 9.9865e-01, 9.2390e-01, 1.8670e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 1.0000e+00,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.5366e-01])\n",
            "Molecule 115: tensor([8.6948e-01, 3.2394e-01, 4.8013e-01, 4.4959e-01, 4.7201e-01, 3.9307e-01,\n",
            "        3.7429e-01, 5.2029e-01, 3.5873e-01, 5.2672e-01, 4.1357e-01, 5.0007e-01,\n",
            "        4.4855e-01, 4.8621e-01, 8.3260e-01, 6.5613e-01, 6.8936e-07, 8.7791e-01,\n",
            "        1.5930e-01, 6.1469e-01, 9.0719e-01, 5.8561e-17, 4.6492e-01, 5.0969e-01,\n",
            "        7.3412e-01, 4.7393e-01, 9.5032e-01, 9.3671e-01, 8.1786e-01, 6.8907e-01,\n",
            "        7.4098e-01, 4.1623e-01, 4.6047e-01, 1.0000e+00, 5.8598e-01, 5.6430e-01,\n",
            "        5.6806e-01, 4.0953e-01, 4.6185e-01, 8.4424e-01, 4.6185e-01, 4.3817e-01,\n",
            "        3.5407e-01, 4.3077e-01, 3.8548e-02, 1.4300e-01, 6.5715e-02, 3.8775e-01,\n",
            "        4.7081e-01, 8.4234e-01, 8.0633e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 6.7960e-01, 7.3166e-01, 7.2707e-01,\n",
            "        5.6952e-08, 6.9263e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 4.9654e-01,\n",
            "        5.9565e-01, 5.7614e-21, 9.9561e-01, 9.0234e-01, 9.7781e-01, 1.1809e-10,\n",
            "        6.2375e-01, 8.7165e-01, 4.6098e-10, 9.9995e-01, 1.3944e-01, 2.0364e-01,\n",
            "        5.8716e-01, 8.3231e-01, 1.2027e-01, 8.3425e-01, 3.4786e-01, 1.6710e-01,\n",
            "        4.2847e-01, 9.8415e-01, 4.9035e-01, 8.4127e-01, 1.5748e-01, 5.3014e-05,\n",
            "        7.3205e-01, 8.9884e-01, 6.9527e-13, 7.7327e-01, 9.7969e-13, 8.0377e-01,\n",
            "        4.8055e-01, 2.8631e-09, 4.4400e-01, 2.4660e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.2973e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1905e-01, 1.9198e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9994e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 9.9996e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.7200e-01])\n",
            "Molecule 116: tensor([8.1388e-01, 2.3873e-01, 3.5812e-01, 3.6498e-01, 3.8667e-01, 2.9079e-01,\n",
            "        3.5364e-01, 5.0081e-01, 3.4193e-01, 5.1124e-01, 3.8129e-01, 4.7421e-01,\n",
            "        4.3130e-01, 4.6650e-01, 7.4264e-01, 6.5613e-01, 6.8936e-07, 5.3637e-01,\n",
            "        5.2240e-01, 7.2125e-01, 9.0116e-01, 5.8561e-17, 1.0887e-06, 5.1827e-01,\n",
            "        5.9151e-01, 3.6346e-01, 9.6335e-01, 9.6097e-01, 9.1524e-01, 8.1731e-01,\n",
            "        8.5658e-01, 3.0986e-01, 3.4372e-01, 1.0000e+00, 4.7893e-01, 4.8195e-01,\n",
            "        5.5952e-01, 3.0994e-01, 3.7654e-01, 8.7267e-01, 3.7654e-01, 4.3698e-01,\n",
            "        5.4527e-01, 4.2963e-01, 3.9909e-02, 1.1228e-01, 7.9074e-02, 2.9872e-01,\n",
            "        3.5881e-01, 8.4234e-01, 6.9483e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 4.9226e-01, 7.3166e-01, 6.2081e-01,\n",
            "        5.6952e-08, 5.8913e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 3.8484e-01,\n",
            "        3.5789e-01, 4.6640e-01, 3.6088e-15, 9.0234e-01, 9.7781e-01, 1.1809e-10,\n",
            "        6.2375e-01, 8.7165e-01, 4.6098e-10, 1.5707e-01, 1.5672e-01, 7.2555e-01,\n",
            "        2.7253e-01, 6.6925e-01, 1.2027e-01, 7.2846e-01, 3.4786e-01, 1.6710e-01,\n",
            "        4.2847e-01, 9.8415e-01, 6.9547e-01, 7.5405e-01, 1.0923e-01, 5.3014e-05,\n",
            "        6.9955e-01, 8.0296e-01, 6.9527e-13, 7.0981e-01, 9.7969e-13, 7.3692e-01,\n",
            "        4.8055e-01, 2.8631e-09, 6.8197e-01, 1.6402e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.7940e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.9812e-01, 1.8239e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 9.9996e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.7301e-01])\n",
            "Molecule 117: tensor([8.2488e-01, 1.1867e-01, 2.3985e-01, 2.9294e-01, 3.8377e-01, 2.1856e-01,\n",
            "        2.7479e-01, 3.1206e-01, 2.2913e-01, 2.7481e-01, 3.5124e-01, 3.8072e-01,\n",
            "        4.0312e-01, 4.2674e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 2.1859e-01,\n",
            "        7.7316e-01, 5.7799e-01, 6.5430e-01, 7.0176e-01, 4.6477e-01, 8.0018e-01,\n",
            "        5.7634e-01, 4.2240e-01, 9.4398e-01, 9.5052e-01, 9.0413e-01, 8.1731e-01,\n",
            "        9.1523e-01, 2.1432e-01, 4.1784e-01, 1.0000e+00, 3.5801e-01, 4.6288e-01,\n",
            "        4.5621e-01, 2.8255e-01, 4.2776e-01, 8.7137e-01, 4.2776e-01, 4.6926e-01,\n",
            "        6.9475e-01, 4.5976e-01, 6.5872e-01, 1.1371e-01, 3.2009e-01, 2.7604e-01,\n",
            "        4.2195e-01, 4.3608e-01, 3.0517e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 3.0707e-01, 4.7447e-01, 3.4646e-01,\n",
            "        5.6952e-08, 4.6631e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 2.6921e-01,\n",
            "        5.9565e-01, 8.4645e-01, 3.6088e-15, 1.4598e-01, 9.7781e-01, 1.1809e-10,\n",
            "        6.2375e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 1.5672e-01, 7.8806e-01,\n",
            "        2.7253e-01, 7.0142e-01, 1.2027e-01, 5.6176e-01, 5.2776e-01, 1.6710e-01,\n",
            "        4.2847e-01, 8.7862e-24, 5.2790e-01, 8.4127e-01, 9.9718e-02, 5.3014e-05,\n",
            "        7.3205e-01, 7.9154e-01, 6.9527e-13, 7.7327e-01, 9.9040e-01, 7.2250e-01,\n",
            "        1.2049e-11, 2.8631e-09, 5.7889e-01, 1.0612e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 1.9024e-01, 5.3014e-05, 9.8218e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.9985e-01, 5.3014e-05, 9.9865e-01, 9.0215e-01, 2.3341e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9994e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.9822e-01])\n",
            "Molecule 118: tensor([8.2879e-01, 2.2501e-01, 3.0489e-01, 3.0109e-01, 3.2127e-01, 2.4130e-01,\n",
            "        2.8158e-01, 4.2851e-01, 2.7003e-01, 4.4055e-01, 3.5635e-01, 4.5062e-01,\n",
            "        3.7946e-01, 4.1861e-01, 7.4264e-01, 6.5613e-01, 6.8936e-07, 5.3637e-01,\n",
            "        5.2240e-01, 6.1469e-01, 9.0116e-01, 5.8561e-17, 1.0887e-06, 5.1827e-01,\n",
            "        5.9151e-01, 3.0958e-01, 9.6915e-01, 9.6403e-01, 9.1006e-01, 7.8032e-01,\n",
            "        8.5658e-01, 2.6018e-01, 2.9565e-01, 1.0000e+00, 4.0489e-01, 3.7842e-01,\n",
            "        5.3246e-01, 2.5510e-01, 3.4858e-01, 8.7267e-01, 3.4858e-01, 4.3698e-01,\n",
            "        5.5225e-01, 4.2963e-01, 3.9947e-02, 1.1228e-01, 5.6578e-02, 2.4016e-01,\n",
            "        3.0460e-01, 8.4234e-01, 6.9483e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 4.9226e-01, 7.3166e-01, 6.2081e-01,\n",
            "        5.6952e-08, 4.6631e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 3.2364e-01,\n",
            "        3.5789e-01, 4.6640e-01, 3.6088e-15, 9.0234e-01, 9.7781e-01, 1.1809e-10,\n",
            "        6.2375e-01, 8.7165e-01, 4.6098e-10, 1.5707e-01, 1.5672e-01, 5.7971e-01,\n",
            "        2.7253e-01, 6.6925e-01, 1.2027e-01, 7.2846e-01, 3.4786e-01, 1.6710e-01,\n",
            "        4.2847e-01, 9.8415e-01, 6.0887e-01, 7.5405e-01, 1.0923e-01, 5.3014e-05,\n",
            "        6.9955e-01, 8.0296e-01, 6.9527e-13, 7.0981e-01, 9.7969e-13, 7.3692e-01,\n",
            "        4.8055e-01, 2.8631e-09, 5.7889e-01, 1.6402e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.7940e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.9521e-01, 1.8238e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.0000e+00, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 9.9996e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.2171e-01])\n",
            "Molecule 119: tensor([7.6293e-01, 1.5582e-01, 4.8328e-02, 4.6028e-02, 3.1809e-02, 6.6772e-02,\n",
            "        6.7820e-02, 4.3823e-02, 7.7052e-02, 4.4769e-02, 1.2478e-01, 7.6099e-02,\n",
            "        1.6393e-01, 1.0346e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 8.0634e-01,\n",
            "        3.0225e-01, 3.3275e-01, 6.5165e-01, 5.1793e-01, 1.0887e-06, 4.6188e-01,\n",
            "        5.9031e-01, 4.7302e-02, 9.8015e-01, 9.9382e-01, 9.9642e-01, 7.3367e-01,\n",
            "        8.3796e-01, 5.9953e-02, 5.0301e-02, 1.0000e+00, 3.1411e-02, 2.8781e-02,\n",
            "        2.1261e-01, 4.1606e-02, 1.3375e-01, 2.4754e-01, 1.3375e-01, 7.4551e-01,\n",
            "        1.0697e-01, 7.4209e-01, 5.3911e-01, 7.3963e-01, 2.9649e-02, 3.2617e-02,\n",
            "        4.5965e-02, 7.0728e-01, 6.9483e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.4723e-02, 9.2731e-01, 3.8583e-01, 6.7960e-01, 7.3166e-01, 4.9077e-01,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 9.8000e-01, 8.8066e-01, 9.6501e-02,\n",
            "        5.9732e-01, 7.2190e-01, 9.8378e-01, 1.4598e-01, 1.7356e-22, 8.8868e-01,\n",
            "        6.0541e-01, 6.4348e-01, 9.5662e-01, 1.5707e-01, 6.0306e-26, 7.2518e-02,\n",
            "        8.0760e-02, 8.4348e-01, 3.9661e-01, 3.2409e-01, 2.2620e-01, 1.6710e-01,\n",
            "        7.9978e-01, 8.7862e-24, 5.1642e-01, 2.2942e-01, 1.0463e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.3056e-01, 6.9527e-13, 0.0000e+00, 9.7969e-13, 5.3116e-01,\n",
            "        2.4246e-01, 2.8631e-09, 3.5431e-01, 1.1248e-01, 2.9949e-06, 9.8609e-01,\n",
            "        5.3014e-05, 7.1674e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 4.0289e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 9.6294e-01,\n",
            "        9.9999e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 7.1316e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 9.9999e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.0000e+00,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.6293e-01])\n",
            "Molecule 120: tensor([8.7625e-01, 8.0847e-02, 6.3283e-02, 4.7535e-02, 5.1560e-02, 6.0398e-02,\n",
            "        4.5652e-02, 4.1390e-02, 4.6266e-02, 4.2371e-02, 7.0499e-02, 6.6503e-02,\n",
            "        8.3243e-02, 7.7733e-02, 8.5251e-01, 5.2530e-01, 6.8936e-07, 1.0022e-01,\n",
            "        4.6461e-01, 2.5099e-11, 7.8846e-01, 7.5902e-01, 1.0887e-06, 2.3915e-11,\n",
            "        8.5199e-01, 7.1357e-02, 9.6703e-01, 9.4812e-01, 9.0818e-01, 3.1694e-01,\n",
            "        8.7859e-01, 5.9953e-02, 7.9416e-02, 1.0000e+00, 6.7629e-02, 7.1632e-02,\n",
            "        2.9745e-01, 6.2635e-02, 1.0559e-01, 8.7987e-01, 1.0559e-01, 8.5253e-01,\n",
            "        8.6103e-01, 8.6007e-01, 1.9215e-01, 1.0439e-01, 1.6684e-01, 4.2602e-02,\n",
            "        7.0009e-02, 4.3608e-01, 1.9367e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 3.0707e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 1.1745e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 9.6501e-02,\n",
            "        5.8601e-01, 7.2153e-01, 9.8635e-01, 1.4598e-01, 1.7356e-22, 8.9828e-01,\n",
            "        5.9983e-02, 6.3417e-01, 4.6098e-10, 1.5707e-01, 5.4988e-01, 4.0442e-02,\n",
            "        2.2762e-01, 5.1910e-01, 1.2027e-01, 7.7011e-01, 3.9840e-01, 1.6710e-01,\n",
            "        7.5581e-02, 8.7862e-24, 2.3955e-01, 2.4729e-01, 3.5405e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.8549e-01, 2.7498e-01,\n",
            "        6.3260e-01, 2.8631e-09, 1.8959e-01, 3.5123e-01, 9.9949e-01, 2.7764e-01,\n",
            "        5.3014e-05, 2.5237e-01, 5.3014e-05, 9.9373e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 3.9982e-01, 2.1614e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        1.0000e+00, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.9944e-01])\n",
            "Molecule 121: tensor([2.8796e-01, 2.6963e-01, 2.3069e-01, 3.3831e-01, 2.8569e-01, 2.6736e-01,\n",
            "        4.2613e-01, 3.4608e-01, 5.3988e-01, 4.2854e-01, 6.8810e-01, 5.7883e-01,\n",
            "        7.6744e-01, 6.6863e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 4.2420e-01,\n",
            "        5.0655e-01, 5.7336e-01, 8.5684e-01, 3.3215e-01, 6.5638e-01, 6.3461e-01,\n",
            "        7.5225e-13, 2.0855e-01, 6.6559e-01, 5.6583e-01, 6.4341e-01, 8.0884e-01,\n",
            "        8.0268e-01, 2.6018e-01, 1.8886e-01, 1.0000e+00, 1.9247e-01, 1.4880e-01,\n",
            "        3.2999e-01, 2.5344e-01, 4.9406e-01, 1.5645e-01, 4.9406e-01, 5.9319e-01,\n",
            "        2.1740e-01, 5.7399e-01, 7.2514e-01, 8.3304e-01, 2.4586e-01, 2.8306e-01,\n",
            "        2.0376e-01, 4.3608e-01, 3.0517e-01, 9.9386e-22, 9.5785e-01, 9.3704e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 3.0707e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 9.9653e-01, 9.4279e-01, 2.6921e-01,\n",
            "        3.6632e-01, 5.7614e-21, 9.8463e-01, 1.4598e-01, 9.7781e-01, 1.1809e-10,\n",
            "        6.1180e-01, 9.0550e-08, 9.5805e-01, 1.5707e-01, 4.7211e-01, 4.8526e-01,\n",
            "        7.3245e-01, 1.9647e-01, 6.1441e-01, 1.8288e-01, 3.7451e-01, 1.6710e-01,\n",
            "        8.1603e-01, 9.9096e-01, 8.1683e-01, 2.4508e-01, 1.5417e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.1443e-01, 6.9527e-13, 0.0000e+00, 9.7969e-13, 6.6136e-01,\n",
            "        3.5237e-01, 2.8631e-09, 7.5946e-01, 1.7683e-01, 2.9949e-06, 9.8573e-01,\n",
            "        5.3014e-05, 1.8294e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 3.9982e-01, 2.4481e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.0122e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 7.1316e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.9786e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 9.9991e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 1.0000e+00, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 9.9284e-01])\n",
            "Molecule 122: tensor([8.4723e-01, 2.3231e-02, 1.0670e-02, 2.4465e-02, 1.6234e-02, 1.6833e-02,\n",
            "        3.6580e-02, 2.2919e-02, 4.8122e-02, 2.6755e-02, 7.3180e-02, 4.2626e-02,\n",
            "        8.2708e-02, 4.9797e-02, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.9674e-02, 1.7344e-01, 8.9366e-01, 5.8561e-17, 1.0887e-06, 9.1928e-01,\n",
            "        7.5225e-13, 7.8010e-03, 6.2435e-01, 6.6345e-01, 5.3213e-01, 4.5627e-01,\n",
            "        9.3603e-01, 1.4189e-02, 6.9027e-03, 1.0000e+00, 9.3925e-03, 2.2868e-02,\n",
            "        2.5942e-01, 1.4343e-02, 1.0286e-02, 1.0520e-01, 1.0286e-02, 1.0585e-02,\n",
            "        9.9685e-01, 6.1806e-03, 9.0941e-01, 8.8658e-01, 2.6252e-01, 2.7468e-02,\n",
            "        7.6873e-03, 6.1316e-02, 5.1530e-02, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 4.0600e-02, 5.5287e-02, 8.8540e-04,\n",
            "        5.6952e-08, 1.6146e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 5.0851e-02,\n",
            "        1.2390e-01, 5.7614e-21, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 9.0550e-08, 4.6098e-10, 1.5707e-01, 6.3929e-01, 1.9062e-01,\n",
            "        2.8479e-01, 2.7501e-02, 1.2027e-01, 1.2446e-01, 1.3065e-01, 1.6710e-01,\n",
            "        1.9057e-01, 8.7862e-24, 1.1339e-01, 6.3325e-01, 2.8531e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 2.9045e-01,\n",
            "        1.2049e-11, 2.8631e-09, 1.9641e-01, 3.5673e-01, 2.9949e-06, 9.7067e-01,\n",
            "        5.3014e-05, 7.4930e-03, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 7.8827e-01, 2.2361e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.5477e-01])\n",
            "Molecule 123: tensor([8.4537e-01, 7.0908e-01, 9.8332e-01, 9.8653e-01, 9.8580e-01, 9.6724e-01,\n",
            "        9.8049e-01, 9.7577e-01, 9.8859e-01, 9.8407e-01, 9.8765e-01, 9.8200e-01,\n",
            "        9.8390e-01, 9.7696e-01, 9.7463e-01, 9.7040e-01, 6.8936e-07, 9.2377e-01,\n",
            "        1.5575e-01, 2.5099e-11, 9.1534e-01, 9.1474e-01, 6.3079e-01, 2.3915e-11,\n",
            "        9.2396e-01, 9.7848e-01, 1.2575e-01, 1.0260e-01, 8.4486e-02, 9.9802e-01,\n",
            "        9.1143e-01, 9.7490e-01, 9.7393e-01, 1.0000e+00, 9.8942e-01, 9.7228e-01,\n",
            "        9.1725e-01, 9.7700e-01, 8.6687e-01, 5.4404e-01, 8.6687e-01, 7.8628e-01,\n",
            "        4.9274e-01, 7.8751e-01, 8.5501e-02, 4.4483e-01, 1.6098e-01, 9.6837e-01,\n",
            "        9.8061e-01, 9.4482e-01, 9.8600e-01, 9.9386e-22, 9.7155e-01, 9.6456e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 9.9910e-01, 9.5102e-01, 9.5878e-01,\n",
            "        5.6952e-08, 5.8913e-01, 0.0000e+00, 9.9907e-01, 9.6593e-01, 9.9038e-01,\n",
            "        9.9453e-01, 9.6780e-01, 9.9629e-01, 1.4598e-01, 1.7356e-22, 8.9828e-01,\n",
            "        6.1801e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 5.1908e-01, 9.6295e-01,\n",
            "        8.5823e-01, 9.8541e-01, 3.9661e-01, 9.6573e-01, 2.3908e-01, 1.6710e-01,\n",
            "        1.9057e-01, 9.9909e-01, 9.9667e-01, 6.5592e-01, 2.5837e-02, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 9.9398e-01,\n",
            "        9.6334e-01, 9.8485e-01, 9.8329e-01, 3.0994e-02, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 9.7570e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 9.7164e-01, 2.5730e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 9.3085e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        1.0000e+00, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.3201e-02])\n",
            "Molecule 124: tensor([8.3436e-01, 6.7041e-01, 9.8082e-01, 9.8565e-01, 9.8483e-01, 9.6439e-01,\n",
            "        9.8016e-01, 9.7533e-01, 9.8758e-01, 9.8264e-01, 9.8741e-01, 9.8165e-01,\n",
            "        9.8344e-01, 9.7627e-01, 9.7327e-01, 9.4626e-01, 6.8936e-07, 9.1664e-01,\n",
            "        3.5595e-01, 2.5099e-11, 6.7292e-01, 9.6843e-01, 6.6299e-01, 2.3915e-11,\n",
            "        9.2396e-01, 9.7548e-01, 1.2341e-01, 1.0780e-01, 9.1611e-02, 9.9802e-01,\n",
            "        9.1646e-01, 9.7182e-01, 9.6987e-01, 1.0000e+00, 9.8814e-01, 9.7403e-01,\n",
            "        9.1513e-01, 9.7472e-01, 8.6351e-01, 5.6466e-01, 8.6351e-01, 7.8595e-01,\n",
            "        2.8966e-01, 7.8714e-01, 1.0220e-01, 4.2458e-01, 3.1793e-01, 9.6686e-01,\n",
            "        9.7780e-01, 9.0949e-01, 9.7841e-01, 9.9386e-22, 9.7155e-01, 9.6456e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 9.9804e-01, 9.1805e-01, 9.3880e-01,\n",
            "        5.6952e-08, 5.8913e-01, 0.0000e+00, 9.9907e-01, 9.6593e-01, 9.8933e-01,\n",
            "        9.9230e-01, 9.3453e-01, 9.9629e-01, 1.4598e-01, 1.7356e-22, 8.9828e-01,\n",
            "        6.1801e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 6.1619e-01, 9.3258e-01,\n",
            "        9.2174e-01, 9.8541e-01, 3.9661e-01, 9.6190e-01, 2.3908e-01, 1.6710e-01,\n",
            "        1.9057e-01, 9.9941e-01, 9.9616e-01, 6.5592e-01, 2.5837e-02, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 9.9113e-01,\n",
            "        9.6334e-01, 9.8837e-01, 9.8329e-01, 3.0994e-02, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 9.6311e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 9.7341e-01, 2.5801e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 9.3085e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        1.0000e+00, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 1.1744e-01])\n",
            "Molecule 125: tensor([8.5979e-01, 7.2548e-01, 9.8498e-01, 9.8855e-01, 9.8801e-01, 9.7148e-01,\n",
            "        9.8259e-01, 9.7856e-01, 9.8914e-01, 9.8484e-01, 9.8971e-01, 9.8507e-01,\n",
            "        9.8532e-01, 9.7907e-01, 9.7319e-01, 9.4626e-01, 6.8936e-07, 9.6682e-01,\n",
            "        1.5575e-01, 2.5099e-11, 8.7258e-01, 9.4711e-01, 6.6299e-01, 2.3915e-11,\n",
            "        9.5051e-01, 9.8076e-01, 9.3689e-02, 8.0598e-02, 6.7357e-02, 9.9808e-01,\n",
            "        9.1143e-01, 9.7759e-01, 9.7657e-01, 1.0000e+00, 9.9058e-01, 9.7666e-01,\n",
            "        9.1261e-01, 9.7979e-01, 8.7690e-01, 5.4404e-01, 8.7690e-01, 7.8628e-01,\n",
            "        5.4982e-01, 7.8751e-01, 8.7056e-02, 4.4483e-01, 2.6928e-01, 9.7282e-01,\n",
            "        9.8274e-01, 9.0949e-01, 9.8600e-01, 9.9386e-22, 9.7155e-01, 9.6456e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 9.9910e-01, 9.1805e-01, 9.5878e-01,\n",
            "        5.6952e-08, 6.9263e-01, 0.0000e+00, 9.9907e-01, 9.6593e-01, 9.9129e-01,\n",
            "        9.9440e-01, 9.6780e-01, 9.9629e-01, 1.4598e-01, 1.7356e-22, 8.9828e-01,\n",
            "        6.1801e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 5.1908e-01, 9.6295e-01,\n",
            "        9.3076e-01, 9.8541e-01, 3.9661e-01, 9.6548e-01, 2.3908e-01, 1.6710e-01,\n",
            "        1.9057e-01, 9.9909e-01, 9.9667e-01, 7.7662e-01, 2.5837e-02, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 9.9439e-01,\n",
            "        9.7755e-01, 9.8485e-01, 9.8329e-01, 3.0994e-02, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 9.6962e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 9.7286e-01, 2.7774e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 9.3843e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        1.0000e+00, 9.9994e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 1.0343e-01])\n",
            "Molecule 126: tensor([8.6008e-01, 7.4899e-01, 9.8545e-01, 9.8721e-01, 9.8654e-01, 9.6977e-01,\n",
            "        9.8059e-01, 9.7591e-01, 9.8937e-01, 9.8518e-01, 9.8746e-01, 9.8172e-01,\n",
            "        9.8421e-01, 9.7743e-01, 9.7721e-01, 9.7040e-01, 1.0000e+00, 6.3009e-01,\n",
            "        1.5575e-01, 1.8331e-01, 9.4401e-01, 9.1614e-01, 5.3480e-01, 2.3915e-11,\n",
            "        9.2396e-01, 9.8136e-01, 1.7248e-01, 1.1875e-01, 9.0791e-02, 9.9802e-01,\n",
            "        9.0196e-01, 9.7759e-01, 9.7796e-01, 1.0000e+00, 9.9050e-01, 9.7046e-01,\n",
            "        9.1154e-01, 9.7878e-01, 9.6463e-01, 5.4404e-01, 9.6463e-01, 7.8628e-01,\n",
            "        1.9787e-01, 7.8751e-01, 5.8250e-02, 4.4483e-01, 1.7360e-01, 9.6872e-01,\n",
            "        9.8329e-01, 9.4482e-01, 9.8600e-01, 9.9386e-22, 9.7155e-01, 9.6456e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 9.9910e-01, 9.5102e-01, 9.7234e-01,\n",
            "        5.6952e-08, 5.8913e-01, 0.0000e+00, 9.9907e-01, 9.6593e-01, 9.9129e-01,\n",
            "        9.9453e-01, 9.3303e-01, 9.9892e-01, 1.4598e-01, 1.7356e-22, 8.9828e-01,\n",
            "        6.1801e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 4.1008e-01, 9.6455e-01,\n",
            "        8.6507e-01, 9.8541e-01, 3.9661e-01, 9.6846e-01, 2.3908e-01, 1.6710e-01,\n",
            "        1.9057e-01, 9.9841e-01, 9.9711e-01, 6.5592e-01, 2.5837e-02, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 9.9507e-01,\n",
            "        9.6334e-01, 9.7907e-01, 9.8329e-01, 3.0994e-02, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 9.7570e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 9.6839e-01, 2.5569e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 9.3085e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        1.0000e+00, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.2522e-02])\n",
            "Molecule 127: tensor([8.3150e-01, 4.7358e-01, 2.5923e-01, 2.5689e-01, 2.0936e-01, 2.6939e-01,\n",
            "        2.3762e-01, 1.7605e-01, 1.9220e-01, 1.2419e-01, 2.4887e-01, 1.6487e-01,\n",
            "        2.9367e-01, 1.9790e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 2.1859e-01,\n",
            "        5.0591e-01, 4.2949e-01, 6.4788e-01, 7.3537e-01, 6.8081e-01, 4.9336e-01,\n",
            "        3.7936e-01, 1.8682e-01, 9.3480e-01, 9.6403e-01, 9.5755e-01, 2.0983e-01,\n",
            "        3.2981e-01, 2.6018e-01, 1.9521e-01, 1.0000e+00, 1.9425e-01, 1.7800e-01,\n",
            "        3.3020e-01, 2.2892e-01, 1.7305e-01, 1.1489e-01, 1.7305e-01, 2.5814e-01,\n",
            "        3.1713e-02, 2.4599e-01, 7.3681e-01, 8.7639e-01, 3.1134e-01, 2.3859e-01,\n",
            "        1.8228e-01, 6.1316e-02, 5.0000e-01, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        3.5821e-01, 9.2731e-01, 6.1776e-01, 4.9226e-01, 5.5287e-02, 3.4646e-01,\n",
            "        5.6952e-08, 1.1745e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 2.0843e-01,\n",
            "        1.2390e-01, 7.1432e-01, 9.8441e-01, 8.4236e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1226e-01, 7.9695e-01, 9.8598e-01, 1.5707e-01, 2.5786e-01, 1.9849e-01,\n",
            "        7.4080e-01, 4.6779e-01, 3.9661e-01, 1.8288e-01, 3.8798e-01, 1.0000e+00,\n",
            "        5.7715e-01, 8.7862e-24, 2.7733e-01, 3.9648e-01, 3.7923e-01, 5.3014e-05,\n",
            "        7.4960e-01, 2.8678e-01, 9.8384e-01, 0.0000e+00, 9.7969e-13, 3.3215e-01,\n",
            "        2.4530e-01, 9.6667e-01, 3.6190e-01, 4.7095e-01, 2.9949e-06, 9.9116e-01,\n",
            "        5.3014e-05, 5.1576e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.8135e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.4231e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 9.2413e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 9.7556e-01, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.5112e-01])\n",
            "Molecule 128: tensor([1.1865e-01, 7.7833e-01, 8.8489e-01, 8.9995e-01, 8.8725e-01, 8.8042e-01,\n",
            "        9.1787e-01, 8.9239e-01, 9.5292e-01, 9.3327e-01, 9.8126e-01, 9.7241e-01,\n",
            "        9.8847e-01, 9.8375e-01, 9.3459e-01, 8.2282e-01, 6.8936e-07, 8.9077e-01,\n",
            "        8.7537e-01, 4.6245e-01, 7.7689e-01, 5.4715e-01, 6.5971e-01, 3.7627e-01,\n",
            "        7.2425e-01, 8.7118e-01, 6.2435e-01, 6.6345e-01, 7.3200e-01, 8.7210e-01,\n",
            "        5.3071e-01, 8.8637e-01, 8.6331e-01, 1.0000e+00, 8.6184e-01, 6.4932e-01,\n",
            "        4.6261e-01, 8.8316e-01, 8.6879e-01, 5.0928e-01, 8.6879e-01, 8.6049e-01,\n",
            "        5.2229e-02, 8.6861e-01, 1.4999e-01, 4.7900e-01, 6.8064e-01, 8.4436e-01,\n",
            "        8.7579e-01, 4.3608e-01, 8.0633e-01, 1.0000e+00, 9.1873e-01, 9.8227e-01,\n",
            "        3.4723e-02, 8.6504e-01, 8.3758e-02, 9.1034e-01, 4.7447e-01, 6.2081e-01,\n",
            "        5.6952e-08, 3.3567e-01, 9.4955e-01, 9.8000e-01, 9.7743e-01, 9.2733e-01,\n",
            "        7.6607e-01, 4.5831e-01, 9.9825e-01, 8.3941e-01, 1.7356e-22, 8.9828e-01,\n",
            "        8.2521e-01, 6.3417e-01, 4.6098e-10, 1.5707e-01, 4.8573e-01, 9.8732e-01,\n",
            "        5.5946e-01, 6.6022e-01, 9.7524e-01, 9.1743e-01, 3.9730e-01, 1.6710e-01,\n",
            "        1.9343e-01, 9.9901e-01, 9.5515e-01, 2.2942e-01, 4.6908e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 7.9298e-01,\n",
            "        8.4683e-01, 9.8407e-01, 9.5516e-01, 5.5116e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.3463e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1548e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9786e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 8.8512e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 2.8154e-01])\n",
            "Molecule 129: tensor([3.2486e-01, 3.7952e-01, 4.4029e-01, 4.7815e-01, 5.6260e-01, 4.8246e-01,\n",
            "        5.8249e-01, 6.0387e-01, 6.1409e-01, 6.3541e-01, 6.9753e-01, 7.2097e-01,\n",
            "        7.5182e-01, 7.1784e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 4.2420e-01,\n",
            "        4.6822e-01, 7.9864e-01, 8.9280e-01, 5.4715e-01, 4.6477e-01, 8.1140e-01,\n",
            "        8.7795e-01, 5.4648e-01, 2.9491e-01, 4.0245e-01, 5.5903e-01, 5.8787e-01,\n",
            "        8.7338e-01, 4.7032e-01, 5.4563e-01, 1.0000e+00, 4.8643e-01, 5.2084e-01,\n",
            "        5.2613e-01, 5.6417e-01, 6.8547e-01, 1.3765e-01, 6.8547e-01, 2.7419e-01,\n",
            "        5.9997e-01, 2.6283e-01, 7.8185e-01, 8.5259e-01, 8.0890e-01, 5.6115e-01,\n",
            "        5.4826e-01, 6.1316e-02, 1.2405e-01, 9.9386e-22, 9.5785e-01, 9.3704e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 8.4739e-02, 5.5287e-02, 2.0751e-01,\n",
            "        5.6952e-08, 2.1430e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 4.7370e-01,\n",
            "        3.4481e-01, 5.7614e-21, 3.6088e-15, 8.4236e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1226e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 8.1824e-01, 8.8064e-01,\n",
            "        2.8479e-01, 7.9218e-01, 6.1441e-01, 1.8288e-01, 7.4170e-01, 1.6710e-01,\n",
            "        4.0799e-01, 8.7862e-24, 6.2409e-01, 7.4540e-01, 6.9526e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.9415e-01, 6.0563e-01,\n",
            "        7.2685e-01, 2.8631e-09, 6.6780e-01, 4.6659e-01, 1.0000e+00, 2.7764e-01,\n",
            "        5.3014e-05, 2.8430e-02, 5.3014e-05, 9.9887e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 7.7645e-01, 5.3014e-05, 9.9865e-01, 8.7742e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.3387e-01])\n",
            "Molecule 130: tensor([7.4258e-01, 4.8012e-01, 3.3834e-01, 2.1362e-01, 2.9379e-01, 2.8302e-01,\n",
            "        2.0784e-01, 4.0087e-01, 2.4527e-01, 4.8573e-01, 2.8476e-01, 4.4888e-01,\n",
            "        3.1384e-01, 4.5245e-01, 8.7662e-01, 7.9181e-01, 6.8936e-07, 8.7681e-01,\n",
            "        1.9674e-02, 4.2002e-01, 7.7290e-01, 7.5902e-01, 4.6477e-01, 2.3915e-11,\n",
            "        7.8075e-01, 3.9840e-01, 4.6913e-01, 3.5802e-01, 2.6416e-01, 1.4670e-01,\n",
            "        7.0247e-01, 3.0986e-01, 4.3301e-01, 1.0000e+00, 3.2384e-01, 1.9280e-01,\n",
            "        3.8106e-01, 3.1593e-01, 4.5369e-01, 8.3965e-02, 4.5369e-01, 3.4721e-01,\n",
            "        2.0393e-01, 3.3917e-01, 3.9404e-02, 9.0902e-01, 1.9703e-01, 2.6673e-01,\n",
            "        3.9600e-01, 7.0728e-01, 5.0000e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 3.0707e-01, 4.7447e-01, 6.2081e-01,\n",
            "        5.6952e-08, 1.1745e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 2.8653e-01,\n",
            "        8.7215e-03, 5.7614e-21, 3.6088e-15, 9.5350e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 9.2399e-01, 4.6098e-10, 1.5707e-01, 7.0538e-01, 1.7840e-01,\n",
            "        1.5343e-01, 7.7137e-01, 3.9661e-01, 7.3036e-01, 9.0409e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.8415e-01, 3.5430e-01, 1.6944e-01, 5.3766e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.0260e-01, 9.8384e-01, 0.0000e+00, 9.8549e-01, 1.9306e-01,\n",
            "        7.7209e-01, 2.8631e-09, 3.2822e-01, 6.4441e-01, 9.9949e-01, 2.7764e-01,\n",
            "        5.3014e-05, 7.5131e-01, 5.3014e-05, 9.9396e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 3.9982e-01, 1.7129e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 8.9864e-01, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.0000e+00, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 9.9996e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 9.0798e-01])\n",
            "Molecule 131: tensor([4.0563e-01, 1.3981e-01, 2.2905e-01, 2.4035e-01, 2.5830e-01, 2.1333e-01,\n",
            "        2.0102e-01, 2.8256e-01, 2.0889e-01, 2.9465e-01, 1.2634e-01, 2.1674e-01,\n",
            "        1.4435e-01, 2.4152e-01, 7.6509e-01, 5.3470e-01, 6.8936e-07, 2.1293e-01,\n",
            "        1.5930e-01, 6.7784e-01, 7.7532e-01, 5.3860e-01, 6.3236e-01, 4.6874e-01,\n",
            "        3.2997e-01, 2.4807e-01, 9.6213e-01, 9.6711e-01, 9.7101e-01, 7.3367e-01,\n",
            "        8.5658e-01, 2.1432e-01, 2.4302e-01, 1.0000e+00, 3.3083e-01, 5.0563e-01,\n",
            "        6.1280e-01, 2.2899e-01, 8.3932e-02, 5.8099e-01, 8.3932e-02, 6.7842e-01,\n",
            "        5.1921e-01, 6.6717e-01, 4.1759e-01, 4.0852e-01, 1.5440e-01, 2.4808e-01,\n",
            "        2.4314e-01, 4.3608e-01, 6.9483e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.4723e-02, 8.6504e-01, 8.3758e-02, 8.2272e-01, 4.7447e-01, 6.2081e-01,\n",
            "        5.6952e-08, 7.7335e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 2.5274e-01,\n",
            "        3.2016e-01, 7.1075e-01, 9.8659e-01, 1.4598e-01, 9.7644e-01, 1.1809e-10,\n",
            "        9.3672e-01, 9.0550e-08, 9.8858e-01, 1.5707e-01, 6.0306e-26, 2.1620e-01,\n",
            "        5.6961e-01, 6.5877e-01, 1.2027e-01, 3.0365e-01, 4.1142e-01, 1.6710e-01,\n",
            "        4.2847e-01, 9.8334e-01, 3.8138e-01, 7.4871e-01, 3.3654e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.1443e-01, 6.9527e-13, 0.0000e+00, 9.8575e-01, 6.9776e-01,\n",
            "        5.6670e-01, 9.6277e-01, 1.8645e-01, 3.0315e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 6.3106e-01, 5.3014e-05, 9.5242e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 6.9372e-01, 2.4344e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.0000e+00, 7.1316e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        1.0000e+00, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.0000e+00, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 9.9920e-01,\n",
            "        1.6663e-01, 2.5755e-01])\n",
            "Molecule 132: tensor([8.7529e-01, 3.0666e-01, 1.7032e-01, 1.0191e-01, 1.5157e-01, 1.7140e-01,\n",
            "        1.0845e-01, 1.2960e-01, 1.0616e-01, 1.3470e-01, 1.2191e-01, 1.3850e-01,\n",
            "        1.3983e-01, 1.4922e-01, 7.8375e-01, 5.2530e-01, 6.8936e-07, 1.9882e-01,\n",
            "        7.3924e-01, 2.5099e-11, 9.2584e-11, 8.8130e-01, 1.0887e-06, 4.7097e-01,\n",
            "        8.7795e-01, 2.3742e-01, 6.0096e-01, 6.3054e-01, 7.3200e-01, 9.0756e-02,\n",
            "        7.8433e-01, 1.7312e-01, 2.7572e-01, 1.0000e+00, 1.5350e-01, 1.2826e-01,\n",
            "        3.4298e-01, 2.0336e-01, 1.7652e-01, 1.8286e-01, 1.7652e-01, 6.1787e-01,\n",
            "        8.1751e-01, 6.0052e-01, 1.1737e-01, 8.0574e-01, 2.8071e-01, 1.7363e-01,\n",
            "        2.3546e-01, 7.0728e-01, 3.0517e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 3.0707e-01, 7.3166e-01, 4.9077e-01,\n",
            "        5.6952e-08, 1.6146e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.6066e-01,\n",
            "        3.7704e-01, 6.8850e-01, 3.6088e-15, 8.4953e-01, 9.7781e-01, 1.1809e-10,\n",
            "        3.1226e-01, 8.0793e-01, 4.6098e-10, 1.5707e-01, 6.9937e-01, 1.1369e-01,\n",
            "        1.4111e-01, 6.3372e-01, 3.9661e-01, 3.2655e-01, 9.1703e-01, 1.6710e-01,\n",
            "        1.9343e-01, 9.8334e-01, 1.0963e-01, 1.8391e-01, 5.1842e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.1443e-01, 9.8384e-01, 0.0000e+00, 9.9415e-01, 3.5044e-01,\n",
            "        2.4530e-01, 2.8631e-09, 1.8085e-01, 4.4790e-01, 1.0000e+00, 2.7764e-01,\n",
            "        5.3014e-05, 5.1960e-01, 5.3014e-05, 9.9886e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 3.9982e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.0000e+00, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.3056e-01])\n",
            "Molecule 133: tensor([8.5344e-01, 5.2530e-02, 2.9397e-02, 2.6759e-02, 1.7848e-02, 3.2309e-02,\n",
            "        3.7448e-02, 2.3478e-02, 4.3039e-02, 2.3693e-02, 6.2954e-02, 3.6270e-02,\n",
            "        8.0580e-02, 4.8447e-02, 5.8883e-01, 2.6487e-01, 6.8936e-07, 8.1264e-01,\n",
            "        1.5575e-01, 1.7021e-01, 5.9417e-01, 5.5013e-01, 1.0887e-06, 1.5833e-01,\n",
            "        7.5637e-01, 2.4874e-02, 9.9369e-01, 9.9619e-01, 9.8996e-01, 8.0884e-01,\n",
            "        8.9763e-01, 3.0800e-02, 2.5116e-02, 1.0000e+00, 2.6569e-02, 3.0977e-02,\n",
            "        2.6147e-01, 2.2660e-02, 1.3501e-01, 2.4754e-01, 1.3501e-01, 8.8604e-01,\n",
            "        1.4021e-01, 8.9567e-01, 4.9169e-01, 7.3963e-01, 2.3314e-02, 1.9697e-02,\n",
            "        2.4254e-02, 8.4234e-01, 5.0000e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.4723e-02, 8.6504e-01, 8.3758e-02, 6.7960e-01, 7.3166e-01, 3.4646e-01,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 9.8000e-01, 8.8066e-01, 7.5730e-02,\n",
            "        6.3046e-01, 7.2713e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 8.9188e-01,\n",
            "        2.9709e-01, 6.3417e-01, 9.5662e-01, 1.5707e-01, 6.0306e-26, 1.2054e-01,\n",
            "        1.5012e-01, 5.0060e-01, 1.2027e-01, 3.2409e-01, 1.3393e-01, 1.6710e-01,\n",
            "        3.9553e-01, 8.7862e-24, 5.1642e-01, 4.2521e-01, 1.0308e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.6883e-01, 9.8441e-01, 0.0000e+00, 9.7969e-13, 3.3873e-01,\n",
            "        2.4246e-01, 2.8631e-09, 3.5431e-01, 1.0949e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 6.9403e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 8.5333e-01, 5.3014e-05, 9.9865e-01, 3.9574e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 1.0000e+00, 5.8371e-13, 9.0122e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 1.1816e-03, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.5162e-01])\n",
            "Molecule 134: tensor([8.8993e-01, 7.7354e-02, 6.8010e-02, 4.0024e-02, 2.7388e-02, 5.7083e-02,\n",
            "        4.5454e-02, 2.8696e-02, 5.8163e-02, 3.2899e-02, 8.2252e-02, 4.8347e-02,\n",
            "        8.9479e-02, 5.4114e-02, 9.2622e-01, 7.1388e-01, 6.8936e-07, 2.1617e-01,\n",
            "        1.9674e-02, 1.2153e-01, 7.7490e-01, 5.8561e-17, 1.0887e-06, 1.5833e-01,\n",
            "        7.5637e-01, 5.5790e-02, 9.6703e-01, 9.4812e-01, 7.8651e-01, 8.0884e-01,\n",
            "        8.8526e-01, 5.9953e-02, 5.8199e-02, 1.0000e+00, 6.8834e-02, 4.9863e-02,\n",
            "        2.6473e-01, 4.1165e-02, 1.4170e-01, 2.4725e-01, 1.4170e-01, 8.8620e-01,\n",
            "        3.2707e-01, 8.9585e-01, 1.4344e-01, 7.3992e-01, 5.0492e-03, 2.5906e-02,\n",
            "        5.4172e-02, 9.4482e-01, 8.0633e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.4723e-02, 8.6504e-01, 8.3758e-02, 9.1034e-01, 9.1805e-01, 6.2081e-01,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 9.8000e-01, 8.8066e-01, 1.0933e-01,\n",
            "        8.9603e-01, 9.3482e-01, 9.8682e-01, 1.4598e-01, 1.7356e-22, 8.9188e-01,\n",
            "        2.9709e-01, 6.3417e-01, 9.5662e-01, 1.5707e-01, 6.0306e-26, 4.0442e-02,\n",
            "        1.5012e-01, 2.4187e-01, 1.2027e-01, 7.8650e-01, 1.3393e-01, 1.6710e-01,\n",
            "        3.9553e-01, 8.7862e-24, 5.0471e-01, 4.2521e-01, 1.0308e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.6883e-01, 9.8441e-01, 0.0000e+00, 9.7969e-13, 7.1200e-01,\n",
            "        2.4246e-01, 2.8631e-09, 8.3482e-02, 1.0949e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.9958e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 4.2962e-01, 5.3014e-05, 0.0000e+00, 3.1772e-01, 2.0287e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 1.0000e+00, 5.8371e-13, 9.0122e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 1.1816e-03, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 2.8927e-01])\n",
            "Molecule 135: tensor([1.9608e-05, 2.6499e-02, 1.6905e-02, 3.1138e-02, 5.5667e-02, 1.3418e-02,\n",
            "        1.4229e-02, 9.0323e-03, 2.0811e-02, 1.0777e-02, 1.0531e-02, 5.6086e-03,\n",
            "        9.3217e-03, 5.2168e-03, 4.0749e-10, 2.6487e-01, 6.8936e-07, 7.6853e-01,\n",
            "        1.3693e-01, 2.5099e-11, 6.0630e-01, 7.8532e-01, 6.2000e-01, 2.3915e-11,\n",
            "        3.4911e-01, 8.1125e-02, 9.7443e-01, 9.3038e-01, 6.9648e-01, 4.5627e-01,\n",
            "        9.3409e-01, 2.1221e-02, 8.7520e-02, 1.0000e+00, 1.0155e-01, 1.4388e-01,\n",
            "        4.7870e-01, 3.6498e-02, 1.0539e-01, 1.0000e+00, 1.0539e-01, 9.5712e-01,\n",
            "        3.2429e-10, 9.6622e-01, 5.2710e-01, 6.6624e-12, 5.5484e-03, 1.0541e-02,\n",
            "        8.0346e-02, 6.1316e-02, 1.9367e-01, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        3.4723e-02, 8.6504e-01, 8.3758e-02, 8.4739e-02, 5.5287e-02, 2.0751e-01,\n",
            "        5.6952e-08, 1.6146e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 6.7352e-02,\n",
            "        9.0590e-01, 5.3289e-01, 9.9591e-01, 8.4886e-01, 1.7356e-22, 9.0093e-01,\n",
            "        5.9983e-02, 7.9364e-01, 4.6098e-10, 1.5707e-01, 6.0306e-26, 4.0442e-02,\n",
            "        4.7844e-01, 2.7501e-02, 2.6103e-02, 9.0597e-01, 1.3770e-01, 1.6710e-01,\n",
            "        1.9057e-01, 9.9096e-01, 1.9854e-02, 4.7872e-01, 1.1406e-01, 5.3014e-05,\n",
            "        6.9955e-01, 9.5779e-01, 9.7891e-01, 7.0981e-01, 9.7969e-13, 2.9151e-01,\n",
            "        3.5237e-01, 2.8631e-09, 8.2539e-03, 1.7979e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.7700e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.9628e-01, 5.3014e-05, 9.9865e-01, 3.9982e-01, 2.5705e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 3.9482e-01])\n",
            "Molecule 136: tensor([8.6476e-01, 2.5291e-02, 1.1835e-02, 1.8113e-02, 1.1832e-02, 1.5848e-02,\n",
            "        2.5509e-02, 1.5916e-02, 3.4811e-02, 1.8815e-02, 7.3680e-02, 4.2940e-02,\n",
            "        9.5567e-02, 5.8019e-02, 4.0749e-10, 2.6487e-01, 6.8936e-07, 4.2420e-01,\n",
            "        1.5575e-01, 3.1175e-01, 9.2584e-11, 5.2284e-01, 6.2799e-01, 1.5833e-01,\n",
            "        7.5225e-13, 8.6223e-03, 9.9040e-01, 9.9601e-01, 9.8108e-01, 5.7227e-01,\n",
            "        9.0053e-01, 1.4189e-02, 8.5480e-03, 1.0000e+00, 7.6046e-03, 9.8198e-03,\n",
            "        1.8322e-01, 1.2125e-02, 1.1686e-01, 1.4388e-01, 1.1686e-01, 2.5428e-01,\n",
            "        7.9484e-01, 2.4194e-01, 8.0857e-01, 8.4610e-01, 1.1407e-01, 1.2692e-02,\n",
            "        8.4843e-03, 6.1316e-02, 1.2405e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.4723e-02, 8.6504e-01, 8.3758e-02, 8.4739e-02, 5.5287e-02, 3.3458e-02,\n",
            "        5.6952e-08, 1.6146e-02, 0.0000e+00, 9.8000e-01, 8.8066e-01, 5.0851e-02,\n",
            "        1.2390e-01, 5.7614e-21, 3.6088e-15, 8.4236e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.2830e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 1.3924e-01, 1.1231e-01,\n",
            "        6.0644e-01, 2.1809e-01, 1.2027e-01, 1.8288e-01, 1.3514e-01, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 3.9050e-01, 2.4508e-01, 1.5527e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 2.4517e-01,\n",
            "        2.4530e-01, 2.8631e-09, 4.6993e-01, 1.7979e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.6788e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 8.9054e-01, 5.3014e-05, 9.9865e-01, 3.9982e-01, 2.2047e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.8322e-01])\n",
            "Molecule 137: tensor([4.3861e-02, 6.2716e-01, 4.4969e-01, 4.9948e-01, 4.4622e-01, 5.5204e-01,\n",
            "        5.8023e-01, 4.9987e-01, 5.8181e-01, 4.7216e-01, 6.5477e-01, 5.4089e-01,\n",
            "        6.8129e-01, 5.6400e-01, 4.0749e-10, 2.4211e-01, 6.8936e-07, 2.1615e-01,\n",
            "        1.9674e-02, 9.3419e-01, 8.8979e-01, 6.7084e-01, 4.6477e-01, 9.0193e-01,\n",
            "        3.2997e-01, 4.4254e-01, 1.3666e-01, 3.0578e-01, 5.2784e-01, 2.6714e-01,\n",
            "        3.8484e-01, 5.2333e-01, 4.3957e-01, 1.0000e+00, 3.5698e-01, 3.5983e-01,\n",
            "        4.2545e-01, 4.9541e-01, 6.5718e-01, 5.6802e-01, 6.5718e-01, 9.0209e-02,\n",
            "        7.6595e-01, 7.4930e-02, 6.3477e-01, 4.2127e-01, 8.2991e-01, 5.5383e-01,\n",
            "        4.3870e-01, 4.3608e-01, 1.9367e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        6.3529e-01, 9.2731e-01, 9.1765e-01, 1.6844e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 2.1430e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 4.7370e-01,\n",
            "        5.7301e-01, 4.7006e-01, 9.8411e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1932e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 2.5786e-01, 7.8970e-01,\n",
            "        9.5917e-01, 4.7021e-01, 8.8518e-01, 2.8385e-01, 3.6977e-01, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 1.1582e-01, 8.1156e-01, 8.0740e-01, 5.3014e-05,\n",
            "        7.3111e-01, 2.8678e-01, 9.9368e-01, 0.0000e+00, 9.7969e-13, 5.0862e-01,\n",
            "        3.2914e-01, 9.3864e-01, 7.4635e-02, 8.7973e-01, 2.9949e-06, 9.9346e-01,\n",
            "        5.3014e-05, 6.6645e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.0049e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        9.9999e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 9.9999e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        1.0000e+00, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 9.9991e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 4.3111e-01])\n",
            "Molecule 138: tensor([7.8949e-01, 5.4543e-02, 4.3223e-02, 5.7756e-02, 4.0601e-02, 4.1758e-02,\n",
            "        5.8990e-02, 3.7760e-02, 1.0190e-01, 6.0937e-02, 5.5672e-02, 3.1806e-02,\n",
            "        7.8666e-02, 4.7235e-02, 7.7859e-01, 2.6487e-01, 6.8936e-07, 2.1859e-01,\n",
            "        1.9674e-02, 1.4776e-01, 9.2584e-11, 3.8158e-01, 7.2505e-01, 1.6919e-01,\n",
            "        3.4911e-01, 2.9265e-02, 8.7482e-01, 7.8800e-01, 5.7003e-01, 4.1208e-01,\n",
            "        8.6237e-01, 4.3509e-02, 2.8158e-02, 1.0000e+00, 4.0379e-02, 3.5098e-02,\n",
            "        3.2557e-01, 3.9314e-02, 1.4323e-01, 1.4459e-01, 1.4323e-01, 4.3939e-01,\n",
            "        4.6499e-01, 4.3195e-01, 3.8821e-01, 8.4536e-01, 1.8423e-01, 4.7146e-02,\n",
            "        2.8527e-02, 4.3608e-01, 1.2405e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 8.4739e-02, 4.7447e-01, 3.3458e-02,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 9.8000e-01, 8.8066e-01, 8.0384e-02,\n",
            "        3.5789e-01, 4.6507e-01, 9.8635e-01, 1.4598e-01, 9.7781e-01, 1.1809e-10,\n",
            "        3.1226e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 6.3929e-01, 2.0418e-01,\n",
            "        8.0760e-02, 2.7501e-02, 1.2027e-01, 3.1121e-01, 2.4429e-01, 1.6710e-01,\n",
            "        2.0507e-01, 8.7862e-24, 5.2555e-01, 3.0449e-02, 2.8531e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.1443e-01, 6.9527e-13, 0.0000e+00, 9.7969e-13, 1.4627e-01,\n",
            "        4.6053e-01, 2.8631e-09, 3.6190e-01, 3.5673e-01, 2.9949e-06, 9.7324e-01,\n",
            "        5.3014e-05, 8.2246e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.6753e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.7766e-01])\n",
            "Molecule 139: tensor([6.4394e-01, 5.0001e-01, 4.2762e-01, 5.2398e-01, 4.7161e-01, 4.9598e-01,\n",
            "        5.3997e-01, 4.5838e-01, 5.3346e-01, 4.2200e-01, 4.9767e-01, 3.7796e-01,\n",
            "        5.5888e-01, 4.3184e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.9674e-02, 9.2695e-01, 9.2584e-11, 5.8561e-17, 5.8646e-01, 9.8715e-01,\n",
            "        5.9522e-01, 3.6755e-01, 1.3245e-01, 2.4526e-01, 4.4593e-01, 2.6714e-01,\n",
            "        4.1168e-01, 4.7032e-01, 3.5200e-01, 1.0000e+00, 3.8404e-01, 4.4608e-01,\n",
            "        4.6437e-01, 4.7347e-01, 1.5225e-02, 1.2622e-01, 1.5225e-02, 9.2924e-02,\n",
            "        9.9328e-01, 7.7527e-02, 8.9721e-01, 8.6452e-01, 7.9097e-01, 5.8930e-01,\n",
            "        3.6281e-01, 6.1316e-02, 1.9367e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        6.3529e-01, 8.6504e-01, 6.1776e-01, 3.0707e-01, 5.5287e-02, 9.8237e-02,\n",
            "        5.6952e-08, 3.3567e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 4.0646e-01,\n",
            "        3.4481e-01, 4.6303e-01, 9.8518e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 8.0793e-01, 4.6098e-10, 1.5707e-01, 7.7384e-01, 6.0694e-01,\n",
            "        5.4946e-01, 4.4763e-01, 6.1441e-01, 1.2446e-01, 5.6218e-01, 1.6710e-01,\n",
            "        4.1217e-01, 9.8334e-01, 1.1339e-01, 8.2291e-01, 8.5752e-01, 5.3014e-05,\n",
            "        1.4266e-16, 2.8678e-01, 9.9749e-01, 0.0000e+00, 9.7969e-13, 6.1912e-01,\n",
            "        1.2049e-11, 2.8631e-09, 3.2027e-01, 9.2422e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.1051e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.9994e-01, 5.3014e-05, 9.9865e-01, 7.5609e-01, 2.4593e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.0000e+00, 8.4442e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.2324e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.8691e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 9.9991e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.1587e-01])\n",
            "Molecule 140: tensor([8.1587e-01, 7.4600e-02, 7.3330e-02, 1.3390e-01, 1.0147e-01, 8.0748e-02,\n",
            "        2.2779e-01, 1.6777e-01, 4.1554e-01, 3.0833e-01, 6.0228e-01, 4.8366e-01,\n",
            "        7.0318e-01, 5.8962e-01, 4.0749e-10, 2.8232e-01, 6.8936e-07, 4.0590e-01,\n",
            "        3.1840e-01, 3.3275e-01, 9.5031e-01, 5.8561e-17, 5.3771e-01, 4.0762e-01,\n",
            "        4.0535e-01, 5.8544e-02, 8.3588e-01, 9.0886e-01, 9.6816e-01, 8.8349e-01,\n",
            "        9.4154e-01, 8.0716e-02, 4.7910e-02, 1.0000e+00, 7.0306e-02, 4.2591e-02,\n",
            "        2.2733e-01, 8.4282e-02, 5.1402e-02, 9.5674e-01, 5.1402e-02, 4.7766e-02,\n",
            "        3.2361e-01, 3.5946e-02, 7.5798e-01, 1.9729e-02, 4.2389e-01, 1.0992e-01,\n",
            "        5.6908e-02, 8.4234e-01, 7.9832e-02, 1.0000e+00, 1.4249e-01, 9.3704e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 8.4739e-02, 7.3166e-01, 7.2855e-03,\n",
            "        5.6952e-08, 2.1523e-03, 8.9543e-01, 1.1424e-21, 8.8066e-01, 1.2411e-01,\n",
            "        3.9871e-01, 4.6640e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 9.0550e-08, 4.6098e-10, 1.5707e-01, 5.8437e-01, 6.8104e-01,\n",
            "        2.4640e-01, 2.7501e-02, 3.9661e-01, 1.8842e-01, 7.3182e-02, 1.6710e-01,\n",
            "        7.5581e-02, 9.9644e-01, 8.5784e-01, 3.0449e-02, 1.4894e-01, 5.3014e-05,\n",
            "        6.9955e-01, 3.4216e-01, 6.9527e-13, 7.0981e-01, 9.7969e-13, 4.9478e-02,\n",
            "        5.5008e-01, 9.3953e-01, 8.3283e-01, 1.1842e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 1.4247e-01, 5.3014e-05, 5.0000e-01, 3.8471e-01, 5.3014e-05,\n",
            "        5.3014e-05, 9.9997e-01, 5.3014e-05, 9.9865e-01, 7.9083e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.0000e+00, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.9964e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 9.6562e-01,\n",
            "        9.6582e-01, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.3764e-01])\n",
            "Molecule 141: tensor([8.6465e-01, 5.5436e-02, 7.4724e-02, 1.2981e-01, 9.8060e-02, 8.8583e-02,\n",
            "        1.3753e-01, 9.4993e-02, 1.5924e-01, 1.0033e-01, 1.4493e-01, 8.9743e-02,\n",
            "        1.6903e-01, 1.0697e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.4158e-01, 4.6784e-01, 6.2858e-01, 5.8561e-17, 5.3892e-01, 9.7311e-01,\n",
            "        7.5225e-13, 5.2112e-02, 2.9491e-01, 3.1689e-01, 2.6416e-01, 4.2030e-01,\n",
            "        8.5058e-01, 8.0716e-02, 4.5563e-02, 1.0000e+00, 9.6661e-02, 2.3287e-01,\n",
            "        4.3949e-01, 8.4655e-02, 1.3960e-02, 1.1149e-01, 1.3960e-02, 1.7019e-02,\n",
            "        9.1775e-01, 1.0788e-02, 8.3925e-01, 8.7996e-01, 4.3705e-01, 1.2540e-01,\n",
            "        5.0675e-02, 6.1316e-02, 7.9832e-02, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 8.4739e-02, 5.5287e-02, 7.2855e-03,\n",
            "        5.6952e-08, 3.3567e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.0933e-01,\n",
            "        1.2390e-01, 5.7614e-21, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.2497e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 6.3917e-01, 5.9480e-01,\n",
            "        4.1484e-01, 2.7501e-02, 1.2027e-01, 1.2446e-01, 7.3182e-02, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 2.4256e-01, 6.4409e-01, 6.4754e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 4.0299e-01,\n",
            "        1.2049e-11, 2.8631e-09, 4.5231e-01, 6.6744e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 1.7069e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.7861e-01, 5.3014e-05, 9.9865e-01, 6.2822e-01, 2.4596e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.3945e-01])\n",
            "Molecule 142: tensor([8.8078e-01, 8.1944e-02, 1.4090e-01, 2.1865e-01, 1.7478e-01, 1.3956e-01,\n",
            "        1.9080e-01, 1.3720e-01, 2.2494e-01, 1.4874e-01, 1.9615e-01, 1.2579e-01,\n",
            "        1.6871e-01, 1.0674e-01, 5.8402e-01, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.6109e-01, 4.4883e-01, 9.2584e-11, 5.8561e-17, 7.4366e-01, 7.4667e-01,\n",
            "        3.4911e-01, 9.9897e-02, 3.9597e-01, 3.5802e-01, 2.8109e-01, 4.9043e-01,\n",
            "        8.4226e-01, 1.3706e-01, 8.7870e-02, 1.0000e+00, 1.9236e-01, 2.7923e-01,\n",
            "        4.4278e-01, 1.4281e-01, 1.8827e-02, 1.8065e-01, 1.8827e-02, 6.1779e-02,\n",
            "        9.5958e-01, 4.8426e-02, 4.2235e-01, 8.0802e-01, 3.7663e-01, 1.8040e-01,\n",
            "        9.7097e-02, 6.1316e-02, 1.2405e-01, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 1.6844e-01, 5.5287e-02, 3.3458e-02,\n",
            "        5.6952e-08, 4.6631e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.6066e-01,\n",
            "        3.3645e-01, 4.5831e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.2497e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 6.3917e-01, 4.8380e-01,\n",
            "        2.7627e-01, 4.8433e-01, 1.2027e-01, 1.8189e-01, 7.3182e-02, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 2.4684e-01, 7.6150e-01, 6.4754e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 5.2757e-01,\n",
            "        4.9310e-01, 2.8631e-09, 3.3447e-01, 6.6744e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 3.2309e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.6606e-01, 2.4445e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.5395e-01])\n",
            "Molecule 143: tensor([1.9608e-05, 2.1735e-01, 6.0164e-01, 5.8465e-01, 5.3553e-01, 4.9768e-01,\n",
            "        4.8167e-01, 3.9997e-01, 4.5349e-01, 3.4361e-01, 3.1260e-01, 2.1482e-01,\n",
            "        2.2162e-01, 1.4408e-01, 8.4735e-01, 5.1130e-01, 6.8936e-07, 4.5585e-01,\n",
            "        1.6109e-01, 4.4883e-01, 9.2584e-11, 5.8561e-17, 7.4366e-01, 7.4667e-01,\n",
            "        7.4212e-01, 4.9359e-01, 2.9491e-01, 1.5421e-01, 8.3343e-02, 5.3930e-01,\n",
            "        4.9475e-01, 5.2333e-01, 4.6868e-01, 1.0000e+00, 7.5360e-01, 8.6227e-01,\n",
            "        8.6451e-01, 5.1746e-01, 4.8718e-02, 7.3297e-01, 4.8718e-02, 7.5799e-01,\n",
            "        8.6300e-01, 7.5602e-01, 1.8401e-01, 2.5787e-01, 3.6123e-01, 5.0260e-01,\n",
            "        4.9062e-01, 7.0728e-01, 6.9483e-01, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 4.9226e-01, 7.3166e-01, 4.9077e-01,\n",
            "        5.6952e-08, 7.7335e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 5.8690e-01,\n",
            "        7.8129e-01, 4.5831e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 9.6111e-01,\n",
            "        8.2521e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 6.3917e-01, 4.8380e-01,\n",
            "        2.7627e-01, 8.3993e-01, 1.2027e-01, 8.5760e-01, 2.4328e-01, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 5.1994e-01, 7.6150e-01, 6.4754e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 8.0509e-01,\n",
            "        7.7866e-01, 2.8631e-09, 5.9466e-01, 6.6744e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.6798e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.6606e-01, 2.4445e-02,\n",
            "        1.0000e+00, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.0000e+00, 1.0000e+00, 7.9714e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.4069e-01])\n",
            "Molecule 144: tensor([6.0266e-01, 9.3414e-02, 5.4575e-02, 5.7744e-02, 4.0592e-02, 6.5232e-02,\n",
            "        5.6971e-02, 3.6390e-02, 4.8607e-02, 2.7049e-02, 4.2718e-02, 2.4006e-02,\n",
            "        4.3049e-02, 2.5143e-02, 4.0749e-10, 2.6487e-01, 6.8936e-07, 4.1130e-01,\n",
            "        3.3882e-01, 1.4776e-01, 9.2584e-11, 5.6633e-01, 6.5200e-01, 4.8966e-01,\n",
            "        3.3637e-01, 4.1887e-02, 9.0997e-01, 9.1371e-01, 8.5590e-01, 1.9703e-01,\n",
            "        7.2851e-01, 5.9953e-02, 4.3254e-02, 1.0000e+00, 5.0858e-02, 1.1140e-01,\n",
            "        4.0860e-01, 4.8588e-02, 1.4666e-01, 1.7723e-01, 1.4666e-01, 6.8401e-01,\n",
            "        8.3616e-01, 6.7339e-01, 5.7087e-01, 8.1155e-01, 1.1829e-01, 4.4870e-02,\n",
            "        4.0740e-02, 7.0728e-01, 3.0517e-01, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 3.0707e-01, 7.3166e-01, 2.0751e-01,\n",
            "        5.6952e-08, 2.1430e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 9.0742e-02,\n",
            "        1.1070e-01, 4.6698e-01, 9.8463e-01, 1.4598e-01, 9.7781e-01, 1.1809e-10,\n",
            "        6.5154e-01, 6.6396e-01, 4.6098e-10, 1.5707e-01, 6.2752e-01, 7.0363e-02,\n",
            "        2.7312e-01, 2.7501e-02, 1.2027e-01, 3.0276e-01, 1.3514e-01, 1.6710e-01,\n",
            "        6.4777e-01, 8.7862e-24, 2.6860e-01, 3.0449e-02, 4.6177e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.4265e-01, 6.9527e-13, 0.0000e+00, 9.7969e-13, 4.8566e-02,\n",
            "        3.2914e-01, 9.4722e-01, 4.1445e-01, 4.3946e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 4.1607e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.4830e-01, 5.3014e-05, 9.9865e-01, 7.9059e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 8.3841e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 1.0000e+00, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.1146e-01])\n",
            "Molecule 145: tensor([6.0184e-01, 2.9400e-01, 5.0175e-01, 5.9702e-01, 6.1746e-01, 4.5758e-01,\n",
            "        6.5314e-01, 7.3855e-01, 6.5907e-01, 7.7627e-01, 7.5580e-01, 8.7608e-01,\n",
            "        8.3751e-01, 9.1284e-01, 7.4684e-01, 6.6681e-01, 6.8936e-07, 2.2228e-01,\n",
            "        7.9120e-01, 8.6229e-01, 7.3404e-01, 3.8126e-01, 5.9677e-01, 6.3952e-01,\n",
            "        7.5225e-13, 5.2055e-01, 7.5470e-01, 7.3142e-01, 6.7616e-01, 9.3932e-01,\n",
            "        9.2899e-01, 4.7032e-01, 4.7725e-01, 1.0000e+00, 6.0970e-01, 5.5716e-01,\n",
            "        5.4341e-01, 5.0050e-01, 4.7230e-01, 9.5535e-01, 4.7230e-01, 6.3977e-01,\n",
            "        4.6976e-01, 6.2444e-01, 4.5260e-02, 2.1102e-02, 2.1354e-01, 5.2876e-01,\n",
            "        5.1844e-01, 7.0728e-01, 5.0000e-01, 9.9995e-01, 9.1873e-01, 9.3704e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 3.0707e-01, 7.3166e-01, 4.9077e-01,\n",
            "        5.6952e-08, 5.8913e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 5.8690e-01,\n",
            "        1.3143e-01, 4.6640e-01, 3.6088e-15, 1.4598e-01, 9.9187e-01, 1.1809e-10,\n",
            "        3.1932e-01, 9.0550e-08, 9.9403e-01, 1.5707e-01, 5.9327e-01, 8.0909e-01,\n",
            "        7.5884e-01, 2.7501e-02, 3.9661e-01, 5.1901e-01, 2.0655e-01, 1.6710e-01,\n",
            "        5.4580e-01, 9.8764e-01, 8.6629e-01, 7.4540e-01, 1.4894e-01, 5.3014e-05,\n",
            "        6.9955e-01, 2.7506e-01, 6.9527e-13, 7.0981e-01, 9.7969e-13, 8.1846e-01,\n",
            "        8.3536e-01, 9.3953e-01, 7.8276e-01, 1.1842e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 4.9683e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.9951e-01, 5.3014e-05, 9.9865e-01, 9.4494e-01, 1.7465e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.0000e+00, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.8691e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 9.6562e-01,\n",
            "        9.6582e-01, 2.1135e-02, 2.1135e-02, 9.9998e-01, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.4531e-01])\n",
            "Molecule 146: tensor([9.0938e-01, 5.7283e-02, 4.3223e-02, 4.8259e-02, 3.3466e-02, 4.5304e-02,\n",
            "        6.1006e-02, 3.9134e-02, 6.3932e-02, 3.6483e-02, 1.2620e-01, 7.7049e-02,\n",
            "        1.4570e-01, 9.1059e-02, 5.8058e-01, 5.1130e-01, 6.8936e-07, 6.0806e-01,\n",
            "        1.5575e-01, 1.4776e-01, 9.2584e-11, 5.8561e-17, 6.8081e-01, 3.3818e-01,\n",
            "        7.5225e-13, 3.0048e-02, 7.9826e-01, 6.8871e-01, 4.7321e-01, 4.5627e-01,\n",
            "        8.4853e-01, 4.3509e-02, 2.9770e-02, 1.0000e+00, 3.8971e-02, 3.3401e-02,\n",
            "        2.0943e-01, 3.6871e-02, 2.1486e-01, 9.7809e-02, 2.1486e-01, 4.0948e-01,\n",
            "        7.0751e-01, 4.0264e-01, 2.7976e-01, 8.9437e-01, 5.5675e-02, 3.6306e-02,\n",
            "        2.9279e-02, 7.0728e-01, 1.9367e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 1.6844e-01, 7.3166e-01, 9.8237e-02,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 9.8000e-01, 8.8066e-01, 8.0384e-02,\n",
            "        8.7215e-03, 4.5490e-01, 3.6088e-15, 8.4236e-01, 9.7781e-01, 1.1809e-10,\n",
            "        9.3441e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 6.4995e-01, 6.7408e-02,\n",
            "        8.0760e-02, 2.3924e-01, 1.2027e-01, 3.1354e-01, 2.4047e-01, 1.6710e-01,\n",
            "        4.4803e-01, 8.7862e-24, 3.9050e-01, 2.2721e-01, 2.1106e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.3223e-01, 6.9527e-13, 0.0000e+00, 9.7969e-13, 1.5757e-01,\n",
            "        6.5882e-01, 2.8631e-09, 3.5071e-01, 2.5614e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 2.8591e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 7.7306e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 8.3841e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 8.9864e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.0000e+00, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.9400e-01])\n",
            "Molecule 147: tensor([2.2932e-01, 6.5785e-01, 4.4969e-01, 5.7601e-01, 5.2635e-01, 5.5557e-01,\n",
            "        6.5574e-01, 5.8032e-01, 6.7903e-01, 5.7964e-01, 7.3404e-01, 6.3325e-01,\n",
            "        7.9537e-01, 7.0481e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.9674e-02, 7.2125e-01, 9.5632e-01, 5.8561e-17, 1.0887e-06, 9.9544e-01,\n",
            "        7.5225e-13, 4.0703e-01, 7.6218e-02, 1.5421e-01, 4.2138e-01, 2.8716e-01,\n",
            "        4.6679e-01, 5.2333e-01, 3.8523e-01, 1.0000e+00, 3.7171e-01, 3.7895e-01,\n",
            "        4.0712e-01, 5.3045e-01, 1.0538e-02, 1.1495e-01, 1.0538e-02, 1.9364e-02,\n",
            "        9.9535e-01, 1.2547e-02, 9.0339e-01, 8.7633e-01, 8.9466e-01, 6.4537e-01,\n",
            "        4.0281e-01, 6.1316e-02, 7.9832e-02, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        9.6401e-01, 8.6504e-01, 9.1765e-01, 8.4739e-02, 5.5287e-02, 7.2855e-03,\n",
            "        5.6952e-08, 3.3567e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 4.5099e-01,\n",
            "        3.2778e-01, 5.7614e-21, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 9.0550e-08, 4.6098e-10, 1.5707e-01, 9.0618e-01, 6.8703e-01,\n",
            "        8.4298e-01, 1.9647e-01, 8.8518e-01, 1.2446e-01, 2.2068e-01, 1.6710e-01,\n",
            "        3.9129e-01, 8.7862e-24, 5.2790e-01, 4.6377e-01, 9.4757e-01, 5.3014e-05,\n",
            "        6.9901e-01, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 2.4968e-01,\n",
            "        8.7407e-01, 2.8631e-09, 4.2672e-01, 9.2923e-01, 2.9949e-06, 9.9098e-01,\n",
            "        5.3014e-05, 1.0166e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 7.6640e-01, 2.2417e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        9.9990e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 9.6402e-01, 1.6148e-09,\n",
            "        9.8691e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 3.0179e-01])\n",
            "Molecule 148: tensor([8.4578e-01, 9.9198e-04, 1.5287e-04, 7.5986e-04, 4.9785e-04, 2.6420e-04,\n",
            "        3.1935e-03, 2.4523e-03, 8.3181e-03, 4.0003e-03, 1.5164e-02, 8.1455e-03,\n",
            "        2.4593e-02, 1.4086e-02, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.9674e-02, 1.5706e-01, 9.0337e-01, 5.8561e-17, 1.0887e-06, 2.2144e-01,\n",
            "        7.5225e-13, 1.1323e-04, 6.5094e-01, 2.4526e-01, 3.8419e-02, 9.9939e-01,\n",
            "        9.8801e-01, 2.0747e-04, 7.5548e-05, 1.0000e+00, 6.6989e-05, 3.0239e-04,\n",
            "        9.0722e-02, 2.5327e-04, 1.0286e-02, 2.2152e-02, 1.0286e-02, 4.5928e-03,\n",
            "        9.9630e-01, 1.0126e-02, 9.0698e-01, 9.7553e-01, 2.2387e-01, 5.7323e-04,\n",
            "        1.1578e-04, 6.1316e-02, 3.3330e-02, 9.9995e-01, 1.4249e-01, 5.0000e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 1.8976e-02, 5.5287e-02, 5.2300e-05,\n",
            "        5.6952e-08, 2.1523e-03, 8.9543e-01, 1.1424e-21, 8.8066e-01, 2.3155e-02,\n",
            "        8.7215e-03, 5.7614e-21, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 9.0550e-08, 4.6098e-10, 1.5707e-01, 5.8923e-01, 3.9922e-02,\n",
            "        8.0760e-02, 2.7501e-02, 2.6103e-02, 1.2446e-01, 7.3182e-02, 1.6710e-01,\n",
            "        7.5581e-02, 9.8764e-01, 6.3677e-01, 3.0449e-02, 2.5837e-02, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 2.6428e-04,\n",
            "        1.2049e-11, 9.3953e-01, 6.2138e-01, 3.0994e-02, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 6.1714e-03, 5.3014e-05, 5.0000e-01, 3.8471e-01, 5.3014e-05,\n",
            "        5.3014e-05, 9.9998e-01, 5.3014e-05, 9.9865e-01, 7.9423e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 2.5609e-01])\n",
            "Molecule 149: tensor([7.5413e-01, 2.5553e-01, 1.0748e-01, 1.3242e-01, 1.0024e-01, 1.4851e-01,\n",
            "        1.7752e-01, 1.2647e-01, 2.2343e-01, 1.4759e-01, 2.7161e-01, 1.8235e-01,\n",
            "        2.9304e-01, 1.9742e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 2.1859e-01,\n",
            "        4.9633e-01, 6.8336e-01, 9.2584e-11, 6.7193e-01, 5.9128e-01, 5.8919e-01,\n",
            "        7.5225e-13, 9.2063e-02, 7.1569e-01, 7.8800e-01, 8.8934e-01, 3.4363e-01,\n",
            "        6.2786e-01, 1.3706e-01, 9.5688e-02, 1.0000e+00, 5.2187e-02, 3.2312e-02,\n",
            "        2.0706e-01, 1.1720e-01, 3.4605e-01, 1.2044e-01, 3.4605e-01, 4.7477e-01,\n",
            "        5.6872e-01, 4.6463e-01, 6.8623e-01, 8.7057e-01, 3.1363e-01, 1.3064e-01,\n",
            "        8.9443e-02, 4.3608e-01, 3.0517e-01, 9.9995e-01, 9.1873e-01, 9.3704e-01,\n",
            "        3.4723e-02, 9.2731e-01, 3.8583e-01, 3.0707e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 1.6146e-02, 8.9543e-01, 1.1424e-21, 8.8066e-01, 1.3232e-01,\n",
            "        3.6632e-01, 4.7009e-01, 9.8518e-01, 1.4598e-01, 9.7781e-01, 1.1809e-10,\n",
            "        3.1226e-01, 8.0774e-01, 4.6098e-10, 1.5707e-01, 6.0306e-26, 5.6536e-01,\n",
            "        4.3285e-01, 4.4148e-01, 6.1441e-01, 1.8288e-01, 5.7280e-01, 1.6710e-01,\n",
            "        4.1633e-01, 8.7862e-24, 5.2790e-01, 3.5570e-01, 2.8191e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.1165e-01, 9.9753e-01, 0.0000e+00, 9.7969e-13, 2.2647e-01,\n",
            "        1.2049e-11, 9.4722e-01, 5.5424e-01, 2.6004e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 2.8478e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 7.6107e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.0122e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 7.1316e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.4279e-01,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.8691e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.0000e+00, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 9.3412e-01])\n",
            "Molecule 150: tensor([2.7158e-01, 6.0942e-01, 6.9489e-01, 7.5790e-01, 7.2540e-01, 7.2354e-01,\n",
            "        7.4898e-01, 6.8492e-01, 6.7047e-01, 5.6981e-01, 7.5447e-01, 6.5827e-01,\n",
            "        7.6452e-01, 6.6491e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 2.2029e-01,\n",
            "        6.6064e-01, 9.3737e-01, 6.3250e-01, 5.9246e-01, 6.2666e-01, 8.5924e-01,\n",
            "        7.2425e-01, 6.6610e-01, 2.9491e-01, 2.7045e-01, 2.7464e-01, 5.7227e-01,\n",
            "        3.3335e-01, 7.0653e-01, 6.4587e-01, 1.0000e+00, 6.9353e-01, 7.3203e-01,\n",
            "        5.6661e-01, 7.0303e-01, 4.5574e-01, 8.4470e-01, 4.5574e-01, 8.9197e-01,\n",
            "        8.8660e-01, 9.0186e-01, 5.5646e-01, 1.4250e-01, 5.8337e-01, 7.3958e-01,\n",
            "        6.6724e-01, 4.3608e-01, 6.9483e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        6.3529e-01, 8.6504e-01, 6.1776e-01, 6.7960e-01, 4.7447e-01, 4.9077e-01,\n",
            "        5.6952e-08, 6.9263e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 7.5824e-01,\n",
            "        8.7195e-01, 4.6338e-01, 9.9561e-01, 1.4598e-01, 1.7356e-22, 8.9828e-01,\n",
            "        3.1932e-01, 6.3417e-01, 4.6098e-10, 1.5707e-01, 3.6664e-01, 4.5026e-01,\n",
            "        9.6072e-01, 8.5821e-01, 6.1441e-01, 7.6033e-01, 5.5095e-01, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 2.6574e-01, 9.6566e-01, 4.6650e-01, 5.3014e-05,\n",
            "        7.3205e-01, 7.7904e-01, 9.8384e-01, 7.7327e-01, 9.7969e-13, 8.7213e-01,\n",
            "        5.2486e-01, 2.8631e-09, 4.3928e-01, 4.6659e-01, 2.9949e-06, 9.8573e-01,\n",
            "        5.3014e-05, 4.1419e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.9995e-01, 5.3014e-05, 9.9865e-01, 9.3194e-01, 2.3478e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        9.9999e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 9.9999e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 8.8512e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9994e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 9.9991e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 4.1673e-01])\n",
            "Molecule 151: tensor([1.6660e-01, 5.6054e-01, 6.0795e-01, 7.1676e-01, 6.7942e-01, 6.3923e-01,\n",
            "        6.8510e-01, 6.1260e-01, 6.5138e-01, 5.4814e-01, 7.5994e-01, 6.6506e-01,\n",
            "        7.7402e-01, 6.7705e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.9674e-02, 9.6180e-01, 8.8154e-01, 7.1776e-01, 5.8558e-01, 8.6621e-01,\n",
            "        7.2425e-01, 5.7248e-01, 1.1084e-01, 1.2747e-01, 1.8026e-01, 6.0077e-01,\n",
            "        4.5884e-01, 6.2199e-01, 5.4216e-01, 1.0000e+00, 5.9902e-01, 6.1185e-01,\n",
            "        4.9932e-01, 6.2616e-01, 1.6574e-02, 8.6072e-01, 1.6574e-02, 9.8562e-02,\n",
            "        9.8735e-01, 8.2950e-02, 8.8543e-01, 1.2528e-01, 6.1909e-01, 6.9351e-01,\n",
            "        5.7132e-01, 4.3608e-01, 5.0000e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        6.3529e-01, 8.6504e-01, 6.1776e-01, 4.9226e-01, 4.7447e-01, 3.4646e-01,\n",
            "        5.6952e-08, 5.8913e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 6.7047e-01,\n",
            "        8.7195e-01, 4.6640e-01, 9.9561e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1932e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 2.5786e-01, 4.5026e-01,\n",
            "        9.7819e-01, 8.6761e-01, 6.1441e-01, 5.5851e-01, 3.6774e-01, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 2.6574e-01, 9.6672e-01, 3.6919e-01, 5.3014e-05,\n",
            "        7.4942e-01, 8.8651e-01, 9.8384e-01, 8.0466e-01, 9.7969e-13, 8.3941e-01,\n",
            "        3.2335e-01, 9.4722e-01, 1.8085e-01, 3.5656e-01, 2.9949e-06, 9.8573e-01,\n",
            "        5.3014e-05, 1.8070e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 9.3511e-01, 2.5631e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        9.9999e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 9.9999e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 8.8512e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9999e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.7467e-01])\n",
            "Molecule 152: tensor([1.6998e-01, 4.7967e-01, 4.9462e-01, 6.2181e-01, 5.7539e-01, 5.4479e-01,\n",
            "        6.2161e-01, 5.4351e-01, 6.0000e-01, 4.9158e-01, 7.1331e-01, 6.0838e-01,\n",
            "        7.3046e-01, 6.2244e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.9674e-02, 9.3992e-01, 8.8154e-01, 5.9246e-01, 4.6477e-01, 9.5528e-01,\n",
            "        5.7634e-01, 4.5852e-01, 1.7973e-01, 1.8399e-01, 2.2057e-01, 5.5726e-01,\n",
            "        5.3867e-01, 5.2333e-01, 4.2699e-01, 1.0000e+00, 4.7868e-01, 5.1065e-01,\n",
            "        4.7043e-01, 5.2879e-01, 1.6481e-02, 8.4470e-01, 1.6481e-02, 9.8562e-02,\n",
            "        9.8785e-01, 8.2950e-02, 8.8623e-01, 1.4250e-01, 6.1693e-01, 6.1869e-01,\n",
            "        4.5497e-01, 4.3608e-01, 3.0517e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        6.3529e-01, 8.6504e-01, 6.1776e-01, 3.0707e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 4.6631e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 5.4216e-01,\n",
            "        7.6726e-01, 5.7614e-21, 9.9561e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1932e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 3.6664e-01, 4.5026e-01,\n",
            "        9.8821e-01, 5.5795e-01, 6.1441e-01, 3.0890e-01, 3.6774e-01, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 2.6574e-01, 9.4817e-01, 4.6650e-01, 5.3014e-05,\n",
            "        7.3205e-01, 7.7904e-01, 9.8384e-01, 7.7327e-01, 9.7969e-13, 7.8421e-01,\n",
            "        3.2335e-01, 9.4722e-01, 1.8085e-01, 4.6659e-01, 2.9949e-06, 9.8573e-01,\n",
            "        5.3014e-05, 9.7558e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 9.3767e-01, 2.3631e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        9.9999e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 9.9999e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9994e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 9.9991e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.8357e-01])\n",
            "Molecule 153: tensor([1.7716e-01, 9.9416e-01, 9.9376e-01, 9.9379e-01, 9.9367e-01, 9.9216e-01,\n",
            "        9.9240e-01, 9.9135e-01, 9.9240e-01, 9.8946e-01, 9.9371e-01, 9.9102e-01,\n",
            "        9.9074e-01, 9.8710e-01, 9.6929e-01, 9.8255e-01, 6.8936e-07, 9.8941e-01,\n",
            "        5.4446e-01, 3.3878e-01, 9.9744e-01, 9.0471e-01, 4.4641e-01, 4.8016e-01,\n",
            "        8.2051e-01, 9.9258e-01, 1.9061e-01, 1.8044e-01, 1.8362e-01, 8.3139e-01,\n",
            "        2.6875e-02, 9.9280e-01, 9.9212e-01, 1.0000e+00, 9.9280e-01, 9.8490e-01,\n",
            "        9.1563e-01, 9.9282e-01, 9.2122e-01, 9.5066e-01, 9.2122e-01, 7.8940e-01,\n",
            "        2.7340e-01, 7.9096e-01, 8.2101e-02, 2.5871e-02, 8.0576e-01, 9.9182e-01,\n",
            "        9.9357e-01, 9.6460e-01, 9.9409e-01, 1.0000e+00, 9.7853e-01, 9.8620e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 9.9959e-01, 9.6947e-01, 9.8148e-01,\n",
            "        5.6952e-08, 3.3567e-01, 8.9543e-01, 9.8000e-01, 9.4279e-01, 9.9520e-01,\n",
            "        9.8998e-01, 8.5593e-01, 9.9564e-01, 1.4598e-01, 9.9385e-01, 9.6022e-01,\n",
            "        9.6721e-01, 6.4468e-01, 4.6098e-10, 1.5707e-01, 8.5797e-01, 3.4710e-01,\n",
            "        9.9971e-01, 9.9145e-01, 9.9534e-01, 9.6199e-01, 7.4391e-01, 1.6710e-01,\n",
            "        8.3649e-01, 9.9909e-01, 9.8167e-01, 8.3562e-01, 7.7999e-01, 5.3014e-05,\n",
            "        7.3205e-01, 8.1074e-01, 6.9527e-13, 7.7327e-01, 9.7969e-13, 9.8525e-01,\n",
            "        8.4683e-01, 9.8883e-01, 9.9068e-01, 6.4768e-01, 2.9949e-06, 9.7167e-01,\n",
            "        5.3014e-05, 9.8427e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.6996e-01, 2.1636e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.0000e+00, 1.6650e-01, 1.6649e-01, 9.4294e-01, 9.8352e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 8.3841e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.0000e+00, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 9.0665e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 1.0000e+00, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.8021e-01, 5.1007e-08,\n",
            "        7.1054e-15, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 9.6562e-01,\n",
            "        9.6582e-01, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 4.5456e-02])\n",
            "Molecule 154: tensor([7.1813e-01, 4.3206e-01, 2.9097e-01, 2.7323e-01, 2.2440e-01, 3.1118e-01,\n",
            "        3.5935e-01, 2.8353e-01, 4.2019e-01, 3.1259e-01, 4.9552e-01, 3.7590e-01,\n",
            "        5.1122e-01, 3.8499e-01, 8.4458e-01, 8.1482e-01, 6.8936e-07, 5.5759e-01,\n",
            "        6.7155e-01, 6.1469e-01, 7.7490e-01, 3.8126e-01, 5.1037e-01, 1.6919e-01,\n",
            "        7.5225e-13, 2.7275e-01, 7.9826e-01, 7.2386e-01, 6.0316e-01, 5.9243e-01,\n",
            "        6.3530e-01, 3.0986e-01, 2.7620e-01, 1.0000e+00, 2.1991e-01, 1.4384e-01,\n",
            "        3.1971e-01, 2.6049e-01, 9.0869e-01, 6.9796e-01, 9.0869e-01, 8.6595e-01,\n",
            "        6.2392e-01, 8.7445e-01, 1.4840e-01, 2.9294e-01, 1.3604e-01, 2.5869e-01,\n",
            "        2.6749e-01, 7.0728e-01, 5.0000e-01, 9.9995e-01, 9.1873e-01, 9.3704e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 4.9226e-01, 7.3166e-01, 4.9077e-01,\n",
            "        5.6952e-08, 1.1745e-01, 8.9543e-01, 9.8000e-01, 9.4279e-01, 3.0469e-01,\n",
            "        7.8241e-01, 7.0625e-01, 3.6088e-15, 8.3034e-01, 1.7356e-22, 8.9828e-01,\n",
            "        3.1226e-01, 7.8931e-01, 4.6098e-10, 1.5707e-01, 6.0306e-26, 1.9621e-01,\n",
            "        9.2611e-01, 4.3954e-01, 6.1441e-01, 5.6307e-01, 5.5095e-01, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 3.9050e-01, 8.1156e-01, 2.5855e-01, 5.3014e-05,\n",
            "        1.4266e-16, 8.1510e-01, 9.9368e-01, 0.0000e+00, 9.7969e-13, 6.0465e-01,\n",
            "        1.2049e-11, 9.3864e-01, 5.6302e-01, 1.6433e-01, 2.9949e-06, 9.8573e-01,\n",
            "        5.3014e-05, 5.1947e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.3575e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 1.0000e+00, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.0000e+00, 1.0000e+00, 5.0000e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 9.6951e-01])\n",
            "Molecule 155: tensor([7.8098e-01, 5.9210e-01, 5.5501e-01, 5.0514e-01, 4.5206e-01, 4.9204e-01,\n",
            "        5.3307e-01, 4.5137e-01, 6.6162e-01, 5.5972e-01, 6.4357e-01, 5.2843e-01,\n",
            "        7.2238e-01, 6.1262e-01, 9.3145e-01, 7.0447e-01, 1.0000e+00, 8.9819e-01,\n",
            "        3.6384e-01, 4.7614e-01, 5.9417e-01, 3.4031e-01, 5.5287e-01, 1.6919e-01,\n",
            "        4.0535e-01, 5.0888e-01, 7.4118e-01, 4.7783e-01, 2.8862e-01, 6.9390e-01,\n",
            "        5.3071e-01, 5.2333e-01, 5.0982e-01, 1.0000e+00, 4.7726e-01, 2.5047e-01,\n",
            "        3.6558e-01, 4.6334e-01, 9.4659e-01, 6.9796e-01, 9.4659e-01, 8.6595e-01,\n",
            "        9.5749e-02, 8.7445e-01, 1.2640e-01, 2.9294e-01, 2.0455e-01, 4.4462e-01,\n",
            "        5.0612e-01, 9.0949e-01, 6.9483e-01, 9.9995e-01, 9.1873e-01, 9.3704e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 6.7960e-01, 8.5589e-01, 7.2707e-01,\n",
            "        5.6952e-08, 1.1745e-01, 8.9543e-01, 9.8000e-01, 9.4279e-01, 5.6470e-01,\n",
            "        8.9391e-01, 7.0202e-01, 9.9571e-01, 8.3034e-01, 1.7356e-22, 8.9828e-01,\n",
            "        3.1226e-01, 8.7191e-01, 4.6098e-10, 1.5707e-01, 6.0306e-26, 2.2396e-01,\n",
            "        8.5942e-01, 6.3912e-01, 6.1441e-01, 7.5122e-01, 7.2051e-01, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 7.7431e-01, 7.0437e-01, 1.8749e-01, 5.3014e-05,\n",
            "        1.4266e-16, 9.1740e-01, 9.9811e-01, 0.0000e+00, 9.7969e-13, 5.8899e-01,\n",
            "        1.2049e-11, 9.6753e-01, 7.6503e-01, 7.1197e-02, 2.9949e-06, 9.8573e-01,\n",
            "        5.3014e-05, 7.7212e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.9484e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 1.0000e+00, 1.0000e+00, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.0000e+00, 1.0000e+00, 5.0000e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 5.9826e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.2324e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.5897e-01])\n",
            "Molecule 156: tensor([7.4634e-01, 5.1821e-01, 4.2338e-01, 4.3607e-01, 3.8167e-01, 4.0070e-01,\n",
            "        4.8614e-01, 4.0438e-01, 5.9194e-01, 4.8293e-01, 6.3331e-01, 5.1713e-01,\n",
            "        6.5634e-01, 5.3558e-01, 8.4458e-01, 7.0447e-01, 1.0000e+00, 8.8743e-01,\n",
            "        6.7155e-01, 4.8369e-01, 6.4788e-01, 5.6633e-01, 5.1037e-01, 3.8601e-01,\n",
            "        7.5225e-13, 3.7920e-01, 9.3099e-01, 9.1206e-01, 8.1786e-01, 6.9390e-01,\n",
            "        6.3530e-01, 4.1623e-01, 3.7243e-01, 1.0000e+00, 3.5326e-01, 2.0271e-01,\n",
            "        3.4765e-01, 3.7412e-01, 9.3259e-01, 6.9796e-01, 9.3259e-01, 8.6595e-01,\n",
            "        7.1064e-01, 8.7445e-01, 1.4884e-01, 2.9294e-01, 2.3881e-01, 3.8444e-01,\n",
            "        3.7442e-01, 7.0728e-01, 5.0000e-01, 9.9995e-01, 9.1873e-01, 9.3704e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 4.9226e-01, 7.3166e-01, 4.9077e-01,\n",
            "        5.6952e-08, 1.1745e-01, 8.9543e-01, 9.8000e-01, 9.4279e-01, 4.2854e-01,\n",
            "        7.8241e-01, 7.0625e-01, 3.6088e-15, 8.3034e-01, 1.7356e-22, 8.9828e-01,\n",
            "        3.1226e-01, 7.8931e-01, 4.6098e-10, 1.5707e-01, 6.0306e-26, 3.4687e-01,\n",
            "        9.2359e-01, 6.3912e-01, 6.1441e-01, 5.6307e-01, 5.5095e-01, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 7.1447e-01, 7.1857e-01, 2.5223e-01, 5.3014e-05,\n",
            "        1.4266e-16, 8.1510e-01, 9.9368e-01, 0.0000e+00, 9.7969e-13, 5.9688e-01,\n",
            "        1.2049e-11, 9.7035e-01, 7.4949e-01, 1.0949e-01, 2.9949e-06, 9.8573e-01,\n",
            "        5.3014e-05, 5.1947e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1677e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 1.0000e+00, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.0000e+00, 1.0000e+00, 5.0000e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 9.5537e-01])\n",
            "Molecule 157: tensor([7.8691e-01, 2.1371e-01, 2.0545e-01, 2.9840e-01, 2.4783e-01, 2.1998e-01,\n",
            "        3.3416e-01, 2.6058e-01, 4.4136e-01, 3.3220e-01, 5.1906e-01, 3.9871e-01,\n",
            "        5.6859e-01, 4.4168e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 2.0552e-01,\n",
            "        1.3785e-01, 7.8374e-01, 6.2858e-01, 5.8561e-17, 6.7748e-01, 8.4297e-01,\n",
            "        7.5225e-13, 1.5318e-01, 2.9491e-01, 2.6338e-01, 3.4841e-01, 4.8529e-01,\n",
            "        7.8970e-01, 2.1432e-01, 1.3717e-01, 1.0000e+00, 2.1021e-01, 1.9844e-01,\n",
            "        3.3820e-01, 2.2245e-01, 7.3180e-01, 1.1148e-01, 7.3180e-01, 1.1675e-01,\n",
            "        8.6101e-01, 1.0069e-01, 5.2286e-01, 8.7997e-01, 5.7787e-01, 2.8296e-01,\n",
            "        1.4924e-01, 6.1316e-02, 7.9832e-02, 9.9995e-01, 1.4249e-01, 5.0000e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 8.4739e-02, 5.5287e-02, 7.2855e-03,\n",
            "        5.6952e-08, 2.1430e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 2.0843e-01,\n",
            "        1.2390e-01, 5.7614e-21, 9.8503e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1226e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 8.2687e-01, 7.3499e-01,\n",
            "        1.4111e-01, 1.9234e-01, 3.9661e-01, 1.8288e-01, 1.3346e-01, 1.6710e-01,\n",
            "        1.9057e-01, 8.7862e-24, 5.0727e-01, 6.4409e-01, 7.2395e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 4.1890e-01,\n",
            "        5.5008e-01, 2.8631e-09, 6.4886e-01, 6.6516e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 2.2685e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.4374e-01, 5.3014e-05, 9.9865e-01, 5.9945e-01, 2.4499e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 9.2713e-01])\n",
            "Molecule 158: tensor([9.2520e-01, 1.8602e-01, 1.8515e-01, 1.7620e-01, 2.4446e-01, 1.7709e-01,\n",
            "        1.9937e-01, 2.2844e-01, 1.5482e-01, 1.9456e-01, 1.5700e-01, 1.7787e-01,\n",
            "        1.5711e-01, 1.7163e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 2.1524e-01,\n",
            "        4.4299e-01, 6.9513e-01, 6.4433e-01, 5.4760e-01, 6.2210e-01, 3.8601e-01,\n",
            "        8.7795e-01, 2.3763e-01, 6.9791e-01, 7.1400e-01, 7.3200e-01, 2.9406e-01,\n",
            "        8.8029e-01, 1.7312e-01, 2.4610e-01, 1.0000e+00, 2.6913e-01, 4.0922e-01,\n",
            "        5.0760e-01, 2.4116e-01, 2.6638e-01, 2.2325e-01, 2.6638e-01, 1.4608e-01,\n",
            "        4.0545e-01, 1.2998e-01, 7.0841e-01, 7.6434e-01, 7.9950e-01, 2.6987e-01,\n",
            "        2.3575e-01, 4.3608e-01, 7.9832e-02, 9.9995e-01, 1.4249e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 8.4739e-02, 4.7447e-01, 9.8237e-02,\n",
            "        5.6952e-08, 3.3567e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.8301e-01,\n",
            "        1.3928e-01, 5.7614e-21, 9.8503e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1226e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 8.2805e-01, 3.0140e-01,\n",
            "        6.5976e-01, 2.0383e-01, 1.2027e-01, 1.8288e-01, 8.4900e-01, 1.6710e-01,\n",
            "        2.0507e-01, 8.7862e-24, 4.0938e-01, 2.2721e-01, 6.1124e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.1443e-01, 6.9527e-13, 0.0000e+00, 9.9415e-01, 6.3175e-02,\n",
            "        2.4530e-01, 2.8631e-09, 4.8787e-01, 6.3851e-01, 9.9949e-01, 9.7134e-01,\n",
            "        5.3014e-05, 4.2219e-02, 5.3014e-05, 9.9892e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.3243e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 9.6071e-01,\n",
            "        1.6663e-01, 5.5238e-01])\n",
            "Molecule 159: tensor([8.8782e-01, 2.5277e-01, 2.8916e-01, 2.1102e-01, 2.2286e-01, 2.5150e-01,\n",
            "        2.1542e-01, 1.9884e-01, 1.8786e-01, 1.7244e-01, 1.6701e-01, 1.3838e-01,\n",
            "        1.6969e-01, 1.2866e-01, 7.7694e-01, 6.8190e-01, 6.8936e-07, 5.8624e-01,\n",
            "        7.6658e-01, 1.6119e-01, 7.7320e-01, 7.5902e-01, 1.0887e-06, 1.6919e-01,\n",
            "        7.9226e-01, 2.8345e-01, 7.4653e-01, 6.4552e-01, 5.7434e-01, 2.0983e-01,\n",
            "        6.3900e-01, 2.6018e-01, 2.9722e-01, 1.0000e+00, 3.4842e-01, 4.4878e-01,\n",
            "        5.9430e-01, 2.6898e-01, 7.7979e-01, 2.2332e-01, 7.7979e-01, 2.3298e-01,\n",
            "        7.9189e-01, 2.1962e-01, 4.3619e-01, 7.6428e-01, 3.7064e-01, 2.5449e-01,\n",
            "        2.7990e-01, 8.4234e-01, 1.9367e-01, 9.9995e-01, 1.4249e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 1.6844e-01, 7.3166e-01, 3.4646e-01,\n",
            "        5.6952e-08, 4.6631e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 2.5274e-01,\n",
            "        4.0966e-01, 4.7058e-01, 9.8503e-01, 8.4236e-01, 1.7356e-22, 1.1809e-10,\n",
            "        6.1801e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 4.5814e-01, 5.3833e-01,\n",
            "        5.4119e-01, 2.0383e-01, 1.2027e-01, 5.4535e-01, 7.3881e-01, 1.6710e-01,\n",
            "        2.0507e-01, 9.8692e-01, 2.5414e-01, 2.2721e-01, 6.2394e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.5194e-01, 9.7588e-01, 0.0000e+00, 9.8549e-01, 1.5530e-01,\n",
            "        4.6290e-01, 2.8631e-09, 3.3949e-01, 6.5275e-01, 9.9949e-01, 9.7134e-01,\n",
            "        5.3014e-05, 4.8741e-01, 5.3014e-05, 9.9353e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 4.9235e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 5.9826e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 1.0000e+00,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 9.6071e-01,\n",
            "        1.6663e-01, 5.3889e-01])\n",
            "Molecule 160: tensor([4.2421e-01, 9.6414e-02, 2.1623e-01, 3.7535e-01, 3.2152e-01, 1.8920e-01,\n",
            "        5.1286e-01, 4.3098e-01, 8.2361e-01, 7.5690e-01, 9.4283e-01, 9.1480e-01,\n",
            "        9.5980e-01, 9.4047e-01, 5.8402e-01, 5.2530e-01, 6.8936e-07, 5.5086e-01,\n",
            "        8.6570e-01, 3.3275e-01, 9.0337e-01, 5.8561e-17, 1.0887e-06, 6.0185e-01,\n",
            "        3.4911e-01, 1.9009e-01, 3.8626e-01, 3.9414e-01, 5.4310e-01, 9.9808e-01,\n",
            "        9.7067e-01, 2.1432e-01, 1.5321e-01, 1.0000e+00, 2.1036e-01, 5.4192e-02,\n",
            "        2.2807e-01, 2.3051e-01, 1.6441e-01, 5.9062e-01, 1.6441e-01, 7.6629e-01,\n",
            "        3.6780e-02, 7.6528e-01, 4.3256e-01, 3.9905e-01, 5.3562e-01, 2.0657e-01,\n",
            "        1.8554e-01, 4.3608e-01, 1.2405e-01, 1.0000e+00, 9.1873e-01, 9.7600e-01,\n",
            "        3.4723e-02, 4.8299e-15, 1.1178e-02, 1.6844e-01, 4.7447e-01, 3.3458e-02,\n",
            "        5.6952e-08, 2.1523e-03, 9.4955e-01, 9.8000e-01, 9.7743e-01, 2.8653e-01,\n",
            "        3.4705e-01, 5.7614e-21, 3.6088e-15, 1.4598e-01, 1.7356e-22, 8.9828e-01,\n",
            "        3.1226e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 2.8953e-01, 9.6175e-01,\n",
            "        2.5494e-01, 4.8060e-01, 6.1441e-01, 5.8229e-01, 1.3599e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9957e-01, 9.1628e-01, 2.2942e-01, 2.5837e-02, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 2.5428e-01,\n",
            "        4.6053e-01, 9.9037e-01, 9.2348e-01, 3.0994e-02, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 1.4513e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 9.3569e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.9994e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        1.0000e+00, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.6664e-01])\n",
            "Molecule 161: tensor([1.9608e-05, 2.4209e-01, 1.6422e-01, 3.0343e-01, 2.9641e-01, 1.7717e-01,\n",
            "        2.0480e-01, 1.8877e-01, 2.0113e-01, 1.8456e-01, 2.4392e-01, 2.0076e-01,\n",
            "        2.8098e-01, 2.2839e-01, 5.8402e-01, 2.1752e-08, 6.8936e-07, 4.8551e-01,\n",
            "        2.9842e-01, 5.6581e-01, 9.2584e-11, 5.8561e-17, 7.2502e-01, 6.3617e-01,\n",
            "        7.7261e-01, 2.9075e-01, 7.6306e-01, 7.1761e-01, 6.8655e-01, 2.9406e-01,\n",
            "        8.4226e-01, 2.1432e-01, 2.9900e-01, 1.0000e+00, 3.2574e-01, 2.7229e-01,\n",
            "        3.7929e-01, 3.1036e-01, 1.8682e-02, 1.0000e+00, 1.8682e-02, 9.9999e-01,\n",
            "        3.2429e-10, 1.0000e+00, 3.6111e-01, 6.6624e-12, 1.1142e-01, 2.4437e-01,\n",
            "        2.8898e-01, 4.3608e-01, 1.2405e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 1.6844e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 2.2235e-01,\n",
            "        8.4288e-01, 5.7614e-21, 9.8419e-01, 1.4598e-01, 9.7851e-01, 5.7988e-01,\n",
            "        5.9983e-02, 9.0550e-08, 9.5673e-01, 1.5707e-01, 7.0538e-01, 4.6150e-01,\n",
            "        3.9518e-01, 2.0344e-01, 3.9661e-01, 7.4795e-01, 5.7539e-01, 1.6710e-01,\n",
            "        2.0507e-01, 9.8334e-01, 4.0263e-01, 2.2721e-01, 6.2712e-01, 5.3014e-05,\n",
            "        1.4266e-16, 8.6204e-01, 9.8384e-01, 0.0000e+00, 9.8549e-01, 6.6158e-02,\n",
            "        4.9310e-01, 2.8631e-09, 5.0920e-01, 6.4614e-01, 9.9949e-01, 2.7764e-01,\n",
            "        5.3014e-05, 5.8543e-02, 5.3014e-05, 9.9416e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.9987e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.0000e+00, 2.7743e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 1.0000e+00, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 9.7351e-01])\n",
            "Molecule 162: tensor([9.4446e-01, 7.8362e-02, 1.9935e-02, 1.5289e-02, 2.8922e-02, 2.2470e-02,\n",
            "        2.0053e-02, 2.7835e-02, 2.1234e-02, 3.3920e-02, 3.1868e-02, 5.5998e-02,\n",
            "        4.4351e-02, 5.1534e-02, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        6.4553e-01, 2.8491e-01, 9.2584e-11, 5.5013e-01, 5.2418e-01, 1.6207e-01,\n",
            "        9.2742e-01, 3.9776e-02, 8.4555e-01, 7.8800e-01, 7.9741e-01, 2.7430e-01,\n",
            "        9.6005e-01, 2.1221e-02, 4.6537e-02, 1.0000e+00, 2.1528e-02, 2.3323e-02,\n",
            "        2.0617e-01, 3.1387e-02, 1.7777e-02, 1.3158e-01, 1.7777e-02, 2.3794e-02,\n",
            "        9.6436e-01, 1.5965e-02, 8.6227e-01, 8.5892e-01, 2.4278e-01, 3.3916e-02,\n",
            "        3.9595e-02, 7.0728e-01, 1.2405e-01, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 1.6844e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 6.0065e-02,\n",
            "        1.5543e-01, 5.7614e-21, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.0473e-01, 9.0550e-08, 9.5805e-01, 1.5707e-01, 4.4967e-01, 6.8268e-02,\n",
            "        2.5712e-01, 8.8399e-01, 1.2027e-01, 1.2446e-01, 8.4007e-01, 1.6710e-01,\n",
            "        4.0702e-01, 9.8692e-01, 1.1582e-01, 2.2721e-01, 1.4138e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.4216e-01, 6.9527e-13, 0.0000e+00, 9.9415e-01, 1.2180e-01,\n",
            "        3.2914e-01, 2.8631e-09, 8.2539e-03, 1.1947e-01, 1.0000e+00, 9.8573e-01,\n",
            "        5.3014e-05, 1.2112e-01, 5.3014e-05, 9.9878e-01, 3.8471e-01, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 6.5891e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.0122e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 1.1816e-03, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 9.3141e-01])\n",
            "Molecule 163: tensor([7.3992e-01, 1.8547e-01, 1.6137e-01, 2.7434e-01, 2.2542e-01, 1.8468e-01,\n",
            "        3.6933e-01, 2.9272e-01, 3.9142e-01, 2.8653e-01, 4.5979e-01, 3.4223e-01,\n",
            "        6.4757e-01, 5.2578e-01, 4.0749e-10, 2.8232e-01, 6.8936e-07, 1.0022e-01,\n",
            "        3.2237e-01, 3.3275e-01, 9.7427e-01, 5.8561e-17, 5.3771e-01, 8.4066e-01,\n",
            "        7.5225e-13, 1.2818e-01, 3.9088e-01, 3.7668e-01, 4.3829e-01, 6.9390e-01,\n",
            "        8.7514e-01, 1.7312e-01, 1.0841e-01, 1.0000e+00, 1.7511e-01, 1.9986e-01,\n",
            "        3.6129e-01, 1.8283e-01, 5.6132e-02, 9.5663e-01, 5.6132e-02, 4.8209e-02,\n",
            "        9.2314e-01, 3.6333e-02, 8.4129e-01, 1.9835e-02, 6.8389e-01, 2.6478e-01,\n",
            "        1.2474e-01, 4.3608e-01, 7.9832e-02, 9.9995e-01, 1.4249e-01, 5.0000e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 8.4739e-02, 4.7447e-01, 7.2855e-03,\n",
            "        5.6952e-08, 3.3567e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.9532e-01,\n",
            "        1.3143e-01, 4.6640e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1932e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 5.8153e-01, 9.5553e-01,\n",
            "        1.4787e-01, 2.7501e-02, 3.9661e-01, 1.8842e-01, 2.1796e-01, 1.6710e-01,\n",
            "        1.9057e-01, 8.7862e-24, 7.8084e-01, 4.4851e-01, 2.7840e-01, 5.3014e-05,\n",
            "        6.9955e-01, 3.7316e-02, 6.9527e-13, 7.0981e-01, 9.7969e-13, 3.7501e-01,\n",
            "        5.8571e-01, 2.8631e-09, 6.9979e-01, 2.5614e-01, 2.9949e-06, 9.8554e-01,\n",
            "        5.3014e-05, 2.8270e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.8123e-01, 5.3014e-05, 9.9865e-01, 9.3049e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.0000e+00, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 9.6562e-01,\n",
            "        9.6582e-01, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 9.6772e-01])\n",
            "Molecule 164: tensor([3.4372e-01, 5.5555e-01, 8.9251e-01, 9.4836e-01, 9.4279e-01, 8.8346e-01,\n",
            "        9.6035e-01, 9.4877e-01, 9.6778e-01, 9.5441e-01, 9.6791e-01, 9.5231e-01,\n",
            "        9.6322e-01, 9.4567e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 4.1015e-01,\n",
            "        6.6894e-01, 8.4879e-01, 9.9781e-01, 5.8561e-17, 1.0887e-06, 9.5654e-01,\n",
            "        5.7634e-01, 8.7389e-01, 5.1213e-01, 5.2267e-01, 5.7257e-01, 9.6081e-01,\n",
            "        8.1982e-01, 8.8637e-01, 8.3816e-01, 1.0000e+00, 9.2541e-01, 9.2619e-01,\n",
            "        8.3140e-01, 9.0761e-01, 7.0655e-01, 7.4713e-01, 7.0655e-01, 7.8478e-01,\n",
            "        5.4021e-01, 7.8584e-01, 5.5670e-01, 2.4359e-01, 9.9698e-01, 9.3008e-01,\n",
            "        8.7853e-01, 6.1316e-02, 1.9367e-01, 9.9995e-01, 9.5785e-01, 9.6456e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 3.0707e-01, 5.5287e-02, 9.8237e-02,\n",
            "        5.6952e-08, 8.7684e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 9.4538e-01,\n",
            "        5.7641e-01, 8.4713e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 8.9828e-01,\n",
            "        3.1226e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 9.0351e-01, 9.9930e-01,\n",
            "        1.5343e-01, 1.9837e-01, 6.1441e-01, 5.6176e-01, 2.3442e-01, 1.6710e-01,\n",
            "        1.9057e-01, 9.9654e-01, 9.8959e-01, 6.2211e-01, 1.4498e-01, 5.3014e-05,\n",
            "        7.3205e-01, 5.7279e-01, 6.9527e-13, 7.7327e-01, 9.7969e-13, 5.0936e-01,\n",
            "        2.4530e-01, 9.6808e-01, 9.9862e-01, 1.1448e-01, 2.9949e-06, 9.7067e-01,\n",
            "        5.3014e-05, 8.4877e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 9.7284e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.8691e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 8.4753e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 9.6071e-01,\n",
            "        1.6663e-01, 3.8749e-02])\n",
            "Molecule 165: tensor([8.1132e-01, 1.1192e-01, 1.7575e-01, 2.6497e-01, 2.1677e-01, 1.8158e-01,\n",
            "        2.1951e-01, 1.6085e-01, 2.2413e-01, 1.4812e-01, 1.8060e-01, 1.1464e-01,\n",
            "        1.5716e-01, 9.8834e-02, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.9674e-02, 7.0380e-01, 6.2858e-01, 4.1465e-01, 6.5259e-01, 9.1283e-01,\n",
            "        3.4911e-01, 1.3294e-01, 2.9491e-01, 3.7668e-01, 2.6416e-01, 4.9043e-01,\n",
            "        7.5009e-01, 1.7312e-01, 1.1746e-01, 1.0000e+00, 2.3186e-01, 4.3396e-01,\n",
            "        5.9073e-01, 1.7995e-01, 1.5644e-02, 8.8004e-01, 1.5644e-02, 5.8253e-02,\n",
            "        9.9141e-01, 4.5243e-02, 8.9282e-01, 1.0420e-01, 3.1521e-01, 2.3855e-01,\n",
            "        1.2935e-01, 6.1316e-02, 1.9367e-01, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 3.0707e-01, 5.5287e-02, 9.8237e-02,\n",
            "        5.6952e-08, 5.8913e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.9532e-01,\n",
            "        5.8399e-01, 7.1225e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 6.4348e-01, 4.6098e-10, 1.5707e-01, 3.6664e-01, 5.7477e-01,\n",
            "        6.0554e-01, 2.6337e-01, 1.2027e-01, 1.8189e-01, 1.3393e-01, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 1.1582e-01, 8.8605e-01, 4.7411e-01, 5.3014e-05,\n",
            "        6.9955e-01, 5.8155e-01, 9.8441e-01, 7.0981e-01, 9.7969e-13, 6.3946e-01,\n",
            "        3.2914e-01, 2.8631e-09, 7.2529e-02, 5.5714e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 4.0727e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 8.2503e-01, 2.6587e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 7.1316e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.1311e-01])\n",
            "Molecule 166: tensor([5.0259e-02, 7.5925e-01, 6.8568e-01, 7.2319e-01, 7.3916e-01, 7.1779e-01,\n",
            "        7.0594e-01, 7.5470e-01, 6.9175e-01, 7.3979e-01, 5.6930e-01, 6.5326e-01,\n",
            "        5.7156e-01, 6.4516e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 2.0928e-01,\n",
            "        6.7554e-01, 7.6052e-01, 7.5054e-01, 6.6331e-01, 6.8501e-01, 9.2914e-01,\n",
            "        3.2997e-01, 6.9844e-01, 4.2306e-01, 5.7588e-01, 7.6167e-01, 3.6548e-01,\n",
            "        3.9245e-01, 7.0653e-01, 6.9156e-01, 1.0000e+00, 7.0158e-01, 7.8084e-01,\n",
            "        7.1045e-01, 7.2377e-01, 3.7192e-01, 5.8099e-01, 3.7192e-01, 6.2867e-01,\n",
            "        7.4806e-01, 6.1228e-01, 6.4167e-01, 4.0852e-01, 7.6487e-01, 7.9155e-01,\n",
            "        7.0060e-01, 7.0728e-01, 5.0000e-01, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        6.3529e-01, 9.2731e-01, 9.1765e-01, 6.7960e-01, 7.3166e-01, 4.9077e-01,\n",
            "        5.6952e-08, 8.3334e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 7.2563e-01,\n",
            "        7.7478e-01, 7.1075e-01, 3.6088e-15, 8.4332e-01, 9.7548e-01, 1.1809e-10,\n",
            "        3.1226e-01, 9.0550e-08, 9.9361e-01, 1.5707e-01, 7.1132e-01, 5.4315e-01,\n",
            "        7.3053e-01, 4.8420e-01, 6.1441e-01, 1.7656e-01, 7.2643e-01, 1.6710e-01,\n",
            "        5.9045e-01, 8.7862e-24, 3.8692e-01, 8.1876e-01, 9.1812e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.4380e-01, 9.8495e-01, 0.0000e+00, 9.8575e-01, 5.9597e-01,\n",
            "        7.5249e-01, 2.8631e-09, 4.3232e-01, 8.6833e-01, 2.9949e-06, 9.8554e-01,\n",
            "        5.3014e-05, 5.1404e-01, 5.3014e-05, 9.5433e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 7.0398e-01, 2.4397e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.0122e-01,\n",
            "        9.9999e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 8.3841e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 9.9999e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        1.0000e+00, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 9.9920e-01,\n",
            "        1.6663e-01, 1.7538e-01])\n",
            "Molecule 167: tensor([5.0259e-02, 7.5925e-01, 6.8568e-01, 7.2319e-01, 7.3916e-01, 7.1779e-01,\n",
            "        7.0594e-01, 7.5470e-01, 6.9175e-01, 7.3979e-01, 5.6930e-01, 6.5326e-01,\n",
            "        5.7156e-01, 6.4516e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 2.0928e-01,\n",
            "        6.7554e-01, 7.6052e-01, 7.5054e-01, 6.6331e-01, 6.8501e-01, 9.2914e-01,\n",
            "        3.2997e-01, 6.9844e-01, 4.2306e-01, 5.7588e-01, 7.6167e-01, 3.6548e-01,\n",
            "        3.9245e-01, 7.0653e-01, 6.9156e-01, 1.0000e+00, 7.0158e-01, 7.8084e-01,\n",
            "        7.1045e-01, 7.2377e-01, 3.7192e-01, 5.8099e-01, 3.7192e-01, 6.2867e-01,\n",
            "        7.4806e-01, 6.1228e-01, 6.4167e-01, 4.0852e-01, 7.6487e-01, 7.9155e-01,\n",
            "        7.0060e-01, 7.0728e-01, 5.0000e-01, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        6.3529e-01, 9.2731e-01, 9.1765e-01, 6.7960e-01, 7.3166e-01, 4.9077e-01,\n",
            "        5.6952e-08, 8.3334e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 7.2563e-01,\n",
            "        7.7478e-01, 7.1075e-01, 3.6088e-15, 8.4332e-01, 9.7548e-01, 1.1809e-10,\n",
            "        3.1226e-01, 9.0550e-08, 9.9361e-01, 1.5707e-01, 7.1132e-01, 5.4315e-01,\n",
            "        7.3053e-01, 4.8420e-01, 6.1441e-01, 1.7656e-01, 7.2643e-01, 1.6710e-01,\n",
            "        5.9045e-01, 8.7862e-24, 3.8692e-01, 8.1876e-01, 9.1812e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.4380e-01, 9.8495e-01, 0.0000e+00, 9.8575e-01, 5.9597e-01,\n",
            "        7.5249e-01, 2.8631e-09, 4.3232e-01, 8.6833e-01, 2.9949e-06, 9.8554e-01,\n",
            "        5.3014e-05, 5.1404e-01, 5.3014e-05, 9.5433e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 7.0398e-01, 2.4397e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.0122e-01,\n",
            "        9.9999e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 8.3841e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 9.9999e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        1.0000e+00, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 9.9920e-01,\n",
            "        1.6663e-01, 1.7538e-01])\n",
            "Molecule 168: tensor([7.5688e-01, 6.8093e-01, 6.6320e-01, 5.2052e-01, 4.6802e-01, 5.9279e-01,\n",
            "        5.0061e-01, 4.1874e-01, 5.9913e-01, 4.9064e-01, 7.0705e-01, 6.0097e-01,\n",
            "        7.5566e-01, 6.5370e-01, 9.6167e-01, 9.6930e-01, 6.8936e-07, 8.7796e-01,\n",
            "        1.9674e-02, 2.5099e-11, 9.0116e-01, 5.8561e-17, 1.0887e-06, 2.3915e-11,\n",
            "        5.9031e-01, 5.8978e-01, 5.8032e-01, 4.4008e-01, 3.7931e-01, 3.7498e-01,\n",
            "        3.0554e-01, 6.2199e-01, 6.1040e-01, 1.0000e+00, 5.7306e-01, 2.7752e-01,\n",
            "        3.2560e-01, 5.5474e-01, 6.7479e-01, 9.5124e-01, 6.7479e-01, 1.8242e-01,\n",
            "        2.6798e-01, 1.6707e-01, 7.5839e-02, 2.5265e-02, 4.0182e-02, 4.1489e-01,\n",
            "        5.8894e-01, 9.4482e-01, 8.7595e-01, 1.0000e+00, 1.4249e-01, 9.3704e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 9.5692e-01, 9.5102e-01, 7.2707e-01,\n",
            "        5.6952e-08, 1.1745e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 6.2991e-01,\n",
            "        9.3835e-01, 9.6679e-01, 9.9566e-01, 8.3941e-01, 1.7356e-22, 1.1809e-10,\n",
            "        8.1960e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 2.5786e-01, 4.0442e-02,\n",
            "        7.0731e-01, 9.0174e-01, 6.1441e-01, 9.4548e-01, 3.9139e-01, 1.6710e-01,\n",
            "        7.5581e-02, 8.7862e-24, 5.0484e-01, 4.6750e-01, 4.3246e-01, 5.3014e-05,\n",
            "        7.4942e-01, 2.7603e-01, 6.9527e-13, 8.0466e-01, 9.7969e-13, 8.2736e-01,\n",
            "        5.2704e-01, 2.8631e-09, 8.7164e-01, 1.1842e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 9.5191e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 2.4524e-01, 2.1516e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.0000e+00, 1.6650e-01, 1.6649e-01, 8.9595e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.9786e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 9.8029e-01,\n",
            "        9.8041e-01, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 2.0417e-01])\n",
            "Molecule 169: tensor([1.1260e-01, 1.5528e-01, 2.3415e-01, 3.0222e-01, 2.5143e-01, 2.5823e-01,\n",
            "        4.6436e-01, 3.8299e-01, 6.9226e-01, 5.9498e-01, 7.8148e-01, 6.9217e-01,\n",
            "        9.0863e-01, 8.6343e-01, 4.0749e-10, 7.1388e-01, 6.8936e-07, 7.6123e-01,\n",
            "        3.5990e-01, 8.4600e-01, 9.0128e-01, 5.4715e-01, 1.0887e-06, 1.6919e-01,\n",
            "        7.5225e-13, 2.1813e-01, 3.8207e-01, 2.2892e-01, 1.6944e-01, 8.8940e-01,\n",
            "        8.4226e-01, 2.6018e-01, 1.9518e-01, 1.0000e+00, 2.0218e-01, 1.2695e-01,\n",
            "        3.4986e-01, 2.5562e-01, 5.2528e-01, 9.3647e-01, 5.2528e-01, 2.6844e-01,\n",
            "        4.8514e-01, 2.5680e-01, 6.9213e-01, 4.1179e-02, 3.8873e-01, 2.4162e-01,\n",
            "        2.1326e-01, 8.4234e-01, 1.9367e-01, 1.0000e+00, 1.4249e-01, 9.7600e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 1.6844e-01, 8.5589e-01, 9.8237e-02,\n",
            "        5.6952e-08, 2.1430e-01, 9.5844e-01, 1.1424e-21, 9.7743e-01, 2.8653e-01,\n",
            "        6.2843e-01, 5.7614e-21, 9.9561e-01, 8.4236e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1226e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 1.3924e-01, 9.7717e-01,\n",
            "        2.5779e-01, 2.7501e-02, 8.8518e-01, 6.0215e-01, 1.3514e-01, 1.6710e-01,\n",
            "        2.0507e-01, 9.9905e-01, 7.7546e-01, 2.2721e-01, 1.0923e-01, 5.3014e-05,\n",
            "        7.3205e-01, 3.1443e-01, 6.9527e-13, 7.7327e-01, 9.7969e-13, 2.4163e-01,\n",
            "        5.2704e-01, 9.8447e-01, 7.7591e-01, 1.1842e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 4.5061e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 5.2834e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.0000e+00, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 9.8029e-01,\n",
            "        9.8041e-01, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.5619e-01])\n",
            "Molecule 170: tensor([8.6288e-01, 1.5077e-01, 9.1969e-02, 8.1573e-02, 5.9004e-02, 1.1406e-01,\n",
            "        1.0317e-01, 6.9111e-02, 1.1021e-01, 6.6466e-02, 1.7339e-01, 1.0953e-01,\n",
            "        2.3559e-01, 1.5424e-01, 7.7404e-01, 5.1130e-01, 6.8936e-07, 2.1859e-01,\n",
            "        1.9674e-02, 2.9050e-01, 9.2584e-11, 5.8561e-17, 7.5433e-01, 3.3818e-01,\n",
            "        7.5225e-13, 6.8379e-02, 3.6935e-02, 2.5613e-02, 1.5244e-02, 8.6141e-02,\n",
            "        5.5454e-01, 1.0630e-01, 7.3581e-02, 1.0000e+00, 5.3945e-02, 4.1306e-02,\n",
            "        2.2003e-01, 8.7643e-02, 3.1282e-01, 1.2460e-01, 3.1282e-01, 8.2118e-01,\n",
            "        9.0121e-01, 8.0386e-01, 1.7120e-01, 8.7355e-01, 1.5887e-01, 8.6707e-02,\n",
            "        6.6436e-02, 7.0728e-01, 1.9367e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 8.4739e-02, 7.3166e-01, 9.8237e-02,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 9.8000e-01, 8.8066e-01, 1.0933e-01,\n",
            "        1.3928e-01, 5.7614e-21, 9.8389e-01, 1.4598e-01, 9.7781e-01, 8.9961e-01,\n",
            "        6.4590e-01, 6.3417e-01, 4.6098e-10, 1.5707e-01, 8.7077e-01, 6.2642e-02,\n",
            "        8.0760e-02, 2.7501e-02, 3.9661e-01, 3.1354e-01, 2.4327e-01, 1.6710e-01,\n",
            "        4.4803e-01, 8.7862e-24, 9.6566e-02, 3.0449e-02, 7.3058e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.3223e-01, 9.7891e-01, 0.0000e+00, 9.7969e-13, 5.8453e-02,\n",
            "        4.9293e-01, 2.8631e-09, 1.7808e-01, 7.6165e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 2.8591e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 3.9982e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 8.3841e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 9.5520e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.0000e+00, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.0000e+00, 8.4342e-01])\n",
            "Molecule 171: tensor([7.9097e-01, 3.4214e-01, 3.8409e-01, 2.5768e-01, 2.8308e-01, 3.4168e-01,\n",
            "        2.4142e-01, 3.8238e-01, 2.4546e-01, 3.5759e-01, 2.9303e-01, 2.8748e-01,\n",
            "        3.3932e-01, 3.0356e-01, 9.1527e-01, 6.8753e-01, 6.8936e-07, 1.0022e-01,\n",
            "        4.5506e-01, 2.5099e-11, 9.2584e-11, 9.7925e-01, 1.0887e-06, 3.1389e-01,\n",
            "        5.8820e-01, 3.9064e-01, 2.2565e-01, 7.9666e-02, 4.5807e-02, 1.4670e-01,\n",
            "        5.9749e-01, 3.6230e-01, 4.1393e-01, 1.0000e+00, 3.7518e-01, 2.4764e-01,\n",
            "        4.1444e-01, 3.1054e-01, 6.3889e-01, 6.3836e-01, 6.3889e-01, 9.8188e-01,\n",
            "        9.6178e-01, 8.0298e-01, 3.1344e-02, 8.7381e-01, 1.3215e-01, 2.4099e-01,\n",
            "        3.8588e-01, 8.4234e-01, 8.0633e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 3.0707e-01, 8.5589e-01, 7.2707e-01,\n",
            "        5.6952e-08, 3.3567e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 3.4336e-01,\n",
            "        6.0975e-01, 5.1734e-01, 9.8389e-01, 1.4598e-01, 9.7781e-01, 9.6889e-01,\n",
            "        6.0298e-01, 8.8113e-01, 4.6098e-10, 1.5707e-01, 8.7077e-01, 6.2642e-02,\n",
            "        8.0760e-02, 2.7501e-02, 3.9661e-01, 8.9102e-01, 4.6923e-01, 1.6710e-01,\n",
            "        4.2847e-01, 8.7862e-24, 9.6566e-02, 2.3382e-01, 7.3058e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.1443e-01, 9.7891e-01, 0.0000e+00, 9.7596e-01, 4.5841e-01,\n",
            "        7.6804e-01, 2.8631e-09, 1.7808e-01, 7.6165e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.5235e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 2.6228e-01, 1.6489e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 9.5520e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.0000e+00, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 1.0000e+00, 1.0000e+00, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.0000e+00, 4.2708e-01])\n",
            "Molecule 172: tensor([8.6288e-01, 1.5077e-01, 9.1969e-02, 8.1573e-02, 5.9004e-02, 1.1406e-01,\n",
            "        1.0317e-01, 6.9111e-02, 1.1021e-01, 6.6466e-02, 1.7339e-01, 1.0953e-01,\n",
            "        2.3559e-01, 1.5424e-01, 7.7404e-01, 5.1130e-01, 6.8936e-07, 2.1859e-01,\n",
            "        1.9674e-02, 2.9050e-01, 9.2584e-11, 5.8561e-17, 7.5433e-01, 3.3818e-01,\n",
            "        7.5225e-13, 6.8379e-02, 3.6935e-02, 2.5613e-02, 1.5244e-02, 8.6141e-02,\n",
            "        5.5454e-01, 1.0630e-01, 7.3581e-02, 1.0000e+00, 5.3945e-02, 4.1306e-02,\n",
            "        2.2003e-01, 8.7643e-02, 3.1282e-01, 1.2460e-01, 3.1282e-01, 8.2118e-01,\n",
            "        9.0121e-01, 8.0386e-01, 1.7120e-01, 8.7355e-01, 1.5887e-01, 8.6707e-02,\n",
            "        6.6436e-02, 7.0728e-01, 1.9367e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 8.4739e-02, 7.3166e-01, 9.8237e-02,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 9.8000e-01, 8.8066e-01, 1.0933e-01,\n",
            "        1.3928e-01, 5.7614e-21, 9.8389e-01, 1.4598e-01, 9.7781e-01, 8.9961e-01,\n",
            "        6.4590e-01, 6.3417e-01, 4.6098e-10, 1.5707e-01, 8.7077e-01, 6.2642e-02,\n",
            "        8.0760e-02, 2.7501e-02, 3.9661e-01, 3.1354e-01, 2.4327e-01, 1.6710e-01,\n",
            "        4.4803e-01, 8.7862e-24, 9.6566e-02, 3.0449e-02, 7.3058e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.3223e-01, 9.7891e-01, 0.0000e+00, 9.7969e-13, 5.8453e-02,\n",
            "        4.9293e-01, 2.8631e-09, 1.7808e-01, 7.6165e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 2.8591e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 3.9982e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 8.3841e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 9.5520e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.0000e+00, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.0000e+00, 8.4342e-01])\n",
            "Molecule 173: tensor([3.4539e-01, 9.9816e-01, 9.9872e-01, 9.9863e-01, 9.9870e-01, 9.9846e-01,\n",
            "        9.9854e-01, 9.9869e-01, 9.9826e-01, 9.9765e-01, 9.9655e-01, 9.9516e-01,\n",
            "        9.9496e-01, 9.9319e-01, 9.7922e-01, 9.9351e-01, 6.8936e-07, 9.9999e-01,\n",
            "        8.6684e-01, 2.5099e-11, 7.3273e-01, 9.9478e-01, 6.9044e-01, 8.8556e-01,\n",
            "        6.4639e-01, 9.9849e-01, 2.6104e-03, 3.0216e-03, 2.6885e-03, 8.9094e-01,\n",
            "        1.2373e-03, 9.9851e-01, 9.9834e-01, 1.0000e+00, 9.9869e-01, 9.9857e-01,\n",
            "        9.9982e-01, 9.9860e-01, 9.2331e-01, 1.4904e-01, 9.2331e-01, 3.7343e-01,\n",
            "        1.8773e-01, 3.6618e-01, 1.5761e-01, 8.4073e-01, 1.0063e-01, 9.9859e-01,\n",
            "        9.9876e-01, 9.9503e-01, 9.9955e-01, 9.9386e-22, 9.7155e-01, 9.6456e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 9.9572e-01, 9.9375e-01, 9.9837e-01,\n",
            "        5.6952e-08, 9.6780e-01, 0.0000e+00, 9.9907e-01, 9.6593e-01, 9.9854e-01,\n",
            "        9.9598e-01, 9.9952e-01, 3.6088e-15, 9.8249e-01, 1.7356e-22, 1.1809e-10,\n",
            "        9.9959e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 9.9831e-01, 9.9872e-01,\n",
            "        6.0844e-01, 2.7501e-02, 8.8518e-01, 9.5056e-01, 9.8955e-01, 1.6710e-01,\n",
            "        9.9981e-01, 9.9958e-01, 9.9762e-01, 7.4540e-01, 7.3058e-01, 5.3014e-05,\n",
            "        1.4266e-16, 9.9832e-01, 6.9527e-13, 0.0000e+00, 9.7969e-13, 9.9543e-01,\n",
            "        9.9661e-01, 9.8485e-01, 9.9749e-01, 7.6165e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 9.9718e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.6915e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 9.9730e-01, 9.9823e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 9.9932e-01, 1.0000e+00,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 9.9975e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.8691e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 2.0535e-02])\n",
            "Molecule 174: tensor([4.5755e-01, 2.1835e-01, 2.3706e-01, 3.4717e-01, 2.9419e-01, 2.8572e-01,\n",
            "        4.2415e-01, 3.4419e-01, 4.2473e-01, 3.1676e-01, 5.6667e-01, 4.4647e-01,\n",
            "        6.0842e-01, 4.8317e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.4158e-01, 7.8075e-01, 9.2637e-01, 4.1465e-01, 5.8646e-01, 8.2233e-01,\n",
            "        3.4911e-01, 2.0230e-01, 9.3480e-01, 9.8370e-01, 9.9451e-01, 6.5621e-01,\n",
            "        8.0520e-01, 2.6018e-01, 1.7652e-01, 1.0000e+00, 2.7850e-01, 4.2749e-01,\n",
            "        4.7723e-01, 2.7120e-01, 1.6070e-02, 8.7982e-01, 1.6070e-02, 5.0583e-02,\n",
            "        9.7651e-01, 3.8416e-02, 8.7223e-01, 1.0444e-01, 6.4657e-01, 3.5752e-01,\n",
            "        1.9762e-01, 4.3608e-01, 1.2405e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 1.6844e-01, 4.7447e-01, 3.3458e-02,\n",
            "        5.6952e-08, 4.6631e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 2.6921e-01,\n",
            "        3.5789e-01, 4.6640e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.2497e-01, 9.0550e-08, 4.6098e-10, 9.9995e-01, 1.3944e-01, 9.5954e-01,\n",
            "        4.2405e-01, 4.9728e-01, 3.9661e-01, 1.8189e-01, 2.2068e-01, 1.6710e-01,\n",
            "        4.3250e-01, 9.9654e-01, 5.2567e-01, 6.3461e-01, 3.8549e-01, 5.3014e-05,\n",
            "        6.9955e-01, 6.0336e-01, 6.9527e-13, 7.0981e-01, 9.7969e-13, 2.9348e-01,\n",
            "        3.2335e-01, 9.6808e-01, 4.7768e-01, 4.7729e-01, 2.9949e-06, 9.8573e-01,\n",
            "        5.3014e-05, 6.0835e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 9.2328e-01, 2.1905e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 9.9998e-01, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.7412e-01])\n",
            "Molecule 175: tensor([4.5755e-01, 2.1835e-01, 2.3706e-01, 3.4717e-01, 2.9419e-01, 2.8572e-01,\n",
            "        4.2415e-01, 3.4419e-01, 4.2473e-01, 3.1676e-01, 5.6667e-01, 4.4647e-01,\n",
            "        6.0842e-01, 4.8317e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.4158e-01, 7.8075e-01, 9.2637e-01, 4.1465e-01, 5.8646e-01, 8.2233e-01,\n",
            "        3.4911e-01, 2.0230e-01, 9.3480e-01, 9.8370e-01, 9.9451e-01, 6.5621e-01,\n",
            "        8.0520e-01, 2.6018e-01, 1.7652e-01, 1.0000e+00, 2.7850e-01, 4.2749e-01,\n",
            "        4.7723e-01, 2.7120e-01, 1.6070e-02, 8.7982e-01, 1.6070e-02, 5.0583e-02,\n",
            "        9.7651e-01, 3.8416e-02, 8.7223e-01, 1.0444e-01, 6.4657e-01, 3.5752e-01,\n",
            "        1.9762e-01, 4.3608e-01, 1.2405e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 1.6844e-01, 4.7447e-01, 3.3458e-02,\n",
            "        5.6952e-08, 4.6631e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 2.6921e-01,\n",
            "        3.5789e-01, 4.6640e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.2497e-01, 9.0550e-08, 4.6098e-10, 9.9995e-01, 1.3944e-01, 9.5954e-01,\n",
            "        4.2405e-01, 4.9728e-01, 3.9661e-01, 1.8189e-01, 2.2068e-01, 1.6710e-01,\n",
            "        4.3250e-01, 9.9654e-01, 5.2567e-01, 6.3461e-01, 3.8549e-01, 5.3014e-05,\n",
            "        6.9955e-01, 6.0336e-01, 6.9527e-13, 7.0981e-01, 9.7969e-13, 2.9348e-01,\n",
            "        3.2335e-01, 9.6808e-01, 4.7768e-01, 4.7729e-01, 2.9949e-06, 9.8573e-01,\n",
            "        5.3014e-05, 6.0835e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 9.2328e-01, 2.1905e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 9.9998e-01, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.7412e-01])\n",
            "Molecule 176: tensor([7.2683e-02, 4.7872e-01, 4.4435e-01, 4.3413e-01, 4.5652e-01, 4.7763e-01,\n",
            "        4.8601e-01, 6.0497e-01, 4.6378e-01, 6.5521e-01, 5.4762e-01, 7.7046e-01,\n",
            "        5.7058e-01, 8.0495e-01, 8.3260e-01, 6.5613e-01, 6.8936e-07, 5.5802e-01,\n",
            "        1.5575e-01, 8.4981e-01, 6.4405e-01, 8.8322e-01, 1.0887e-06, 5.8000e-01,\n",
            "        7.5225e-13, 4.8947e-01, 1.7621e-01, 2.0535e-01, 2.6416e-01, 5.5308e-01,\n",
            "        5.9364e-01, 4.7032e-01, 4.9373e-01, 1.0000e+00, 4.1718e-01, 3.7121e-01,\n",
            "        4.3794e-01, 4.5173e-01, 4.0556e-01, 1.4338e-01, 4.0556e-01, 5.6596e-01,\n",
            "        5.6892e-01, 5.4544e-01, 4.1962e-02, 8.4662e-01, 7.1732e-02, 4.1507e-01,\n",
            "        4.8668e-01, 6.1316e-02, 8.0633e-01, 9.9386e-22, 9.5785e-01, 9.3704e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 8.2272e-01, 5.5287e-02, 7.2707e-01,\n",
            "        5.6952e-08, 3.3567e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 4.7370e-01,\n",
            "        1.2390e-01, 4.1842e-01, 3.6088e-15, 8.4332e-01, 9.9692e-01, 1.1809e-10,\n",
            "        6.2375e-01, 9.5085e-01, 4.6098e-10, 1.5707e-01, 2.5786e-01, 1.9085e-01,\n",
            "        9.6753e-01, 1.9837e-01, 6.1441e-01, 5.0078e-01, 5.2907e-01, 1.6710e-01,\n",
            "        7.8733e-01, 8.7862e-24, 2.1909e-01, 9.1639e-01, 3.7923e-01, 5.3014e-05,\n",
            "        1.4266e-16, 2.8678e-01, 9.8495e-01, 0.0000e+00, 9.7969e-13, 8.8884e-01,\n",
            "        4.8055e-01, 2.8631e-09, 3.0298e-01, 5.3877e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 6.5976e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.5728e-01, 5.3014e-05, 9.9865e-01, 8.8833e-01, 1.7286e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.0122e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 9.2413e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 9.9996e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.6109e-01])\n",
            "Molecule 177: tensor([8.5658e-01, 1.8506e-01, 1.6422e-01, 2.7512e-01, 2.2614e-01, 1.7941e-01,\n",
            "        2.9694e-01, 2.2733e-01, 3.9290e-01, 2.8786e-01, 4.4666e-01, 3.3014e-01,\n",
            "        5.3603e-01, 4.0908e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 2.0552e-01,\n",
            "        1.9674e-02, 3.3577e-01, 9.1507e-01, 5.8561e-17, 4.7966e-01, 9.8283e-01,\n",
            "        7.5225e-13, 1.1452e-01, 1.4997e-01, 7.5211e-02, 6.0380e-02, 3.9900e-01,\n",
            "        8.0770e-01, 1.7312e-01, 9.9860e-02, 1.0000e+00, 1.5810e-01, 1.3367e-01,\n",
            "        3.0308e-01, 1.8504e-01, 1.1553e-02, 1.2145e-01, 1.1553e-02, 1.0467e-02,\n",
            "        3.7068e-01, 6.1001e-03, 7.6141e-01, 8.6951e-01, 7.3526e-01, 2.8621e-01,\n",
            "        1.1141e-01, 4.3608e-01, 5.1530e-02, 9.9995e-01, 1.4249e-01, 5.0000e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 4.0600e-02, 4.7447e-01, 8.8540e-04,\n",
            "        5.6952e-08, 1.1745e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.7147e-01,\n",
            "        1.3928e-01, 5.7614e-21, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 9.0550e-08, 4.6098e-10, 1.5707e-01, 9.1481e-01, 6.6761e-01,\n",
            "        1.3907e-01, 2.7501e-02, 3.9661e-01, 1.2446e-01, 1.3065e-01, 1.6710e-01,\n",
            "        2.0507e-01, 8.7862e-24, 5.2567e-01, 4.6377e-01, 7.9096e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.1443e-01, 6.9527e-13, 0.0000e+00, 9.7969e-13, 7.9787e-02,\n",
            "        2.7552e-01, 2.8631e-09, 7.5866e-01, 6.6533e-01, 2.9949e-06, 9.7067e-01,\n",
            "        5.3014e-05, 1.3019e-02, 5.3014e-05, 5.0000e-01, 3.8471e-01, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1538e-01, 2.2198e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.8691e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 9.6071e-01,\n",
            "        1.6663e-01, 8.7723e-01])\n",
            "Molecule 178: tensor([8.3462e-01, 2.0806e-01, 2.1569e-01, 3.5942e-01, 3.0603e-01, 2.0946e-01,\n",
            "        3.4872e-01, 2.7380e-01, 5.2079e-01, 4.0920e-01, 4.9006e-01, 3.7067e-01,\n",
            "        5.6688e-01, 4.3994e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 2.0552e-01,\n",
            "        1.9674e-02, 3.3577e-01, 9.1507e-01, 5.8561e-17, 1.0887e-06, 9.9258e-01,\n",
            "        7.5225e-13, 1.4799e-01, 1.0814e-01, 5.4309e-02, 4.3059e-02, 4.5627e-01,\n",
            "        8.0770e-01, 2.1432e-01, 1.2711e-01, 1.0000e+00, 2.1445e-01, 1.5967e-01,\n",
            "        3.2683e-01, 2.3434e-01, 1.0376e-02, 1.1124e-01, 1.0376e-02, 1.0467e-02,\n",
            "        3.6413e-01, 6.1001e-03, 7.6092e-01, 8.8023e-01, 8.0069e-01, 3.4868e-01,\n",
            "        1.4418e-01, 6.1316e-02, 5.1530e-02, 9.9995e-01, 1.4249e-01, 5.0000e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 4.0600e-02, 5.5287e-02, 8.8540e-04,\n",
            "        5.6952e-08, 1.1745e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 2.0843e-01,\n",
            "        1.2390e-01, 5.7614e-21, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 9.0550e-08, 4.6098e-10, 1.5707e-01, 9.1481e-01, 6.7889e-01,\n",
            "        2.5779e-01, 2.7501e-02, 3.9661e-01, 1.2446e-01, 1.3065e-01, 1.6710e-01,\n",
            "        1.9057e-01, 8.7862e-24, 5.2567e-01, 6.4409e-01, 7.9096e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 3.0087e-01,\n",
            "        2.7552e-01, 2.8631e-09, 7.5866e-01, 6.6533e-01, 2.9949e-06, 9.7067e-01,\n",
            "        5.3014e-05, 7.4930e-03, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 9.1663e-01, 2.4638e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.8691e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.2904e-01])\n",
            "Molecule 179: tensor([2.7257e-02, 5.0800e-01, 6.3008e-01, 6.5670e-01, 6.1325e-01, 6.7482e-01,\n",
            "        6.8880e-01, 6.1670e-01, 7.1620e-01, 6.2317e-01, 7.8839e-01, 7.0099e-01,\n",
            "        7.8253e-01, 6.8804e-01, 5.8402e-01, 5.2530e-01, 6.8936e-07, 6.3176e-01,\n",
            "        8.7305e-01, 6.8625e-01, 9.2584e-11, 5.4433e-01, 6.9981e-01, 1.5559e-01,\n",
            "        8.2051e-01, 6.3096e-01, 4.9917e-01, 5.0906e-01, 5.9888e-01, 6.3120e-01,\n",
            "        4.1556e-01, 6.6622e-01, 6.2489e-01, 1.0000e+00, 5.6905e-01, 4.7936e-01,\n",
            "        4.9530e-01, 6.4583e-01, 3.2753e-01, 8.8002e-01, 3.2753e-01, 9.5704e-01,\n",
            "        7.5504e-01, 9.6615e-01, 2.3400e-01, 1.0422e-01, 3.3185e-01, 5.9119e-01,\n",
            "        6.3118e-01, 4.3608e-01, 8.0633e-01, 9.9386e-22, 9.7155e-01, 9.6456e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 8.2272e-01, 4.7447e-01, 6.2081e-01,\n",
            "        5.6952e-08, 3.3567e-01, 0.0000e+00, 9.9653e-01, 9.4279e-01, 7.0806e-01,\n",
            "        8.7131e-01, 7.2123e-01, 9.9561e-01, 8.6070e-01, 1.7356e-22, 9.0093e-01,\n",
            "        6.2944e-01, 6.3417e-01, 4.6098e-10, 1.5707e-01, 1.3924e-01, 8.0094e-01,\n",
            "        5.9075e-01, 7.1659e-01, 8.8518e-01, 8.9349e-01, 2.3971e-01, 1.6710e-01,\n",
            "        1.9057e-01, 8.7862e-24, 5.0484e-01, 9.2052e-01, 3.7508e-01, 5.3014e-05,\n",
            "        7.4942e-01, 8.8651e-01, 9.9409e-01, 8.0466e-01, 9.7969e-13, 8.2797e-01,\n",
            "        4.9310e-01, 2.8631e-09, 3.3949e-01, 4.6659e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 5.9544e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 8.2801e-01, 2.1806e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 9.0665e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        1.0000e+00, 9.9922e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 9.9998e-01, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.2252e-01])\n",
            "Molecule 180: tensor([1.9608e-05, 1.3661e-01, 3.2604e-01, 4.8401e-01, 5.7444e-01, 3.0113e-01,\n",
            "        5.1633e-01, 4.3446e-01, 6.7195e-01, 5.7151e-01, 8.1523e-01, 7.3584e-01,\n",
            "        8.3465e-01, 7.5768e-01, 6.0080e-01, 5.2530e-01, 6.8936e-07, 9.5852e-01,\n",
            "        5.1646e-01, 5.5649e-01, 7.8353e-01, 5.8561e-17, 6.5200e-01, 6.0449e-01,\n",
            "        3.4911e-01, 5.7931e-01, 7.1569e-01, 3.7365e-01, 1.8498e-01, 9.0488e-01,\n",
            "        9.5051e-01, 3.6230e-01, 5.5727e-01, 1.0000e+00, 5.9826e-01, 5.1689e-01,\n",
            "        4.8388e-01, 4.8013e-01, 4.2193e-01, 1.0000e+00, 4.2193e-01, 8.0065e-01,\n",
            "        3.2429e-10, 8.0341e-01, 3.8453e-01, 6.6624e-12, 3.1380e-02, 3.2461e-01,\n",
            "        5.8171e-01, 4.3608e-01, 1.9367e-01, 9.9386e-22, 9.5785e-01, 9.3704e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 1.6844e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 3.3567e-01, 0.0000e+00, 9.9653e-01, 9.4279e-01, 4.5099e-01,\n",
            "        9.4504e-01, 7.2640e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 8.9828e-01,\n",
            "        3.1226e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 5.5749e-01, 1.2562e-01,\n",
            "        6.0125e-01, 9.1927e-01, 3.9661e-01, 9.2576e-01, 1.3599e-01, 1.6710e-01,\n",
            "        7.5581e-02, 8.7862e-24, 9.1119e-01, 4.6564e-01, 2.1106e-01, 5.3014e-05,\n",
            "        1.4266e-16, 8.4681e-01, 6.9527e-13, 0.0000e+00, 9.7969e-13, 7.5191e-01,\n",
            "        4.6053e-01, 2.8631e-09, 8.3972e-01, 2.5614e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 1.4513e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.8988e-01, 2.2568e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.8691e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 9.9998e-01, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 1.0000e+00, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 4.1557e-01])\n",
            "Molecule 181: tensor([4.2533e-01, 1.0546e-01, 2.1569e-01, 2.5343e-01, 2.0619e-01, 2.0985e-01,\n",
            "        3.3250e-01, 2.5908e-01, 4.6570e-01, 3.5522e-01, 6.2286e-01, 5.0574e-01,\n",
            "        6.7021e-01, 5.5128e-01, 6.0080e-01, 7.1686e-01, 6.8936e-07, 9.5698e-01,\n",
            "        3.5595e-01, 4.6223e-01, 9.2584e-11, 4.1274e-01, 6.5200e-01, 2.3915e-11,\n",
            "        3.4911e-01, 1.8693e-01, 8.8039e-01, 6.3838e-01, 4.0784e-01, 8.4676e-01,\n",
            "        8.9313e-01, 2.1432e-01, 1.7040e-01, 1.0000e+00, 2.4139e-01, 1.9008e-01,\n",
            "        3.5958e-01, 2.0646e-01, 3.6331e-01, 9.9999e-01, 3.6331e-01, 8.0065e-01,\n",
            "        2.6998e-01, 8.0341e-01, 3.4129e-01, 6.8454e-10, 1.8313e-01, 1.8149e-01,\n",
            "        1.8238e-01, 4.3608e-01, 3.0517e-01, 9.9386e-22, 9.5785e-01, 9.3704e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 3.0707e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 2.1430e-01, 0.0000e+00, 9.9653e-01, 9.4279e-01, 2.5274e-01,\n",
            "        7.7702e-01, 7.2640e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 8.9828e-01,\n",
            "        3.1226e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 5.5749e-01, 3.8706e-02,\n",
            "        6.0125e-01, 8.4925e-01, 3.9661e-01, 7.6777e-01, 1.3599e-01, 1.6710e-01,\n",
            "        7.5581e-02, 8.7862e-24, 8.1371e-01, 4.6564e-01, 2.7367e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 6.8493e-01,\n",
            "        4.6053e-01, 9.3269e-01, 6.9077e-01, 2.5614e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 4.5104e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 3.4906e-01, 2.1930e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        1.0000e+00, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.8691e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 9.9998e-01, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 1.0000e+00, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 3.9082e-01])\n",
            "Molecule 182: tensor([1.8148e-01, 5.4328e-01, 5.9223e-01, 6.2134e-01, 6.4111e-01, 5.5722e-01,\n",
            "        5.6230e-01, 6.3478e-01, 6.2233e-01, 6.8220e-01, 3.9760e-01, 5.0500e-01,\n",
            "        3.1362e-01, 4.1668e-01, 5.8058e-01, 2.6487e-01, 6.8936e-07, 2.0928e-01,\n",
            "        6.7554e-01, 7.4895e-01, 9.2584e-11, 7.5757e-01, 7.0852e-01, 5.9103e-01,\n",
            "        6.0157e-01, 5.8658e-01, 7.2818e-01, 8.3360e-01, 7.6465e-01, 5.3930e-01,\n",
            "        5.7029e-01, 5.7417e-01, 5.7350e-01, 1.0000e+00, 6.4392e-01, 6.6092e-01,\n",
            "        7.2564e-01, 5.9540e-01, 3.0307e-01, 5.7651e-01, 3.0307e-01, 4.4206e-01,\n",
            "        6.2056e-01, 4.3450e-01, 4.5546e-01, 4.1292e-01, 4.4501e-01, 6.4593e-01,\n",
            "        5.8599e-01, 9.0949e-01, 6.9483e-01, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        3.4723e-02, 9.5258e-01, 6.1776e-01, 8.2272e-01, 8.5589e-01, 6.2081e-01,\n",
            "        5.6952e-08, 7.7335e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 6.0867e-01,\n",
            "        6.2574e-01, 7.1075e-01, 3.6088e-15, 8.4332e-01, 9.7548e-01, 1.1809e-10,\n",
            "        8.3066e-01, 6.4348e-01, 9.8858e-01, 1.5707e-01, 1.3924e-01, 5.8941e-01,\n",
            "        9.1442e-01, 4.4318e-01, 3.9661e-01, 1.7656e-01, 4.0287e-01, 1.6710e-01,\n",
            "        5.9465e-01, 9.8692e-01, 7.1122e-01, 5.7430e-01, 7.7423e-01, 5.3014e-05,\n",
            "        1.4266e-16, 8.3857e-01, 9.8495e-01, 0.0000e+00, 9.8575e-01, 3.3627e-01,\n",
            "        7.2873e-01, 9.4722e-01, 7.5485e-01, 5.1097e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.2432e-01, 5.3014e-05, 9.5294e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 9.2612e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.4231e-01,\n",
            "        9.9999e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 8.3841e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 9.9999e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        1.0000e+00, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 9.9920e-01,\n",
            "        1.6663e-01, 3.0607e-01])\n",
            "Molecule 183: tensor([8.6670e-01, 1.0100e-01, 3.8867e-02, 3.4023e-02, 2.3031e-02, 4.7363e-02,\n",
            "        3.4871e-02, 2.1823e-02, 2.7844e-02, 1.4769e-02, 2.8031e-02, 1.5409e-02,\n",
            "        2.7601e-02, 1.5866e-02, 4.0749e-10, 2.1752e-08, 6.8936e-07, 2.1617e-01,\n",
            "        3.1320e-01, 1.5101e-01, 9.2584e-11, 5.4715e-01, 6.5200e-01, 4.6883e-01,\n",
            "        6.4639e-01, 2.6275e-02, 1.1856e-01, 2.0078e-01, 2.4424e-01, 2.1555e-14,\n",
            "        6.2786e-01, 4.3509e-02, 2.8164e-02, 1.0000e+00, 2.6129e-02, 4.8762e-02,\n",
            "        3.0408e-01, 3.4286e-02, 1.6900e-02, 2.2257e-01, 1.6900e-02, 8.5550e-02,\n",
            "        8.4655e-01, 7.0499e-02, 8.1902e-01, 7.6504e-01, 3.1587e-01, 5.1722e-02,\n",
            "        2.5621e-02, 9.0949e-01, 3.0517e-01, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 4.9226e-01, 7.3166e-01, 2.0751e-01,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 7.1394e-02,\n",
            "        4.3134e-01, 7.1027e-01, 9.8518e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 6.4348e-01, 9.5824e-01, 9.9986e-01, 3.6664e-01, 1.8561e-01,\n",
            "        8.0760e-02, 2.0344e-01, 1.2027e-01, 1.2446e-01, 5.6564e-01, 1.6710e-01,\n",
            "        1.9343e-01, 9.9545e-01, 1.9854e-02, 3.9722e-01, 2.9207e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.7077e-01, 9.9851e-01, 0.0000e+00, 9.7969e-13, 7.2224e-03,\n",
            "        1.2049e-11, 2.8631e-09, 8.2539e-03, 6.3115e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 6.8757e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.9880e-01, 5.3014e-05, 9.9865e-01, 3.9982e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 1.0000e+00, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 7.1316e-01, 1.1816e-03, 1.0000e+00,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.2324e-01,\n",
            "        2.8681e-10, 3.7774e-01, 1.0000e+00, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.6126e-01])\n",
            "Molecule 184: tensor([1.0431e-01, 7.8305e-01, 7.1904e-01, 7.0517e-01, 6.6656e-01, 7.4917e-01,\n",
            "        7.6049e-01, 6.9828e-01, 7.6388e-01, 6.8107e-01, 8.0848e-01, 7.2699e-01,\n",
            "        8.3499e-01, 7.5815e-01, 6.1012e-01, 7.9781e-01, 6.8936e-07, 5.7419e-01,\n",
            "        3.5990e-01, 9.5305e-01, 9.2690e-01, 8.8130e-01, 1.0887e-06, 3.0230e-01,\n",
            "        7.5225e-13, 7.0406e-01, 9.5511e-02, 1.1634e-01, 1.8672e-01, 3.3167e-01,\n",
            "        3.6981e-01, 7.4282e-01, 7.0646e-01, 1.0000e+00, 6.7844e-01, 6.3243e-01,\n",
            "        5.5388e-01, 7.1508e-01, 8.7192e-01, 2.3405e-01, 8.7192e-01, 5.4078e-02,\n",
            "        8.4588e-01, 4.1510e-02, 3.5271e-01, 7.5334e-01, 9.3630e-01, 7.0670e-01,\n",
            "        7.0610e-01, 4.3608e-01, 1.2405e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        9.6401e-01, 8.6504e-01, 9.1765e-01, 1.6844e-01, 4.7447e-01, 3.4646e-01,\n",
            "        5.6952e-08, 4.6631e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 7.5824e-01,\n",
            "        3.3834e-01, 8.5333e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1932e-01, 8.6609e-01, 4.6098e-10, 1.5707e-01, 2.5786e-01, 9.8500e-01,\n",
            "        8.4298e-01, 4.5675e-01, 8.8518e-01, 7.3904e-01, 2.2068e-01, 1.6710e-01,\n",
            "        3.9129e-01, 8.7862e-24, 6.2680e-01, 4.4851e-01, 9.4678e-01, 5.3014e-05,\n",
            "        6.9901e-01, 3.7316e-02, 9.9601e-01, 0.0000e+00, 9.7969e-13, 3.4480e-01,\n",
            "        5.8995e-01, 9.7868e-01, 6.7065e-01, 8.3655e-01, 2.9949e-06, 9.9098e-01,\n",
            "        5.3014e-05, 4.0145e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 7.9415e-01, 2.0287e-02,\n",
            "        5.7087e-19, 9.9925e-01, 9.9786e-01, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 9.6402e-01, 1.6148e-09,\n",
            "        9.9786e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.8713e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 2.2527e-01])\n",
            "Molecule 185: tensor([7.9005e-01, 1.6420e-01, 9.0039e-02, 1.4701e-01, 1.1247e-01, 1.1539e-01,\n",
            "        1.6642e-01, 1.1760e-01, 1.8932e-01, 1.2207e-01, 2.8749e-01, 1.9479e-01,\n",
            "        3.0077e-01, 2.0341e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.4503e-01, 4.5199e-01, 7.5664e-01, 5.8561e-17, 1.0887e-06, 9.8251e-01,\n",
            "        3.6402e-01, 6.5497e-02, 2.9491e-01, 2.6634e-01, 4.3470e-01, 2.9406e-01,\n",
            "        7.4404e-01, 1.0630e-01, 6.1166e-02, 1.0000e+00, 6.8230e-02, 7.9592e-02,\n",
            "        2.9535e-01, 1.0580e-01, 1.4470e-02, 1.6899e-01, 1.4470e-02, 3.8844e-02,\n",
            "        9.0304e-01, 2.8269e-02, 8.3419e-01, 8.2006e-01, 6.4361e-01, 1.6262e-01,\n",
            "        6.3662e-02, 6.1316e-02, 7.9832e-02, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 8.4739e-02, 5.5287e-02, 7.2855e-03,\n",
            "        5.6952e-08, 1.6146e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.1646e-01,\n",
            "        1.2390e-01, 4.7105e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 6.4388e-01, 4.6098e-10, 1.5707e-01, 7.7384e-01, 2.9763e-01,\n",
            "        1.6303e-01, 4.6120e-01, 3.9661e-01, 1.2446e-01, 2.3399e-01, 1.6710e-01,\n",
            "        1.9057e-01, 9.8334e-01, 4.0131e-01, 2.4508e-01, 6.4350e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.8384e-01, 0.0000e+00, 9.7969e-13, 1.4712e-01,\n",
            "        3.2335e-01, 2.8631e-09, 4.6263e-01, 7.4610e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 1.6474e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.9999e-01, 5.3014e-05, 9.9865e-01, 7.7115e-01, 2.2323e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.0000e+00, 5.2233e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 1.0000e+00, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 9.9991e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.5500e-01])\n",
            "Molecule 186: tensor([8.0239e-01, 2.4606e-01, 2.1237e-01, 2.7219e-01, 2.2343e-01, 2.1483e-01,\n",
            "        2.5104e-01, 1.8746e-01, 3.0972e-01, 2.1618e-01, 3.3560e-01, 2.3360e-01,\n",
            "        2.5735e-01, 1.7032e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 4.2420e-01,\n",
            "        5.1079e-01, 2.9666e-01, 9.2584e-11, 5.5013e-01, 7.2221e-01, 6.2984e-01,\n",
            "        7.5225e-13, 1.6121e-01, 7.6306e-01, 7.8800e-01, 8.6406e-01, 3.8906e-01,\n",
            "        6.3900e-01, 2.1432e-01, 1.5323e-01, 1.0000e+00, 1.8286e-01, 1.6371e-01,\n",
            "        3.3298e-01, 2.0573e-01, 6.0550e-01, 1.4286e-01, 6.0550e-01, 5.0359e-01,\n",
            "        1.3397e-01, 4.8676e-01, 7.3082e-01, 8.4715e-01, 3.3248e-01, 2.6256e-01,\n",
            "        1.5707e-01, 4.3608e-01, 3.0517e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 3.0707e-01, 4.7447e-01, 2.0751e-01,\n",
            "        5.6952e-08, 1.1745e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 2.0843e-01,\n",
            "        6.1032e-01, 4.7009e-01, 3.6088e-15, 1.4598e-01, 9.7781e-01, 1.1809e-10,\n",
            "        3.1226e-01, 6.4348e-01, 4.6098e-10, 1.5707e-01, 2.5786e-01, 6.0753e-01,\n",
            "        4.4266e-01, 6.5006e-01, 3.9661e-01, 1.8288e-01, 5.6855e-01, 1.6710e-01,\n",
            "        4.1217e-01, 8.7862e-24, 2.5700e-01, 8.0896e-01, 3.7716e-01, 5.3014e-05,\n",
            "        1.4266e-16, 6.1165e-01, 9.9749e-01, 0.0000e+00, 9.7969e-13, 6.1453e-01,\n",
            "        1.2049e-11, 2.8631e-09, 3.1429e-01, 4.6878e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 1.6457e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.9777e-01, 5.3014e-05, 9.9865e-01, 8.2241e-01, 2.4387e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 7.1316e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.5332e-01, 2.6412e-12, 9.4279e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.8691e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 9.9998e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 9.9902e-01])\n",
            "Molecule 187: tensor([6.9572e-01, 3.7561e-02, 5.9089e-02, 1.4885e-01, 1.1403e-01, 9.6189e-02,\n",
            "        2.9958e-01, 2.2967e-01, 3.5230e-01, 2.5218e-01, 5.4725e-01, 4.2673e-01,\n",
            "        6.9271e-01, 5.7729e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.3118e-01, 2.5099e-11, 9.9063e-01, 3.6413e-01, 1.0887e-06, 8.2381e-01,\n",
            "        7.5225e-13, 5.5937e-02, 3.2550e-02, 4.6705e-02, 7.2556e-02, 9.0251e-01,\n",
            "        9.5686e-01, 8.0716e-02, 4.3302e-02, 1.0000e+00, 7.6487e-02, 1.2798e-01,\n",
            "        2.8863e-01, 9.2857e-02, 1.0926e-02, 9.7960e-02, 1.0926e-02, 1.6555e-02,\n",
            "        9.1338e-01, 1.0444e-02, 8.3768e-01, 8.9421e-01, 7.2782e-01, 1.3321e-01,\n",
            "        5.4391e-02, 6.1316e-02, 5.1530e-02, 9.9995e-01, 9.1873e-01, 9.3704e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 4.0600e-02, 5.5287e-02, 8.8540e-04,\n",
            "        5.6952e-08, 5.2057e-02, 8.9543e-01, 9.8000e-01, 9.4279e-01, 1.2411e-01,\n",
            "        8.7215e-03, 5.7614e-21, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1932e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 8.3792e-01, 5.8466e-01,\n",
            "        1.4077e-01, 2.7501e-02, 3.9661e-01, 1.2446e-01, 7.3182e-02, 1.6710e-01,\n",
            "        1.9057e-01, 8.7862e-24, 8.5784e-01, 4.4851e-01, 2.1106e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 1.5083e-01,\n",
            "        2.8149e-01, 2.8631e-09, 8.8054e-01, 2.5614e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 7.4930e-03, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.1561e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 9.9962e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 9.9998e-01, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.5399e-01])\n",
            "Molecule 188: tensor([1.9460e-01, 7.7502e-02, 1.5271e-01, 2.3017e-01, 1.8510e-01, 1.8302e-01,\n",
            "        3.7164e-01, 2.9486e-01, 4.7665e-01, 3.6574e-01, 5.6739e-01, 4.4720e-01,\n",
            "        6.5335e-01, 5.3222e-01, 4.0749e-10, 4.9276e-01, 6.8936e-07, 4.1127e-01,\n",
            "        3.2855e-01, 5.9365e-01, 9.7861e-01, 5.4715e-01, 1.0887e-06, 1.5559e-01,\n",
            "        7.5225e-13, 1.4283e-01, 3.9088e-01, 1.9504e-01, 1.5257e-01, 8.7036e-01,\n",
            "        9.2123e-01, 1.7312e-01, 1.2458e-01, 1.0000e+00, 1.9310e-01, 2.8752e-01,\n",
            "        4.9815e-01, 1.7553e-01, 5.4261e-01, 1.0556e-01, 5.4261e-01, 9.8708e-02,\n",
            "        6.1104e-01, 8.3091e-02, 5.8596e-01, 8.8621e-01, 6.3002e-01, 1.8262e-01,\n",
            "        1.3905e-01, 6.1316e-02, 7.9832e-02, 9.9995e-01, 9.5785e-01, 9.6456e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 8.4739e-02, 5.5287e-02, 3.3458e-02,\n",
            "        5.6952e-08, 3.3567e-01, 8.9543e-01, 9.9653e-01, 9.6593e-01, 2.0843e-01,\n",
            "        1.2390e-01, 4.7006e-01, 9.8503e-01, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1226e-01, 6.1316e-01, 4.6098e-10, 1.5707e-01, 6.0306e-26, 9.6246e-01,\n",
            "        5.8357e-01, 2.7501e-02, 6.1441e-01, 2.9768e-01, 1.3346e-01, 1.6710e-01,\n",
            "        1.9057e-01, 9.9654e-01, 7.1169e-01, 6.2211e-01, 2.0837e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 9.7588e-01, 0.0000e+00, 9.7969e-13, 3.9885e-01,\n",
            "        1.2049e-11, 9.7894e-01, 8.2212e-01, 1.7683e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 2.2685e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 8.6001e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.9964e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.8653e-01])\n",
            "Molecule 189: tensor([9.9508e-02, 6.3135e-01, 4.9462e-01, 4.9589e-01, 4.4253e-01, 5.3673e-01,\n",
            "        5.6432e-01, 4.8336e-01, 5.4459e-01, 4.3335e-01, 5.9914e-01, 4.8032e-01,\n",
            "        6.1825e-01, 4.9370e-01, 4.0749e-10, 6.8190e-01, 6.8936e-07, 5.6830e-01,\n",
            "        3.2855e-01, 9.0053e-01, 8.9471e-01, 3.2778e-01, 6.2210e-01, 4.8841e-01,\n",
            "        7.5225e-13, 4.5830e-01, 5.2237e-01, 6.0879e-01, 6.9648e-01, 3.5351e-01,\n",
            "        4.0781e-01, 5.2333e-01, 4.5625e-01, 1.0000e+00, 4.5523e-01, 4.7969e-01,\n",
            "        4.8807e-01, 4.8537e-01, 5.8723e-01, 1.3352e-01, 5.8723e-01, 8.4213e-01,\n",
            "        2.5873e-01, 7.6370e-01, 5.5399e-01, 8.8393e-01, 5.7093e-01, 5.2623e-01,\n",
            "        4.5470e-01, 4.3608e-01, 3.0517e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        6.3529e-01, 8.6504e-01, 6.1776e-01, 3.0707e-01, 4.7447e-01, 3.4646e-01,\n",
            "        5.6952e-08, 4.6631e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 4.9654e-01,\n",
            "        1.2694e-01, 4.7006e-01, 9.8503e-01, 1.4598e-01, 1.7356e-22, 8.9188e-01,\n",
            "        8.1590e-01, 7.8931e-01, 4.6098e-10, 1.5707e-01, 3.6681e-01, 7.0106e-01,\n",
            "        8.5635e-01, 4.3242e-01, 6.1441e-01, 2.9768e-01, 5.4946e-01, 1.6710e-01,\n",
            "        5.7002e-01, 8.7862e-24, 3.9865e-01, 6.2211e-01, 7.8674e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.3924e-01, 9.7588e-01, 0.0000e+00, 9.7969e-13, 5.7380e-01,\n",
            "        1.2049e-11, 9.3864e-01, 5.6989e-01, 7.4330e-01, 2.9949e-06, 9.9106e-01,\n",
            "        5.3014e-05, 2.8450e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.0091e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.0122e-01,\n",
            "        9.9999e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 9.9999e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.0000e+00,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 9.6615e-01, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.1310e-01])\n",
            "Molecule 190: tensor([3.2095e-01, 7.4159e-01, 7.6324e-01, 6.5701e-01, 7.2599e-01, 7.2823e-01,\n",
            "        5.9665e-01, 6.9353e-01, 5.9117e-01, 7.0833e-01, 6.0216e-01, 7.8031e-01,\n",
            "        6.1379e-01, 8.1874e-01, 9.2276e-01, 8.9623e-01, 6.8936e-07, 9.5484e-01,\n",
            "        4.5904e-01, 1.3031e-01, 8.5158e-01, 8.3722e-01, 1.0887e-06, 3.3331e-01,\n",
            "        8.4910e-01, 8.0074e-01, 9.1765e-01, 8.9240e-01, 8.4838e-01, 3.7498e-01,\n",
            "        2.9213e-01, 7.4282e-01, 8.2269e-01, 1.0000e+00, 7.3560e-01, 6.1595e-01,\n",
            "        5.1869e-01, 7.5265e-01, 6.4965e-01, 6.8931e-01, 6.4965e-01, 8.8805e-01,\n",
            "        6.2747e-01, 8.9778e-01, 1.4359e-01, 3.0155e-01, 2.2776e-01, 6.4729e-01,\n",
            "        8.0573e-01, 7.0728e-01, 9.2017e-01, 9.9386e-22, 9.5785e-01, 9.3704e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 9.1034e-01, 7.3166e-01, 9.0962e-01,\n",
            "        5.6952e-08, 4.6631e-01, 0.0000e+00, 9.8000e-01, 8.8066e-01, 7.7326e-01,\n",
            "        7.7664e-01, 9.9251e-01, 3.6088e-15, 1.4598e-01, 9.9399e-01, 9.6111e-01,\n",
            "        9.2251e-01, 6.3417e-01, 4.6098e-10, 1.0000e+00, 6.2062e-01, 7.3439e-02,\n",
            "        5.4795e-01, 1.7665e-01, 6.1441e-01, 9.1682e-01, 9.5933e-01, 1.6710e-01,\n",
            "        6.1584e-01, 8.7862e-24, 5.1806e-01, 4.2582e-01, 4.3735e-01, 5.3014e-05,\n",
            "        7.3111e-01, 3.1443e-01, 6.9527e-13, 0.0000e+00, 9.9420e-01, 8.3085e-01,\n",
            "        7.6148e-01, 9.4722e-01, 4.4068e-01, 4.2371e-01, 9.9949e-01, 9.8622e-01,\n",
            "        5.3014e-05, 9.1826e-01, 5.3014e-05, 9.9621e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.1066e-01, 2.0287e-02,\n",
            "        1.0000e+00, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.0000e+00, 1.0000e+00, 9.4294e-01, 9.6973e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 8.9864e-01, 2.6412e-12, 9.9913e-02,\n",
            "        9.9953e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 1.0000e+00,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 3.0263e-01])\n",
            "Molecule 191: tensor([7.4530e-01, 1.9691e-01, 9.6145e-02, 8.8065e-02, 6.4131e-02, 1.1105e-01,\n",
            "        1.2159e-01, 8.2844e-02, 1.4160e-01, 8.7917e-02, 2.2980e-01, 1.5051e-01,\n",
            "        2.9952e-01, 2.0244e-01, 7.7959e-01, 5.1130e-01, 6.8936e-07, 2.1524e-01,\n",
            "        6.7000e-01, 1.5118e-01, 9.2584e-11, 7.5902e-01, 6.1381e-01, 2.3915e-11,\n",
            "        3.7056e-01, 7.3013e-02, 5.1817e-01, 5.1526e-01, 5.1325e-01, 2.4204e-01,\n",
            "        6.5363e-01, 1.0630e-01, 7.6955e-02, 1.0000e+00, 6.0643e-02, 4.8457e-02,\n",
            "        2.4176e-01, 8.6976e-02, 3.3537e-01, 7.2840e-01, 3.3537e-01, 7.8928e-01,\n",
            "        3.4528e-01, 7.9083e-01, 2.5748e-01, 2.6247e-01, 2.4078e-01, 8.0343e-02,\n",
            "        7.0932e-02, 4.3608e-01, 1.9367e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 1.6844e-01, 4.7447e-01, 9.8237e-02,\n",
            "        5.6952e-08, 1.1745e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.1646e-01,\n",
            "        3.3834e-01, 5.7614e-21, 3.6088e-15, 8.3941e-01, 1.7356e-22, 8.9828e-01,\n",
            "        6.1801e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 5.5749e-01, 1.1707e-01,\n",
            "        4.1465e-01, 4.5639e-01, 3.9661e-01, 5.8544e-01, 2.3908e-01, 1.6710e-01,\n",
            "        1.7959e-01, 8.7862e-24, 3.9050e-01, 3.0449e-02, 5.4233e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 2.1663e-01,\n",
            "        5.3171e-01, 2.8631e-09, 6.4508e-01, 4.6659e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 3.0148e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 5.2888e-01, 2.0287e-02,\n",
            "        1.0000e+00, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 7.9681e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.0000e+00, 1.0000e+00, 7.9714e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 9.2658e-01])\n",
            "Molecule 192: tensor([7.8373e-01, 3.7738e-01, 2.9798e-01, 2.4916e-01, 3.2884e-01, 3.2468e-01,\n",
            "        2.4748e-01, 2.7880e-01, 1.9470e-01, 2.3724e-01, 1.9031e-01, 2.1124e-01,\n",
            "        2.1775e-01, 2.2769e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        7.6296e-01, 5.4925e-01, 9.2584e-11, 5.4738e-01, 6.7748e-01, 6.2823e-01,\n",
            "        9.2128e-01, 3.7878e-01, 6.5094e-01, 7.8800e-01, 8.8201e-01, 1.3134e-01,\n",
            "        7.2851e-01, 3.0986e-01, 4.0540e-01, 1.0000e+00, 3.2956e-01, 4.3027e-01,\n",
            "        4.7072e-01, 3.7621e-01, 1.9381e-02, 8.5190e-02, 1.9381e-02, 7.8529e-02,\n",
            "        8.9246e-01, 6.3880e-02, 8.3090e-01, 9.0772e-01, 7.7777e-01, 4.1255e-01,\n",
            "        3.7777e-01, 4.3608e-01, 1.9367e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 3.0707e-01, 4.7447e-01, 3.4646e-01,\n",
            "        5.6952e-08, 2.1430e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 2.6921e-01,\n",
            "        8.7215e-03, 4.7105e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        8.4559e-01, 6.4388e-01, 4.6098e-10, 9.9995e-01, 7.6367e-01, 1.8561e-01,\n",
            "        4.9747e-01, 8.3015e-01, 3.9661e-01, 1.8363e-01, 9.1640e-01, 1.6710e-01,\n",
            "        2.1099e-01, 9.9524e-01, 1.9854e-02, 4.5041e-01, 7.8476e-01, 5.3014e-05,\n",
            "        1.4266e-16, 3.2529e-01, 9.8384e-01, 0.0000e+00, 9.9415e-01, 2.8345e-01,\n",
            "        2.4741e-01, 2.8631e-09, 1.7808e-01, 8.1860e-01, 1.0000e+00, 2.7764e-01,\n",
            "        5.3014e-05, 1.3994e-01, 5.3014e-05, 9.9897e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 9.9795e-01, 5.3014e-05, 9.9865e-01, 8.8773e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.0000e+00, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        1.0000e+00, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 1.0000e+00, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 9.6071e-01,\n",
            "        1.6663e-01, 3.4681e-01])\n",
            "Molecule 193: tensor([4.4404e-01, 2.4433e-01, 1.7717e-01, 2.5414e-01, 2.0684e-01, 2.2799e-01,\n",
            "        2.7396e-01, 2.0721e-01, 3.1719e-01, 2.2240e-01, 4.0480e-01, 2.9257e-01,\n",
            "        3.8836e-01, 2.7441e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        1.4053e-01, 8.9994e-01, 9.2584e-11, 5.8561e-17, 6.5638e-01, 8.5034e-01,\n",
            "        3.4911e-01, 1.6394e-01, 2.1714e-01, 3.2411e-01, 5.4310e-01, 5.2893e-01,\n",
            "        6.6084e-01, 2.1432e-01, 1.5884e-01, 1.0000e+00, 1.2020e-01, 9.9724e-02,\n",
            "        2.8209e-01, 2.0088e-01, 1.7619e-02, 3.9331e-01, 1.7619e-02, 5.1621e-01,\n",
            "        9.6921e-01, 4.9693e-01, 8.6588e-01, 5.9346e-01, 2.0788e-01, 2.3241e-01,\n",
            "        1.5973e-01, 6.1316e-02, 5.0000e-01, 9.9386e-22, 9.5785e-01, 9.3704e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 6.7960e-01, 5.5287e-02, 3.4646e-01,\n",
            "        5.6952e-08, 1.6146e-02, 0.0000e+00, 9.8000e-01, 8.8066e-01, 2.0843e-01,\n",
            "        7.6957e-01, 4.6303e-01, 9.9566e-01, 1.4598e-01, 9.7764e-01, 1.1809e-10,\n",
            "        5.9983e-02, 9.0550e-08, 4.6098e-10, 9.9999e-01, 2.5786e-01, 1.2327e-01,\n",
            "        8.8329e-01, 2.0344e-01, 6.1441e-01, 1.8189e-01, 3.8644e-01, 1.6710e-01,\n",
            "        6.0193e-01, 8.7862e-24, 1.9854e-02, 9.4213e-01, 1.5732e-01, 5.3014e-05,\n",
            "        7.3255e-01, 7.8401e-01, 9.9749e-01, 7.7419e-01, 9.7969e-13, 7.7084e-01,\n",
            "        1.2049e-11, 2.8631e-09, 8.2539e-03, 2.5614e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 1.2869e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 8.8035e-01, 2.4552e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.0122e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 9.2413e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.4279e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.8691e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 9.4590e-01, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 8.4801e-01])\n",
            "Molecule 194: tensor([6.5692e-01, 5.3350e-01, 2.0975e-01, 1.8787e-01, 1.4759e-01, 2.8880e-01,\n",
            "        2.0830e-01, 1.5154e-01, 1.7175e-01, 1.0928e-01, 2.1775e-01, 1.4156e-01,\n",
            "        2.4195e-01, 1.5891e-01, 4.0749e-10, 2.6487e-01, 6.8936e-07, 2.1524e-01,\n",
            "        4.8119e-01, 2.9375e-01, 6.4788e-01, 9.4334e-01, 5.8558e-01, 5.8625e-01,\n",
            "        7.5225e-13, 1.7503e-01, 1.5984e-01, 4.1048e-01, 5.7434e-01, 2.1555e-14,\n",
            "        2.6017e-01, 2.6018e-01, 1.9521e-01, 1.0000e+00, 1.1726e-01, 1.2556e-01,\n",
            "        2.9529e-01, 2.1259e-01, 4.3037e-01, 9.2668e-02, 4.3037e-01, 2.3031e-01,\n",
            "        7.4212e-01, 2.1683e-01, 6.4381e-01, 8.9980e-01, 2.6484e-01, 2.0447e-01,\n",
            "        1.7066e-01, 6.1316e-02, 5.0000e-01, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        3.4723e-02, 9.6609e-01, 9.1765e-01, 6.7960e-01, 5.5287e-02, 3.4646e-01,\n",
            "        5.6952e-08, 1.1745e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.8301e-01,\n",
            "        8.7215e-03, 4.6338e-01, 9.8441e-01, 8.3941e-01, 1.7356e-22, 1.1809e-10,\n",
            "        8.3066e-01, 7.9695e-01, 9.5805e-01, 1.5707e-01, 1.3924e-01, 2.9329e-01,\n",
            "        7.2747e-01, 6.6583e-01, 6.1441e-01, 1.8288e-01, 2.3196e-01, 1.6710e-01,\n",
            "        9.2241e-01, 8.7862e-24, 1.9854e-02, 3.0449e-02, 8.0942e-01, 5.3014e-05,\n",
            "        7.3111e-01, 3.7316e-02, 6.9527e-13, 0.0000e+00, 9.7969e-13, 3.9949e-01,\n",
            "        1.2049e-11, 2.8631e-09, 2.8662e-01, 8.4334e-01, 2.9949e-06, 9.9116e-01,\n",
            "        5.3014e-05, 4.9900e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 3.9982e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.7471e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 9.2413e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.0000e+00, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.0000e+00, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 4.1870e-01])\n",
            "Molecule 195: tensor([9.6439e-01, 2.6967e-01, 7.6341e-02, 2.5329e-02, 7.2371e-02, 4.6183e-02,\n",
            "        1.7991e-02, 2.0221e-01, 2.7908e-02, 3.7200e-01, 3.2166e-02, 3.6533e-01,\n",
            "        3.7642e-02, 4.2228e-01, 8.9161e-01, 7.6395e-01, 6.8936e-07, 5.1436e-01,\n",
            "        1.9674e-02, 3.2209e-01, 6.4405e-01, 5.8561e-17, 1.0887e-06, 3.0999e-01,\n",
            "        7.8075e-01, 1.5791e-01, 9.0997e-01, 7.8800e-01, 6.1096e-01, 2.1555e-14,\n",
            "        9.2792e-01, 5.9953e-02, 1.9348e-01, 1.0000e+00, 7.9036e-02, 2.0409e-02,\n",
            "        2.7928e-01, 5.9332e-02, 1.4601e-01, 1.5178e-01, 1.4601e-01, 6.7460e-01,\n",
            "        6.5568e-01, 6.6293e-01, 3.7562e-02, 8.3788e-01, 3.9378e-02, 4.5400e-02,\n",
            "        1.5534e-01, 8.4234e-01, 6.9483e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 4.9226e-01, 7.3166e-01, 8.0827e-01,\n",
            "        5.6952e-08, 1.6146e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.0269e-01,\n",
            "        1.3928e-01, 8.2872e-01, 3.6088e-15, 9.0234e-01, 9.9156e-01, 1.1809e-10,\n",
            "        5.9983e-02, 8.7165e-01, 9.8049e-01, 9.9975e-01, 2.4789e-01, 6.8268e-02,\n",
            "        8.0760e-02, 4.1884e-01, 1.2027e-01, 6.8754e-01, 9.4081e-01, 1.6710e-01,\n",
            "        7.5581e-02, 9.9482e-01, 1.8462e-01, 1.8391e-01, 7.4439e-02, 5.3014e-05,\n",
            "        1.4266e-16, 6.2356e-01, 9.8384e-01, 0.0000e+00, 9.8549e-01, 2.5203e-01,\n",
            "        7.8112e-01, 2.8631e-09, 8.2539e-03, 2.0125e-01, 9.9949e-01, 2.7764e-01,\n",
            "        5.3014e-05, 8.6204e-01, 5.3014e-05, 9.9311e-01, 0.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 3.9982e-01, 1.4489e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 9.9999e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.8152e-01])\n",
            "Molecule 196: tensor([8.7659e-01, 2.6685e-01, 1.7956e-01, 2.0259e-01, 1.6051e-01, 1.6707e-01,\n",
            "        1.6866e-01, 1.1938e-01, 1.9603e-01, 1.2702e-01, 2.4280e-01, 1.6027e-01,\n",
            "        3.1860e-01, 2.1738e-01, 4.0749e-10, 5.1130e-01, 6.8936e-07, 6.0340e-01,\n",
            "        4.8982e-01, 1.5101e-01, 6.0630e-01, 7.5118e-01, 6.8081e-01, 1.6207e-01,\n",
            "        7.5225e-13, 1.3040e-01, 3.9088e-01, 3.0578e-01, 3.1493e-01, 3.4363e-01,\n",
            "        5.5058e-01, 1.7312e-01, 1.3198e-01, 1.0000e+00, 1.2138e-01, 6.8754e-02,\n",
            "        2.6049e-01, 1.5105e-01, 4.0064e-01, 1.0147e-01, 4.0064e-01, 3.4320e-01,\n",
            "        6.6224e-01, 3.3501e-01, 6.1418e-01, 8.9051e-01, 1.5758e-01, 1.5972e-01,\n",
            "        1.2683e-01, 6.1316e-02, 5.0000e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 3.0707e-01, 5.5287e-02, 3.4646e-01,\n",
            "        5.6952e-08, 1.6146e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.7147e-01,\n",
            "        8.7215e-03, 7.2902e-01, 9.8518e-01, 9.1627e-01, 1.7356e-22, 1.1809e-10,\n",
            "        9.6717e-01, 9.0550e-08, 9.5805e-01, 1.5707e-01, 3.6664e-01, 1.2202e-01,\n",
            "        4.6931e-01, 2.0371e-01, 3.9661e-01, 3.1354e-01, 7.3926e-01, 1.6710e-01,\n",
            "        4.0702e-01, 9.9096e-01, 2.6574e-01, 5.5482e-01, 2.1248e-01, 5.3014e-05,\n",
            "        1.4266e-16, 5.9018e-01, 9.9749e-01, 0.0000e+00, 9.7969e-13, 3.6491e-01,\n",
            "        7.0122e-01, 9.4722e-01, 1.9923e-01, 2.5614e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 2.8928e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 7.6766e-01, 5.3014e-05, 0.0000e+00, 7.4542e-01, 2.3717e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 9.0122e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 7.9714e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 8.4442e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 8.9864e-01, 2.6412e-12, 9.4279e-01,\n",
            "        9.9990e-01, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 9.9991e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.5879e-01])\n",
            "Molecule 197: tensor([9.6198e-01, 2.3217e-01, 7.6341e-02, 2.8591e-02, 7.9480e-02, 4.6183e-02,\n",
            "        2.2146e-02, 2.2956e-01, 3.3910e-02, 4.2188e-01, 4.0894e-02, 4.3460e-01,\n",
            "        4.8829e-02, 4.9721e-01, 8.9161e-01, 7.6395e-01, 6.8936e-07, 7.4489e-01,\n",
            "        1.9674e-02, 1.6094e-01, 6.4405e-01, 5.8561e-17, 1.0887e-06, 3.2000e-01,\n",
            "        7.8075e-01, 1.6340e-01, 9.0997e-01, 7.8800e-01, 6.1096e-01, 1.6747e-01,\n",
            "        9.5344e-01, 5.9953e-02, 1.9348e-01, 1.0000e+00, 8.9169e-02, 2.4836e-02,\n",
            "        2.9270e-01, 6.1454e-02, 1.5729e-01, 1.9454e-01, 1.5729e-01, 3.6088e-01,\n",
            "        1.0153e-01, 3.5330e-01, 3.7807e-02, 7.9374e-01, 2.6410e-02, 4.3540e-02,\n",
            "        1.6077e-01, 9.0949e-01, 6.9483e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 4.9226e-01, 8.5589e-01, 8.0827e-01,\n",
            "        5.6952e-08, 1.6146e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.0933e-01,\n",
            "        1.3928e-01, 6.5057e-01, 3.6088e-15, 9.4948e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 9.4713e-01, 9.5307e-01, 1.5707e-01, 2.4789e-01, 6.8268e-02,\n",
            "        8.0760e-02, 6.6356e-01, 1.2027e-01, 6.8754e-01, 8.8458e-01, 1.6710e-01,\n",
            "        1.8464e-01, 9.8415e-01, 1.8462e-01, 4.1394e-01, 7.4439e-02, 5.3014e-05,\n",
            "        1.4266e-16, 8.0255e-01, 9.8384e-01, 0.0000e+00, 9.8549e-01, 2.5880e-01,\n",
            "        7.8112e-01, 2.8631e-09, 8.2539e-03, 1.5197e-01, 9.9949e-01, 2.7764e-01,\n",
            "        5.3014e-05, 8.6081e-01, 5.3014e-05, 9.9317e-01, 0.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 4.0273e-01, 1.4608e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 8.3841e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 9.9999e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.9539e-01])\n",
            "Molecule 198: tensor([9.6752e-01, 3.1592e-01, 1.9122e-01, 6.0589e-02, 1.0154e-01, 9.6726e-02,\n",
            "        4.2483e-02, 2.6184e-01, 6.6280e-02, 4.4947e-01, 6.9934e-02, 4.1832e-01,\n",
            "        8.2340e-02, 4.7709e-01, 9.3457e-01, 9.4621e-01, 6.8936e-07, 4.3898e-01,\n",
            "        3.3331e-01, 2.5099e-11, 9.2584e-11, 5.8561e-17, 4.4091e-01, 1.6919e-01,\n",
            "        3.7241e-01, 2.7224e-01, 7.9826e-01, 5.2973e-01, 2.8109e-01, 3.1694e-01,\n",
            "        9.0196e-01, 1.3706e-01, 3.1533e-01, 1.0000e+00, 2.1290e-01, 4.4581e-02,\n",
            "        3.3752e-01, 9.4740e-02, 5.3509e-01, 3.2259e-01, 5.3509e-01, 9.5897e-01,\n",
            "        8.6933e-01, 9.2605e-01, 3.0243e-02, 7.9368e-01, 3.5733e-02, 4.3510e-02,\n",
            "        2.6731e-01, 9.0949e-01, 6.9483e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 4.9226e-01, 8.5589e-01, 9.0962e-01,\n",
            "        5.6952e-08, 1.6146e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.9532e-01,\n",
            "        1.3928e-01, 4.1842e-01, 3.6088e-15, 9.4948e-01, 1.7356e-22, 9.0264e-01,\n",
            "        5.9983e-02, 9.4713e-01, 9.9428e-01, 1.5707e-01, 6.0306e-26, 6.8268e-02,\n",
            "        8.0760e-02, 7.9833e-01, 1.2027e-01, 9.0035e-01, 6.5128e-01, 1.6710e-01,\n",
            "        1.8464e-01, 9.8415e-01, 3.2583e-01, 4.1394e-01, 7.6856e-02, 5.3014e-05,\n",
            "        1.4266e-16, 8.0255e-01, 9.9787e-01, 0.0000e+00, 9.7969e-13, 2.5880e-01,\n",
            "        8.7911e-01, 2.8631e-09, 7.2529e-02, 1.5197e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 8.6081e-01, 5.3014e-05, 5.0000e-01, 0.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 3.4236e-01, 1.4024e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 8.3841e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.0000e+00, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.8713e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 9.9999e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.2164e-01])\n",
            "Molecule 199: tensor([9.5875e-01, 3.0866e-01, 1.8811e-01, 8.4866e-02, 2.4243e-01, 1.0547e-01,\n",
            "        5.6813e-02, 4.3049e-01, 8.8062e-02, 6.4560e-01, 1.1446e-01, 7.2671e-01,\n",
            "        1.0233e-01, 7.5124e-01, 9.1279e-01, 7.6395e-01, 6.8936e-07, 7.1994e-01,\n",
            "        1.9674e-02, 2.7159e-01, 7.8744e-01, 5.8561e-17, 1.0887e-06, 1.6919e-01,\n",
            "        9.2340e-01, 3.7838e-01, 9.6061e-01, 8.5173e-01, 5.5025e-01, 4.5627e-01,\n",
            "        9.7021e-01, 1.3706e-01, 4.2231e-01, 1.0000e+00, 2.6435e-01, 8.8824e-02,\n",
            "        3.2529e-01, 1.7835e-01, 3.1256e-01, 1.8739e-01, 3.1256e-01, 3.7689e-01,\n",
            "        1.2345e-01, 3.6973e-01, 3.7269e-02, 8.0108e-01, 5.8628e-02, 1.2714e-01,\n",
            "        3.7777e-01, 8.4234e-01, 6.9483e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 4.9226e-01, 7.3166e-01, 8.6759e-01,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.9532e-01,\n",
            "        1.3928e-01, 8.2524e-01, 3.6088e-15, 9.4948e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 9.4713e-01, 9.4638e-01, 1.0000e+00, 2.4789e-01, 6.8268e-02,\n",
            "        1.6303e-01, 6.3911e-01, 1.2027e-01, 6.8754e-01, 9.6676e-01, 1.6710e-01,\n",
            "        1.7133e-01, 9.8415e-01, 3.2559e-01, 5.8975e-01, 7.4439e-02, 5.3014e-05,\n",
            "        1.4266e-16, 6.2356e-01, 9.8384e-01, 0.0000e+00, 9.9415e-01, 5.7972e-01,\n",
            "        7.8112e-01, 2.8631e-09, 8.2539e-03, 1.5197e-01, 9.9949e-01, 2.7764e-01,\n",
            "        5.3014e-05, 8.2305e-01, 5.3014e-05, 9.9870e-01, 0.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 2.5637e-01, 5.3014e-05, 0.0000e+00, 3.9982e-01, 1.5296e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.7007e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 9.9999e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.6071e-01])\n",
            "Molecule 200: tensor([9.0635e-01, 4.3951e-01, 4.7148e-01, 2.2852e-01, 4.6298e-01, 2.7748e-01,\n",
            "        1.4815e-01, 6.7448e-01, 2.0492e-01, 8.2512e-01, 1.7654e-01, 8.5891e-01,\n",
            "        1.6106e-01, 8.6973e-01, 9.3678e-01, 9.4621e-01, 6.8936e-07, 7.1577e-01,\n",
            "        3.2142e-01, 4.1791e-01, 6.7130e-01, 5.8561e-17, 1.0887e-06, 1.6919e-01,\n",
            "        7.8075e-01, 6.7140e-01, 9.3945e-01, 7.8800e-01, 5.0352e-01, 6.6357e-01,\n",
            "        9.6243e-01, 3.6230e-01, 7.1082e-01, 1.0000e+00, 6.0967e-01, 2.9970e-01,\n",
            "        5.6568e-01, 3.8882e-01, 4.0255e-01, 2.5760e-01, 4.0255e-01, 9.4427e-01,\n",
            "        4.6903e-02, 9.2127e-01, 3.4938e-02, 8.0052e-01, 1.4445e-01, 2.5977e-01,\n",
            "        6.7456e-01, 8.4234e-01, 6.9483e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 6.7960e-01, 7.3166e-01, 9.5878e-01,\n",
            "        5.6952e-08, 2.1430e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 4.7370e-01,\n",
            "        1.3928e-01, 8.2524e-01, 3.6088e-15, 9.4948e-01, 1.7356e-22, 9.0264e-01,\n",
            "        5.9983e-02, 9.4713e-01, 9.9405e-01, 1.0000e+00, 2.4789e-01, 6.8268e-02,\n",
            "        2.7770e-01, 6.3505e-01, 1.2027e-01, 9.0035e-01, 9.6735e-01, 1.6710e-01,\n",
            "        1.7133e-01, 9.8415e-01, 4.5818e-01, 7.0700e-01, 7.4439e-02, 5.3014e-05,\n",
            "        1.4266e-16, 6.2356e-01, 9.9787e-01, 0.0000e+00, 9.9420e-01, 7.3719e-01,\n",
            "        7.8112e-01, 2.8631e-09, 8.2539e-03, 1.5197e-01, 9.9949e-01, 2.7764e-01,\n",
            "        5.3014e-05, 8.2305e-01, 5.3014e-05, 9.9449e-01, 0.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 3.9982e-01, 1.4958e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 5.9826e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.0000e+00, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.9366e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 9.9999e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 7.3844e-01])\n",
            "Molecule 201: tensor([9.5140e-01, 3.0844e-01, 1.8811e-01, 5.8875e-02, 2.4708e-01, 1.0182e-01,\n",
            "        4.2977e-02, 4.4227e-01, 6.7221e-02, 6.8755e-01, 6.5236e-02, 6.1626e-01,\n",
            "        7.4750e-02, 7.0554e-01, 9.2441e-01, 7.6395e-01, 6.8936e-07, 5.1436e-01,\n",
            "        1.9674e-02, 3.1540e-01, 9.2584e-11, 5.8561e-17, 1.0887e-06, 3.2000e-01,\n",
            "        9.7324e-01, 4.5725e-01, 8.6180e-01, 6.2186e-01, 3.3731e-01, 3.1694e-01,\n",
            "        9.8106e-01, 1.3706e-01, 5.1942e-01, 1.0000e+00, 2.8436e-01, 1.0211e-01,\n",
            "        3.8753e-01, 2.0501e-01, 2.3032e-01, 1.8547e-01, 2.3032e-01, 3.6284e-01,\n",
            "        4.4596e-01, 3.5531e-01, 3.6987e-02, 8.0306e-01, 7.0972e-02, 1.2835e-01,\n",
            "        4.5960e-01, 9.0949e-01, 6.9483e-01, 9.9386e-22, 9.1873e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 4.9226e-01, 8.5589e-01, 9.0962e-01,\n",
            "        5.6952e-08, 5.2057e-02, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.9532e-01,\n",
            "        1.3928e-01, 9.0173e-01, 3.6088e-15, 9.4948e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 9.4713e-01, 9.5307e-01, 1.0000e+00, 2.4789e-01, 6.8268e-02,\n",
            "        8.0760e-02, 4.1884e-01, 1.2027e-01, 6.8754e-01, 9.9120e-01, 1.6710e-01,\n",
            "        1.8464e-01, 9.8415e-01, 4.3091e-01, 1.8391e-01, 7.4439e-02, 5.3014e-05,\n",
            "        1.4266e-16, 8.0255e-01, 9.8384e-01, 0.0000e+00, 9.9658e-01, 3.4839e-01,\n",
            "        7.8112e-01, 2.8631e-09, 8.2539e-03, 1.5197e-01, 9.9949e-01, 2.7764e-01,\n",
            "        5.3014e-05, 8.6081e-01, 5.3014e-05, 9.9959e-01, 0.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 0.0000e+00, 3.9982e-01, 1.4408e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 6.8719e-10, 8.3841e-01, 9.9989e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9997e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 8.7973e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 9.8713e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 9.9999e-01, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 5.9874e-01])\n",
            "Molecule 202: tensor([1.9608e-05, 9.2995e-02, 1.4914e-01, 3.4331e-01, 2.6940e-01, 1.3943e-01,\n",
            "        2.2702e-01, 1.6713e-01, 2.5185e-01, 1.6954e-01, 3.2489e-01, 2.2481e-01,\n",
            "        4.4921e-01, 3.2744e-01, 5.7359e-01, 2.6487e-01, 6.8936e-07, 8.3728e-01,\n",
            "        1.6109e-01, 4.6223e-01, 9.2584e-11, 5.8561e-17, 7.2834e-01, 5.1608e-01,\n",
            "        3.4911e-01, 1.9903e-01, 9.2881e-01, 8.4904e-01, 6.5968e-01, 6.8907e-01,\n",
            "        9.0881e-01, 1.7312e-01, 1.8083e-01, 1.0000e+00, 4.0648e-01, 4.3047e-01,\n",
            "        4.2644e-01, 2.3902e-01, 4.9957e-01, 1.0000e+00, 4.9957e-01, 9.9999e-01,\n",
            "        3.2429e-10, 1.0000e+00, 3.6635e-01, 6.6624e-12, 3.2067e-02, 1.8118e-01,\n",
            "        1.9577e-01, 6.1316e-02, 1.2405e-01, 9.9995e-01, 1.4249e-01, 5.0000e-01,\n",
            "        3.5821e-01, 4.8299e-15, 8.3758e-02, 1.6844e-01, 5.5287e-02, 9.8237e-02,\n",
            "        5.6952e-08, 2.1430e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 2.2235e-01,\n",
            "        8.3438e-01, 4.4803e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 9.2327e-01,\n",
            "        3.1226e-01, 9.0550e-08, 4.6098e-10, 1.5707e-01, 7.1154e-01, 4.9499e-01,\n",
            "        1.4787e-01, 2.4187e-01, 1.2027e-01, 8.4358e-01, 1.3599e-01, 1.6710e-01,\n",
            "        1.9057e-01, 8.7862e-24, 6.1668e-01, 6.4541e-01, 3.7539e-01, 5.3014e-05,\n",
            "        1.4266e-16, 7.1007e-01, 6.9527e-13, 0.0000e+00, 9.7969e-13, 5.3597e-01,\n",
            "        6.5341e-01, 2.8631e-09, 5.1614e-01, 4.6691e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 4.3578e-02, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 7.8880e-01, 2.4366e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 5.0000e-01, 5.0000e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.0000e+00, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.0000e+00, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 9.9997e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 4.6492e-01])\n",
            "Molecule 203: tensor([6.8435e-01, 9.8786e-02, 1.6663e-01, 2.1862e-01, 2.3075e-01, 1.9033e-01,\n",
            "        2.4329e-01, 2.4518e-01, 2.0233e-01, 1.7779e-01, 2.0574e-01, 1.5781e-01,\n",
            "        1.8814e-01, 1.6091e-01, 4.0749e-10, 2.1752e-08, 6.8936e-07, 1.0022e-01,\n",
            "        5.2780e-01, 4.7178e-01, 6.2858e-01, 5.8561e-17, 6.7748e-01, 8.3243e-01,\n",
            "        7.7261e-01, 1.8095e-01, 2.9491e-01, 1.9504e-01, 1.8362e-01, 4.5627e-01,\n",
            "        8.8029e-01, 1.7312e-01, 1.6882e-01, 1.0000e+00, 2.6913e-01, 5.8929e-01,\n",
            "        6.5544e-01, 2.1883e-01, 1.7874e-02, 8.3658e-01, 1.7874e-02, 5.0391e-02,\n",
            "        8.7331e-01, 3.8247e-02, 8.2554e-01, 1.5115e-01, 6.9770e-01, 2.6487e-01,\n",
            "        1.7788e-01, 6.1316e-02, 7.9832e-02, 9.9386e-22, 1.4249e-01, 6.2963e-02,\n",
            "        6.3529e-01, 4.8299e-15, 3.8583e-01, 8.4739e-02, 5.5287e-02, 3.3458e-02,\n",
            "        5.6952e-08, 6.9263e-01, 0.0000e+00, 1.1424e-21, 2.4025e-23, 1.9532e-01,\n",
            "        1.1811e-01, 7.3642e-01, 3.6088e-15, 1.4598e-01, 1.7356e-22, 1.1809e-10,\n",
            "        3.1932e-01, 9.0550e-08, 4.6098e-10, 1.0000e+00, 7.7384e-01, 1.9085e-01,\n",
            "        5.8177e-01, 2.7501e-02, 1.2027e-01, 1.8189e-01, 2.3571e-01, 1.6710e-01,\n",
            "        1.9057e-01, 8.7862e-24, 4.0395e-01, 6.0837e-01, 6.5126e-01, 5.3014e-05,\n",
            "        6.9955e-01, 2.7603e-01, 6.9527e-13, 7.0981e-01, 9.8549e-01, 3.9194e-01,\n",
            "        3.2914e-01, 2.8631e-09, 2.0732e-01, 7.6165e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 1.3398e-02, 5.3014e-05, 9.9367e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 8.9476e-01, 2.0287e-02,\n",
            "        5.7087e-19, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 2.7743e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 9.9784e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 6.3535e-01, 1.6148e-09,\n",
            "        1.8752e-18, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 7.6084e-01,\n",
            "        2.1116e-16, 1.1682e-09, 9.0951e-01, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 9.9991e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 6.3509e-01])\n",
            "Molecule 204: tensor([3.0327e-01, 5.8795e-01, 6.8555e-01, 6.0282e-01, 6.2311e-01, 6.4361e-01,\n",
            "        5.7219e-01, 6.0993e-01, 6.7131e-01, 7.9051e-01, 6.2669e-01, 7.8291e-01,\n",
            "        6.5940e-01, 8.4868e-01, 9.4086e-01, 8.9984e-01, 6.8936e-07, 2.1433e-01,\n",
            "        3.0737e-01, 2.5099e-11, 9.6191e-01, 8.9347e-01, 1.0887e-06, 3.2830e-01,\n",
            "        3.2997e-01, 6.8378e-01, 8.5095e-01, 7.8800e-01, 6.5004e-01, 4.5627e-01,\n",
            "        3.0554e-01, 6.6622e-01, 6.9750e-01, 1.0000e+00, 6.3456e-01, 4.5318e-01,\n",
            "        4.8373e-01, 6.5543e-01, 6.4786e-01, 9.5679e-01, 6.4786e-01, 8.3473e-01,\n",
            "        2.9970e-01, 8.4081e-01, 1.8619e-01, 1.9678e-02, 1.5985e-01, 5.9200e-01,\n",
            "        6.8551e-01, 8.4234e-01, 8.7595e-01, 9.9386e-22, 9.5785e-01, 9.3704e-01,\n",
            "        3.5821e-01, 8.6504e-01, 3.8583e-01, 8.2272e-01, 8.5589e-01, 8.0827e-01,\n",
            "        5.6952e-08, 4.6631e-01, 0.0000e+00, 9.9653e-01, 9.4279e-01, 6.8966e-01,\n",
            "        8.8333e-01, 9.6464e-01, 9.8611e-01, 9.1627e-01, 1.7356e-22, 8.9828e-01,\n",
            "        8.2545e-01, 6.3417e-01, 4.6098e-10, 1.0000e+00, 2.5786e-01, 5.6887e-01,\n",
            "        1.3021e-01, 4.9139e-01, 6.1441e-01, 8.9452e-01, 8.6450e-01, 1.6710e-01,\n",
            "        4.2847e-01, 9.8334e-01, 7.4915e-01, 3.0449e-02, 4.7051e-01, 5.3014e-05,\n",
            "        6.9955e-01, 3.1443e-01, 6.9527e-13, 7.0981e-01, 9.8575e-01, 8.2088e-01,\n",
            "        6.3621e-01, 2.8631e-09, 5.9794e-01, 6.1979e-01, 2.9949e-06, 2.7764e-01,\n",
            "        5.3014e-05, 9.0361e-01, 5.3014e-05, 9.3693e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.6466e-01, 5.3014e-05, 9.9865e-01, 8.6276e-01, 2.0287e-02,\n",
            "        1.0000e+00, 3.3236e-10, 9.6420e-10, 7.1054e-15, 5.8371e-13, 1.1988e-20,\n",
            "        1.6508e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00, 8.9595e-01, 9.3063e-01,\n",
            "        7.1054e-15, 1.6835e-01, 1.0000e+00, 5.2233e-01, 5.9826e-01, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 8.9864e-01, 2.6412e-12, 9.9913e-02,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.5823e-01, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        1.0000e+00, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 1.0000e+00,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 9.6562e-01,\n",
            "        9.6582e-01, 2.1135e-02, 2.1135e-02, 2.3882e-20, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.0000e+00, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 3.0055e-01])\n",
            "Molecule 205: tensor([7.1037e-01, 4.2865e-01, 8.2118e-01, 8.5023e-01, 8.3020e-01, 8.4517e-01,\n",
            "        8.8660e-01, 8.5197e-01, 8.2866e-01, 7.6347e-01, 8.4532e-01, 7.7608e-01,\n",
            "        8.5617e-01, 7.8763e-01, 4.0749e-10, 8.4015e-01, 6.8936e-07, 8.4930e-01,\n",
            "        9.5044e-01, 9.6649e-01, 7.8353e-01, 4.9043e-01, 1.0887e-06, 3.1263e-01,\n",
            "        8.3590e-01, 8.2517e-01, 5.0543e-03, 4.6250e-03, 3.5492e-03, 9.6375e-01,\n",
            "        5.8590e-01, 8.2881e-01, 8.0407e-01, 1.0000e+00, 8.6143e-01, 9.1115e-01,\n",
            "        7.1303e-01, 8.2733e-01, 4.8795e-02, 2.4984e-01, 4.8795e-02, 2.7751e-01,\n",
            "        4.3116e-01, 2.6633e-01, 7.0554e-01, 7.3729e-01, 3.4799e-02, 8.4238e-01,\n",
            "        8.2942e-01, 9.0949e-01, 9.6667e-01, 9.9386e-22, 9.5785e-01, 9.3704e-01,\n",
            "        3.4723e-02, 9.2731e-01, 3.8583e-01, 9.9572e-01, 9.1805e-01, 9.0962e-01,\n",
            "        5.6952e-08, 9.0812e-01, 0.0000e+00, 9.9653e-01, 9.4279e-01, 9.0756e-01,\n",
            "        9.7700e-01, 6.9480e-01, 9.9571e-01, 9.1682e-01, 1.7356e-22, 1.1809e-10,\n",
            "        5.9983e-02, 8.0774e-01, 9.8508e-01, 1.5707e-01, 6.0306e-26, 4.8028e-01,\n",
            "        9.6985e-01, 8.5942e-01, 6.1441e-01, 7.9458e-01, 8.4724e-01, 1.6710e-01,\n",
            "        8.1401e-01, 8.7862e-24, 7.1169e-01, 9.9711e-01, 2.5837e-02, 5.3014e-05,\n",
            "        1.4266e-16, 8.9405e-01, 9.9857e-01, 0.0000e+00, 9.7969e-13, 9.8272e-01,\n",
            "        1.2049e-11, 2.8631e-09, 7.0936e-01, 3.0994e-02, 2.9949e-06, 9.8591e-01,\n",
            "        5.3014e-05, 9.3004e-01, 5.3014e-05, 5.0000e-01, 1.0000e+00, 5.3014e-05,\n",
            "        5.3014e-05, 1.0000e+00, 5.3014e-05, 9.9865e-01, 8.8946e-01, 2.0287e-02,\n",
            "        5.7087e-19, 1.0000e+00, 1.0000e+00, 7.1054e-15, 5.8371e-13, 9.6294e-01,\n",
            "        1.6508e-01, 1.6704e-01, 1.6650e-01, 1.6649e-01, 2.0286e-01, 6.9366e-02,\n",
            "        7.1054e-15, 1.6835e-01, 1.6798e-01, 9.9549e-01, 1.1816e-03, 1.6433e-01,\n",
            "        8.3778e-04, 1.6633e-01, 1.6303e-01, 1.6508e-01, 9.5697e-08, 3.4971e-08,\n",
            "        1.6821e-01, 1.6581e-01, 1.6735e-01, 7.1396e-07, 2.6412e-12, 9.5424e-01,\n",
            "        2.8681e-10, 3.7774e-01, 4.5062e-03, 1.3325e-01, 3.4730e-02, 1.6148e-09,\n",
            "        9.1403e-01, 2.0941e-07, 7.1054e-15, 4.9926e-01, 1.6493e-01, 1.3174e-17,\n",
            "        2.1116e-16, 1.1682e-09, 3.2592e-22, 6.2460e-10, 1.6815e-01, 1.6545e-01,\n",
            "        1.1711e-13, 0.0000e+00, 1.6467e-01, 1.6692e-01, 0.0000e+00, 5.1007e-08,\n",
            "        7.1054e-15, 1.5465e-01, 2.7942e-22, 0.0000e+00, 1.6764e-01, 6.3150e-25,\n",
            "        1.6819e-01, 9.0885e-03, 1.6836e-01, 8.2654e-11, 1.5635e-01, 0.0000e+00,\n",
            "        0.0000e+00, 2.1135e-02, 2.1135e-02, 1.0000e+00, 0.0000e+00, 8.3367e-25,\n",
            "        5.3014e-05, 1.5695e-01, 4.0343e-08, 1.5526e-23, 1.5931e-17, 5.7661e-14,\n",
            "        2.9580e-11, 1.6838e-01, 1.6738e-01, 1.4815e-18, 2.3241e-16, 4.7036e-08,\n",
            "        1.6663e-01, 1.3826e-01])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code accesses the output masks for the train, validation, and test sets, and then prints the masks.As you can see, there is no empty cell and values of 1 are given."
      ],
      "metadata": {
        "id": "Rwj0dwGQnWZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the output masks\n",
        "train_masks = train_set.masks\n",
        "val_masks = val_set.masks\n",
        "test_masks = test_set.masks\n",
        "\n",
        "# Print the output masks\n",
        "print(\"Train Set Output Masks:\")\n",
        "print(train_masks)\n",
        "print()\n",
        "\n",
        "print(\"Validation Set Output Masks:\")\n",
        "print(val_masks)\n",
        "print()\n",
        "\n",
        "print(\"Test Set Output Masks:\")\n",
        "print(test_masks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g06zRFdUx1KT",
        "outputId": "4cb0b38b-2927-40c6-9321-b19e1a5f49e6"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set Output Masks:\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        ...,\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "\n",
            "Validation Set Output Masks:\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n",
            "\n",
            "Test Set Output Masks:\n",
            "tensor([[1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code checks if there are any empty cells (cells with NaN values) in the train, validation, and test sets.\n",
        "By iterating over the samples and checking for NaN values in the labels tensor, the code determines if there are any empty cells present in the train, validation, and test sets."
      ],
      "metadata": {
        "id": "ibsB5LFtmrLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there is an empty cell in the train_set\n",
        "empty_cells_train = any(torch.isnan(labels).any() for _, labels, _, _ in train_set)\n",
        "if empty_cells_train:\n",
        "    print(\"Train set contains empty cells.\")\n",
        "else:\n",
        "    print(\"Train set does not contain empty cells.\")\n",
        "\n",
        "# Check if there is an empty cell in the val_set\n",
        "empty_cells_val = any(torch.isnan(labels).any() for _, labels, _, _ in val_set)\n",
        "if empty_cells_val:\n",
        "    print(\"Validation set contains empty cells.\")\n",
        "else:\n",
        "    print(\"Validation set does not contain empty cells.\")\n",
        "\n",
        "# Check if there is an empty cell in the test_set\n",
        "empty_cells_test = any(torch.isnan(labels).any() for _, labels, _, _ in test_set)\n",
        "if empty_cells_test:\n",
        "    print(\"Test set contains empty cells.\")\n",
        "else:\n",
        "    print(\"Test set does not contain empty cells.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7fdE1-XF7l9",
        "outputId": "a744a940-e24c-4690-e4a0-487d5fa74228"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set does not contain empty cells.\n",
            "Validation set does not contain empty cells.\n",
            "Test set does not contain empty cells.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because the data is a task, there is no empty cell"
      ],
      "metadata": {
        "id": "F96AKaUfnDb6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBKR_7i_t3L7"
      },
      "source": [
        "#### Data Loader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the `collate` function is used to process a batch of samples by concatenating the graphs, labels, masks, and globals. The `loader` function creates dataloaders for the training, validation, and test sets using the `DataLoader` class, with the `collate` function specified to process the batches."
      ],
      "metadata": {
        "id": "4hcyWHEGxE66"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "FMfrwxtQt3L7"
      },
      "outputs": [],
      "source": [
        "def collate(batch):\n",
        "    # batch is a list of tuples (graphs, labels, masks, globals)\n",
        "    # Concatenate a sequence of graphs\n",
        "    graphs = [e[0] for e in batch]\n",
        "    g = dgl.batch(graphs)\n",
        "\n",
        "    # Concatenate a sequence of tensors (labels) along a new dimension\n",
        "    labels = [e[1] for e in batch]\n",
        "    labels = torch.stack(labels, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (masks) along a new dimension\n",
        "    masks = [e[2] for e in batch]\n",
        "    masks = torch.stack(masks, 0)\n",
        "\n",
        "    # Concatenate a sequence of tensors (globals) along a new dimension\n",
        "    globals = [e[3] for e in batch]\n",
        "    globals = torch.stack(globals, 0)\n",
        "\n",
        "    return g, labels, masks, globals\n",
        "\n",
        "\n",
        "def loader(batch_size=64):\n",
        "    train_dataloader = DataLoader(train_set,\n",
        "                              batch_size=batch_size,\n",
        "                              collate_fn=collate,\n",
        "                              drop_last=False,\n",
        "                              shuffle=True,\n",
        "                              num_workers=1)\n",
        "\n",
        "    val_dataloader =  DataLoader(val_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "\n",
        "    test_dataloader = DataLoader(test_set,\n",
        "                             batch_size=batch_size,\n",
        "                             collate_fn=collate,\n",
        "                             drop_last=False,\n",
        "                             shuffle=False,\n",
        "                             num_workers=1)\n",
        "    return train_dataloader, val_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "btedvgv3t3L8"
      },
      "outputs": [],
      "source": [
        "train_dataloader, val_dataloader, test_dataloader = loader(batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " this code snippet iterate over the training data batch by batch, where each batch contains a graph g and other associated information (labels, masks, globals) that can be used for training model."
      ],
      "metadata": {
        "id": "sYGRI_rboepR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g,_,_,_=next(iter(train_dataloader))\n",
        "g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXyDLrJU-Lkp",
        "outputId": "d92f467c-1abd-4e02-f4b7-19768ba5b6f9"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Graph(num_nodes=462, num_edges=838,\n",
              "      ndata_schemes={'v': Scheme(shape=(128,), dtype=torch.float32)}\n",
              "      edata_schemes={'e': Scheme(shape=(13,), dtype=torch.float32)})"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4gHP6jet3L8"
      },
      "source": [
        "#### Defining A GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev4cykK0t3L8"
      },
      "source": [
        "##### Some Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " the code  sets up several parameters and configurations for training a model. These include the number of tasks, the size of global features, the number of epochs, the patience for early stopping, and the model configuration dictionary specifying the sizes of different features and hidden layers."
      ],
      "metadata": {
        "id": "kmaZaH2Ayjtf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "v5ierpRkt3L8"
      },
      "outputs": [],
      "source": [
        "#Bace dataset has 1 task. Some other datasets may have some more number of tasks, e.g., tox21 has 12 tasks.\n",
        "num_tasks = 1\n",
        "\n",
        "# Size of global feature of each graph\n",
        "global_size = 200\n",
        "\n",
        "# Number of epochs to train the model\n",
        "num_epochs = 100\n",
        "\n",
        "# Number of steps to wait if the model performance on the validation set does not improve\n",
        "patience = 10\n",
        "\n",
        "#Configurations to instantiate the model\n",
        "config = {\"node_feature_size\":127, \"edge_feature_size\":12, \"hidden_size\":100}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " the `GNN` class represents a Graph Neural Network (GNN) model. It takes a DGL graph and global features as input and performs graph convolutions to obtain graph-level representations. The model architecture and parameters are defined in the `__init__` method, and the forward pass is implemented in the `forward` method."
      ],
      "metadata": {
        "id": "jaz2CTMDzEp4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "sUOiv0crt3L8"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size = 200, num_tasks = 1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size,allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.num_tasks,allow_zero_in_degree=True)\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"]= mol_dgl_graph.ndata[\"v\"][:,:self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:,:self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVCgaSspt3L9"
      },
      "source": [
        "#### Function to Compute Score of the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the `compute_score` function evaluates the model by computing the ROC AUC score for each task in a multi-task setting. It aggregates the scores and returns the average score across all tasks."
      ],
      "metadata": {
        "id": "KKgTOhrizQEF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {
        "id": "d3MV2-YLt3L9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def compute_score(model, data_loader, val_size, num_tasks):\n",
        "    model.eval()\n",
        "    metric = roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        prediction_all= torch.empty(0)\n",
        "        labels_all= torch.empty(0)\n",
        "        masks_all= torch.empty(0)\n",
        "        for i, (mol_dgl_graph, labels, masks, globals) in enumerate(data_loader):\n",
        "            prediction = model(mol_dgl_graph, globals)\n",
        "            prediction = torch.sigmoid(prediction)\n",
        "            prediction_all = torch.cat((prediction_all, prediction), 0)\n",
        "            labels_all = torch.cat((labels_all, labels), 0)\n",
        "            masks_all = torch.cat((masks_all, masks), 0)\n",
        "        average = torch.tensor([0.])\n",
        "        for i in range(num_tasks):\n",
        "            a1 = prediction_all[:, i][masks_all[:,i]==1]\n",
        "            a2 = labels_all[:, i][masks_all[:,i]==1]\n",
        "            try:\n",
        "                t = metric(a2.int().cpu(), a1.cpu()).item()\n",
        "            except ValueError:\n",
        "                t = 0\n",
        "            average += t\n",
        "    return average.item()/num_tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y18Wlm0et3L9"
      },
      "source": [
        "#### Loss Function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " the `loss_func` function calculates the loss for a multi-task binary classification problem using the binary cross-entropy loss (`BCEWithLogitsLoss`) with specified positive weights. It applies a mask to filter out padded or irrelevant elements, and the final loss is averaged over the valid elements."
      ],
      "metadata": {
        "id": "ufnBAhOh9TSg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {
        "id": "uvfJ6Eh1t3L9"
      },
      "outputs": [],
      "source": [
        "# def loss_func(output, label, mask, num_tasks):\n",
        "#     pos_weight = torch.ones((1, num_tasks))\n",
        "#     pos_weight\n",
        "#     criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "#     loss = mask*criterion(output,label)\n",
        "#     loss = loss.sum() / mask.sum()\n",
        "#     return loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_func(output, label, mask, num_tasks):\n",
        "    pos_weight = torch.ones((1, num_tasks))\n",
        "    pos_weight\n",
        "    criterion = torch.nn.BCEWithLogitsLoss(reduction='none', pos_weight=pos_weight)\n",
        "    loss = criterion(output, label)\n",
        "    loss = loss.mean()\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "Y-HuMEWvzAIO"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFfGjb_9t3L9"
      },
      "source": [
        "#### Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx1pNYqdt3L-"
      },
      "source": [
        "##### Training Function"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the `train_epoch` function performs one training epoch for a graph-based model. It iterates over the batches in the training data, computes the model's predictions and the training loss, performs backpropagation to compute the gradients, updates the model's parameters, and accumulates the training loss. The function returns the average training loss per iteration for the epoch."
      ],
      "metadata": {
        "id": "ue3kCM_990IX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {
        "id": "C3j9TEy1t3L-"
      },
      "outputs": [],
      "source": [
        "def train_epoch(train_dataloader, model, optimizer):\n",
        "    epoch_train_loss = 0\n",
        "    iterations = 0\n",
        "    model.train() # Prepare model for training\n",
        "    for i, (mol_dgl_graph, labels, masks, globals) in enumerate(train_dataloader):\n",
        "        prediction = model(mol_dgl_graph, globals)\n",
        "        loss_train = loss_func(prediction, labels, masks, num_tasks)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss_train.detach().item()\n",
        "        iterations += 1\n",
        "    epoch_train_loss /= iterations\n",
        "    return epoch_train_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the train_evaluate function trains and evaluates a graph-based model for a specified number of epochs. It keeps track of the best validation score and saves the corresponding model checkpoint. After training, it copies the checkpoint files of the best model to a separate directory. Finally, it prints the final results, including the average validation score."
      ],
      "metadata": {
        "id": "_bsiVcBT95Ou"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "id": "g3_RC68Gt3L-"
      },
      "outputs": [],
      "source": [
        "def train_evaluate():\n",
        "\n",
        "    model = GNN(config, global_size, num_tasks)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "    best_val = 0\n",
        "    patience_count = 1\n",
        "    epoch = 1\n",
        "\n",
        "    while epoch <= num_epochs:\n",
        "        if patience_count <= patience:\n",
        "            model.train()\n",
        "            loss_train = train_epoch(train_dataloader, model, optimizer)\n",
        "            model.eval()\n",
        "            score_val = compute_score(model, val_dataloader, len(val_set), num_tasks)\n",
        "            if score_val > best_val:\n",
        "                best_val = score_val\n",
        "                print(\"Save checkpoint\")\n",
        "                path = os.path.join(checkpoint_path, 'checkpoint.pth')\n",
        "                dict_checkpoint = {\"score_val\": score_val}\n",
        "                dict_checkpoint.update({\"model_state_dict\": model.state_dict(), \"optimizer_state\": optimizer.state_dict()})\n",
        "                with open(path, \"wb\") as outputfile:\n",
        "                    cloudpickle.dump(dict_checkpoint, outputfile)\n",
        "                patience_count = 1\n",
        "            else:\n",
        "                print(\"Patience\", patience_count)\n",
        "                patience_count += 1\n",
        "\n",
        "            print(\"Epoch: {}/{} | Training Loss: {:.3f} | Valid Score: {:.3f}\".format(\n",
        "            epoch, num_epochs, loss_train, score_val))\n",
        "\n",
        "            print(\" \")\n",
        "            print(\"Epoch: {}/{} | Best Valid Score Until Now: {:.3f}\".format(epoch, num_epochs, best_val), \"\\n\")\n",
        "        epoch += 1\n",
        "\n",
        "    # best model save\n",
        "    shutil.rmtree(best_model_path, ignore_errors=True)\n",
        "    shutil.copytree(checkpoint_path, best_model_path)\n",
        "\n",
        "    print(\"Final results:\")\n",
        "    print(\"Average Valid Score: {:.3f}\".format(np.mean(best_val)), \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQYY1p2qt3L-"
      },
      "source": [
        "##### Function to compute test set score of the final saved model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " the `test_evaluate` function loads the best model checkpoint, initializes a model with the same configuration, loads the model's state from the checkpoint, evaluates the model on the test dataset, and prints the test score and execution time."
      ],
      "metadata": {
        "id": "nQG4adnM_DyS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "KOF0FfElt3L-"
      },
      "outputs": [],
      "source": [
        "def test_evaluate():\n",
        "    final_model = GNN(config, global_size, num_tasks)\n",
        "    path = os.path.join(best_model_path, 'checkpoint.pth')\n",
        "    with open(path, 'rb') as f:\n",
        "        checkpoint = cloudpickle.load(f)\n",
        "    final_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    final_model.eval()\n",
        "    test_score = compute_score(final_model, test_dataloader, len(test_set), num_tasks)\n",
        "\n",
        "    print(\"Test Score: {:.3f}\".format(test_score), \"\\n\")\n",
        "    print(\"Execution time: {:.3f} seconds\".format(time.time() - start_time))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrhbK140t3L-"
      },
      "source": [
        "##### Train the model and evaluate its performance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By calling `train_evaluate()` and `test_evaluate()` one after the other, the code performs both training and testing of the graph-based model. The `start_time` variable is used to calculate and print the total execution time for both operations."
      ],
      "metadata": {
        "id": "MjDgu-Hm_YrX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIw5IQLyt3L-",
        "outputId": "220b1dcb-46c7-4b43-fcb2-1648faa993b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.669 | Valid Score: 0.240\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.240 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.643 | Valid Score: 0.241\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.241 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.625 | Valid Score: 0.244\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.244 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.612 | Valid Score: 0.253\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.253 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.603 | Valid Score: 0.263\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.263 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.598 | Valid Score: 0.274\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.274 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.595 | Valid Score: 0.285\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.285 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.590 | Valid Score: 0.298\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.298 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.587 | Valid Score: 0.312\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.312 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.580 | Valid Score: 0.334\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.334 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.578 | Valid Score: 0.354\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.354 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.574 | Valid Score: 0.386\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.386 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.569 | Valid Score: 0.424\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.424 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.565 | Valid Score: 0.453\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.453 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.562 | Valid Score: 0.494\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.494 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.558 | Valid Score: 0.533\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.533 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.554 | Valid Score: 0.568\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.568 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.551 | Valid Score: 0.588\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.588 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.547 | Valid Score: 0.608\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.608 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.543 | Valid Score: 0.630\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.630 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.541 | Valid Score: 0.654\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.654 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.536 | Valid Score: 0.680\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.680 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.532 | Valid Score: 0.694\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.694 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.530 | Valid Score: 0.709\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.709 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 0.525 | Valid Score: 0.727\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.727 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 0.525 | Valid Score: 0.735\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.735 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.524 | Valid Score: 0.746\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.746 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 0.515 | Valid Score: 0.751\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.751 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 0.514 | Valid Score: 0.755\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.755 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 0.512 | Valid Score: 0.759\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.759 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 0.510 | Valid Score: 0.766\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.766 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 0.506 | Valid Score: 0.775\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.775 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.503 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.779 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 0.499 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.779 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.498 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 0.495 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 0.490 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 0.491 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.488 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 0.485 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 0.485 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 42/100 | Training Loss: 0.485 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 0.479 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 0.477 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 45/100 | Training Loss: 0.481 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 0.475 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 0.474 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 0.470 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 49/100 | Training Loss: 0.468 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 50/100 | Training Loss: 0.471 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 0.465 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 0.464 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 0.464 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 54/100 | Training Loss: 0.460 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 0.460 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 0.458 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 57/100 | Training Loss: 0.460 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 0.455 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 59/100 | Training Loss: 0.455 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 0.453 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 61/100 | Training Loss: 0.452 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 62/100 | Training Loss: 0.451 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 63/100 | Training Loss: 0.454 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 0.452 | Valid Score: 0.816\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.816 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 0.449 | Valid Score: 0.816\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.816 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 66/100 | Training Loss: 0.448 | Valid Score: 0.816\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.816 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 0.450 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 0.446 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 0.446 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 0.447 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 0.447 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 0.444 | Valid Score: 0.819\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.819 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 0.439 | Valid Score: 0.819\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.819 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 74/100 | Training Loss: 0.443 | Valid Score: 0.819\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.819 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 0.445 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 76/100 | Training Loss: 0.440 | Valid Score: 0.820\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.820 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 77/100 | Training Loss: 0.440 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.821 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 78/100 | Training Loss: 0.437 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.821 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 79/100 | Training Loss: 0.440 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.821 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 80/100 | Training Loss: 0.441 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 81/100 | Training Loss: 0.437 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 82/100 | Training Loss: 0.439 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 83/100 | Training Loss: 0.436 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 0.823 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 84/100 | Training Loss: 0.437 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 0.823 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 85/100 | Training Loss: 0.433 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 0.823 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 86/100 | Training Loss: 0.436 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 0.823 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 87/100 | Training Loss: 0.437 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 0.823 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 0.432 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 0.823 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 89/100 | Training Loss: 0.431 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 0.823 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 90/100 | Training Loss: 0.433 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 0.823 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 91/100 | Training Loss: 0.433 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 0.823 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 0.432 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 93/100 | Training Loss: 0.434 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 94/100 | Training Loss: 0.430 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 95/100 | Training Loss: 0.431 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 96/100 | Training Loss: 0.431 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 97/100 | Training Loss: 0.427 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 98/100 | Training Loss: 0.428 | Valid Score: 0.823\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 99/100 | Training Loss: 0.429 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 100/100 | Training Loss: 0.428 | Valid Score: 0.824\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 0.824 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.824 \n",
            "\n",
            "Test Score: 0.636 \n",
            "\n",
            "Execution time: 89.537 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DGLDatasetClass(torch.utils.data.Dataset):\n",
        "    def __init__(self, address):\n",
        "        self.address = address + \".bin\"\n",
        "        self.list_graphs, train_labels_masks_globals, edge_features = dgl.load_graphs(self.address)\n",
        "        num_graphs = len(self.list_graphs)\n",
        "        self.labels = train_labels_masks_globals[\"labels\"].view(num_graphs, -1)\n",
        "        self.masks = train_labels_masks_globals[\"masks\"].view(num_graphs, -1)\n",
        "        self.globals = train_labels_masks_globals[\"globals\"].view(num_graphs, -1)\n",
        "        self.edge_features = edge_features.view(num_graphs, -1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_graphs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.list_graphs[idx], self.labels[idx], self.masks[idx], self.globals[idx], self.edge_features[idx]\n"
      ],
      "metadata": {
        "id": "oLQ8oEbtbE98"
      },
      "execution_count": 257,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this code demonstrates the construction of a GNN model using DGL for graph processing and message passing. The model takes a DGL graph (mol_dgl_graph) and global features (globals) as inputs and returns the aggregated node features."
      ],
      "metadata": {
        "id": "xnDg8DM5p3jU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "from dgl.nn import GraphConv\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        # Graph convolution layers\n",
        "        self.conv1 = GraphConv(self.node_feature_size, self.hidden_size, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(self.hidden_size, self.num_tasks, allow_zero_in_degree=True)\n",
        "\n",
        "        # Global feature size\n",
        "        self.global_feature_size = global_size\n",
        "\n",
        "        # Global feature linear transformation\n",
        "        self.global_transform = nn.Linear(self.global_feature_size, self.hidden_size)\n",
        "\n",
        "        # Message function\n",
        "        self.message_func = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "\n",
        "        # Reduce function\n",
        "        self.reduce_func = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        # Preprocess node and edge features\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "\n",
        "        # Initialize node features with initial node features\n",
        "        mol_dgl_graph.ndata[\"h\"] = mol_dgl_graph.ndata[\"v\"]\n",
        "\n",
        "        # Apply graph convolution to node features\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"h\"])\n",
        "\n",
        "        # Message passing\n",
        "        mol_dgl_graph.update_all(\n",
        "            message_func=(lambda edges: self.message_func(edges.src['h'])),\n",
        "            reduce_func=(lambda nodes: torch.cat([nodes.mailbox['m'], nodes.data['h']], dim=-1))\n",
        "        )\n",
        "\n",
        "        # Get the updated node features after message passing\n",
        "        h = mol_dgl_graph.ndata[\"h\"]\n",
        "\n",
        "        # Global feature transformation\n",
        "        global_feat = self.global_transform(globals)\n",
        "        global_feat = global_feat.unsqueeze(1).expand(-1, h.shape[1], -1)\n",
        "\n",
        "        # Concatenate global feature with node features\n",
        "        h = torch.cat([h, global_feat], dim=-1)\n",
        "\n",
        "        # Apply ReLU activation\n",
        "        h = F.relu(h)\n",
        "\n",
        "        # Apply the second graph convolutional layer\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "\n",
        "        # Update node features with the final representation\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "\n",
        "        # Aggregate the node features and return the mean\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")"
      ],
      "metadata": {
        "id": "y-B21HnlgSUs"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##sage"
      ],
      "metadata": {
        "id": "ODgIAG9PW6pB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##message copy and reduce mean"
      ],
      "metadata": {
        "id": "WiNwtE7lUOTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a custom SAGEConv (GraphSAGE Convolution) module in PyTorch for graph convolutional operations.\n",
        "The `SAGEConv` class extends the `nn.Module` class and initializes a SAGEConv layer. It takes the input feature size (`in_feat`), output feature size (`out_feat`), and aggregator type as arguments. The aggregator type determines how neighbor information is aggregated, with `'mean'` being the default.\n",
        "\n",
        "The `forward` method performs the graph convolution operation. It takes a DGL graph (`g`) and a tensor of node features (`h`) as inputs. The method begins by setting the node features in the graph with `g.ndata[\"h\"] = h`. Then, it performs message passing using `update_all`. The `message_func` copies the node features to messages, while the `reduce_func` applies the specified aggregator type to aggregate the messages from neighboring nodes.\n",
        "After message passing, the method retrieves the aggregated node features (`h_N`) from the graph. It concatenates the original node features (`h`) with the aggregated features (`h_N`). Finally, the concatenated features are passed through a linear transformation (`self.linear`) to obtain the output features."
      ],
      "metadata": {
        "id": "qwrr7Q1kqv4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "from dgl.nn import GraphConv\n",
        "import dgl.function as fn\n",
        "from dgl.nn import SAGEConv\n",
        "\n",
        "\n",
        "class SAGEConv(nn.Module):\n",
        "\n",
        "    def __init__(self, in_feat, out_feat, aggregator_type='mean'):\n",
        "        super(SAGEConv, self).__init__()\n",
        "        self.aggregator_type = aggregator_type\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.update_all(\n",
        "                message_func=fn.copy_u(\"h\", \"m\"),\n",
        "                reduce_func=getattr(fn, self.aggregator_type)(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "32aG_4T3V4U_"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this code defines a GNN model that performs graph convolution operations using the SAGEConv module. It applies two SAGEConv layers to obtain node representations and aggregates them to compute the final output of the model."
      ],
      "metadata": {
        "id": "ur5Jt1bLrd8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ],
      "metadata": {
        "id": "9yJGr39mV5C_"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aDTuPrbV-it",
        "outputId": "218e8807-0036-4402-d6fe-339b61d0104a"
      },
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.671 | Valid Score: 0.349\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.349 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 0.644 | Valid Score: 0.323\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.349 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 3/100 | Training Loss: 0.621 | Valid Score: 0.322\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.349 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 4/100 | Training Loss: 0.606 | Valid Score: 0.325\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.349 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 5/100 | Training Loss: 0.596 | Valid Score: 0.338\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.349 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.592 | Valid Score: 0.359\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.359 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.585 | Valid Score: 0.382\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.382 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.581 | Valid Score: 0.411\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.411 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.574 | Valid Score: 0.471\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.471 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.567 | Valid Score: 0.526\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.526 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.563 | Valid Score: 0.584\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.584 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.558 | Valid Score: 0.626\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.626 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.549 | Valid Score: 0.676\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.676 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.540 | Valid Score: 0.712\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.712 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.535 | Valid Score: 0.741\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.741 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.528 | Valid Score: 0.778\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.521 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.520 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.513 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.507 | Valid Score: 0.817\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.817 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.502 | Valid Score: 0.825\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.825 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.496 | Valid Score: 0.831\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.831 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.490 | Valid Score: 0.834\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.834 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.486 | Valid Score: 0.836\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.836 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 0.482 | Valid Score: 0.838\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.838 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 0.483 | Valid Score: 0.838\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.838 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.476 | Valid Score: 0.841\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.841 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 0.470 | Valid Score: 0.840\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.841 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 0.472 | Valid Score: 0.841\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.841 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 0.467 | Valid Score: 0.842\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.842 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 0.465 | Valid Score: 0.842\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.842 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 32/100 | Training Loss: 0.462 | Valid Score: 0.841\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.842 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.458 | Valid Score: 0.843\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 0.457 | Valid Score: 0.842\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 35/100 | Training Loss: 0.454 | Valid Score: 0.842\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 36/100 | Training Loss: 0.453 | Valid Score: 0.841\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 37/100 | Training Loss: 0.449 | Valid Score: 0.841\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 38/100 | Training Loss: 0.448 | Valid Score: 0.841\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 39/100 | Training Loss: 0.447 | Valid Score: 0.840\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 40/100 | Training Loss: 0.445 | Valid Score: 0.841\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 41/100 | Training Loss: 0.440 | Valid Score: 0.840\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 42/100 | Training Loss: 0.437 | Valid Score: 0.841\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 43/100 | Training Loss: 0.441 | Valid Score: 0.840\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.843 \n",
            "\n",
            "Test Score: 0.565 \n",
            "\n",
            "Execution time: 39.441 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##message add and reduce sum"
      ],
      "metadata": {
        "id": "DXB1bHGOT-pQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `SAGEConv1` class extends the `nn.Module` class and defines a SAGEConv convolutional layer. `SAGEConv1` applies a linear transformation to the concatenation of the node features and the sum of their neighbors' features.\n",
        "\n",
        "The `forward` method of `SAGEConv1` takes a DGL graph `g` and a tensor of node features `h` as inputs. It first sets the node features in the graph `g`, then performs message passing using the `u_add_v` and `sum` built-in DGL functions to compute the sum of the neighbor features for each node. Finally, it concatenates the original node features with the sum of neighbor features, applies a linear transformation, and returns the result."
      ],
      "metadata": {
        "id": "IGAGtosVvh-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGEConv1(nn.Module):\n",
        "\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv1, self).__init__()\n",
        "\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "        #The forward method of SAGEConv1 takes a DGL graph g and a tensor of node features h as inputs.\n",
        "        # It first sets the node features in the graph g, then performs message passing using the u_add_v and sum built-in DGL functions to compute the sum of the neighbor features for each node.\n",
        "        # Finally, it concatenates the original node features with the sum of neighbor features, applies a linear transformation, and returns the result.\n",
        "\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.update_all(\n",
        "                message_func=fn.u_add_v(\"h\",\"h\", \"m\"),\n",
        "                reduce_func=fn.sum(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "iL8RAIR92LKh"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The `GNN` class extends the `nn.Module` class and initializes a GNN model. It takes a configuration dictionary (`config`), global size, and number of tasks as arguments. The model has two SAGEConv1 layers (`self.conv1` and `self.conv2`) for performing graph convolution operations.\n",
        "The `forward` method performs the forward pass of the GNN model. It takes a DGL graph (`mol_dgl_graph`) and global features (`globals`) as inputs. The method first restricts the node features and edge features to their respective sizes by slicing the tensors.\n",
        "\n",
        "Then, it applies the first SAGEConv1 layer (`self.conv1`) to the node features, followed by a ReLU activation function (`F.relu`). Next, it applies the second SAGEConv1 layer (`self.conv2`) to obtain the final node representations.\n",
        "\n",
        "The final node representations are stored in the graph with `mol_dgl_graph.ndata[\"h\"] = h`. Finally, the method computes the mean of the node representations using `dgl.mean_nodes` with the feature name \"h\" and returns the result.\n",
        "\n"
      ],
      "metadata": {
        "id": "bfxLnaV8wDuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv1(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv1(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ],
      "metadata": {
        "id": "g8Kg-NE_45xs"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d167cb-f04a-4c13-8972-07467d5fbbff",
        "id": "DXh9NBfo3WQj"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.670 | Valid Score: 0.307\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.307 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.621 | Valid Score: 0.344\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.344 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.600 | Valid Score: 0.431\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.431 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.583 | Valid Score: 0.518\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.518 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.567 | Valid Score: 0.590\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.590 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.548 | Valid Score: 0.669\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.669 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.533 | Valid Score: 0.712\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.712 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.518 | Valid Score: 0.739\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.739 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.508 | Valid Score: 0.771\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.771 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.494 | Valid Score: 0.771\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.771 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.484 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.478 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.470 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.462 | Valid Score: 0.816\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.816 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.459 | Valid Score: 0.827\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 16/100 | Training Loss: 0.452 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.449 | Valid Score: 0.833\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.833 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.441 | Valid Score: 0.834\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.834 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.441 | Valid Score: 0.836\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.836 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.436 | Valid Score: 0.843\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 21/100 | Training Loss: 0.431 | Valid Score: 0.840\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 22/100 | Training Loss: 0.429 | Valid Score: 0.841\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 23/100 | Training Loss: 0.425 | Valid Score: 0.839\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.426 | Valid Score: 0.843\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 25/100 | Training Loss: 0.423 | Valid Score: 0.842\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.843 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 0.422 | Valid Score: 0.844\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.844 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.419 | Valid Score: 0.844\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.844 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 0.416 | Valid Score: 0.844\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.844 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 29/100 | Training Loss: 0.414 | Valid Score: 0.844\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.844 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 30/100 | Training Loss: 0.412 | Valid Score: 0.844\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.844 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 0.412 | Valid Score: 0.847\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.847 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 0.409 | Valid Score: 0.848\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.848 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 33/100 | Training Loss: 0.408 | Valid Score: 0.847\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.848 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 34/100 | Training Loss: 0.409 | Valid Score: 0.846\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.848 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 35/100 | Training Loss: 0.405 | Valid Score: 0.846\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.848 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 36/100 | Training Loss: 0.401 | Valid Score: 0.843\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.848 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 37/100 | Training Loss: 0.403 | Valid Score: 0.844\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.848 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 38/100 | Training Loss: 0.401 | Valid Score: 0.844\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.848 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 39/100 | Training Loss: 0.403 | Valid Score: 0.845\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.848 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 40/100 | Training Loss: 0.404 | Valid Score: 0.838\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.848 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 41/100 | Training Loss: 0.399 | Valid Score: 0.838\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.848 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 42/100 | Training Loss: 0.401 | Valid Score: 0.838\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.848 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.848 \n",
            "\n",
            "Test Score: 0.634 \n",
            "\n",
            "Execution time: 38.615 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##message add and reduce sum"
      ],
      "metadata": {
        "id": "0JwFrrVlT4Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGEConv2(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv2, self).__init__()\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.send_and_recv(g.edges(), fn.u_add_v(\"h\", \"h\", \"m\"), fn.sum(\"m\", \"h_N\"))\n",
        "\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv2(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv2(self.hidden_size, self.num_tasks)\n",
        "#The forward method of SAGEConv2 takes a DGL graph g and a tensor of node features h as inputs.\n",
        "# It first sets the node features in the graph g, then performs message passing and aggregation using the send_and_recv function.\n",
        "#It sends messages by applying the \"add\" message function fn.u_add_v(\"h\", \"h\", \"m\") to each edge of the graph.\n",
        "#The messages are then received and aggregated using the \"sum\" reduce function fn.sum(\"m\", \"h_N\") to compute the sum of the neighbor features for each node.\n",
        "#After the message passing and aggregation step, it retrieves the aggregated neighbor features h_N from the graph data. It concatenates the original node features h with the aggregated neighbor features h_N, applies a linear transformation, and returns the result.\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n",
        "\n",
        "#\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltGW23vl8lC0",
        "outputId": "8f1746e6-cd28-41a9-92c2-a09addbd424d"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.632 | Valid Score: 0.350\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.350 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.609 | Valid Score: 0.443\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.443 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.589 | Valid Score: 0.547\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.547 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.572 | Valid Score: 0.609\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.609 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.554 | Valid Score: 0.712\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.712 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.536 | Valid Score: 0.732\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.732 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.521 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.788 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.509 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.500 | Valid Score: 0.827\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 10/100 | Training Loss: 0.485 | Valid Score: 0.819\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 11/100 | Training Loss: 0.478 | Valid Score: 0.825\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.827 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.468 | Valid Score: 0.842\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.842 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.461 | Valid Score: 0.845\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.845 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.455 | Valid Score: 0.845\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.845 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.450 | Valid Score: 0.860\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.860 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 16/100 | Training Loss: 0.441 | Valid Score: 0.847\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.860 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.442 | Valid Score: 0.864\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.864 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 18/100 | Training Loss: 0.440 | Valid Score: 0.857\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.864 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 19/100 | Training Loss: 0.439 | Valid Score: 0.860\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.864 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 20/100 | Training Loss: 0.432 | Valid Score: 0.847\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.864 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 21/100 | Training Loss: 0.425 | Valid Score: 0.862\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.864 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 22/100 | Training Loss: 0.425 | Valid Score: 0.861\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.864 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 23/100 | Training Loss: 0.423 | Valid Score: 0.860\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.864 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 24/100 | Training Loss: 0.422 | Valid Score: 0.858\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.864 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 25/100 | Training Loss: 0.416 | Valid Score: 0.858\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.864 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 26/100 | Training Loss: 0.415 | Valid Score: 0.861\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.864 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 27/100 | Training Loss: 0.410 | Valid Score: 0.856\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.864 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.864 \n",
            "\n",
            "Test Score: 0.565 \n",
            "\n",
            "Execution time: 28.719 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##message div and reduce max"
      ],
      "metadata": {
        "id": "DWQP58h8TvNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this code defines a SAGEConv3 module for graph convolutional operations, which uses \"div\" as the message function to compute element-wise division of node features and \"mean\" as the reduce function to compute the mean of the aggregated messages from neighboring nodes."
      ],
      "metadata": {
        "id": "0eSIdvXmytKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGEConv3(nn.Module):\n",
        "\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv3, self).__init__()\n",
        "\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.update_all(\n",
        "                message_func=fn.u_div_v(\"h\",\"h\", \"m\"),\n",
        "                reduce_func=fn.mean(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "v5epjL8q_Oam"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv3(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv3(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ],
      "metadata": {
        "id": "HsdRE5GG_yTF"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG3qp84n_5eZ",
        "outputId": "9cd02cd6-1f8c-4794-c498-6a38917c41ce"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patience 1\n",
            "Epoch: 1/100 | Training Loss: nan | Valid Score: 0.000\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.000 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 2/100 | Training Loss: nan | Valid Score: 0.000\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.000 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 3/100 | Training Loss: nan | Valid Score: 0.000\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.000 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 4/100 | Training Loss: nan | Valid Score: 0.000\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.000 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 5/100 | Training Loss: nan | Valid Score: 0.000\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.000 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 6/100 | Training Loss: nan | Valid Score: 0.000\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.000 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 7/100 | Training Loss: nan | Valid Score: 0.000\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.000 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 8/100 | Training Loss: nan | Valid Score: 0.000\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.000 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 9/100 | Training Loss: nan | Valid Score: 0.000\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.000 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 10/100 | Training Loss: nan | Valid Score: 0.000\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.000 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.000 \n",
            "\n",
            "Test Score: 0.000 \n",
            "\n",
            "Execution time: 9.678 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##message sub and reduce mean"
      ],
      "metadata": {
        "id": "YusFQloiTpVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "this code defines a SAGEConv4 module for graph convolutional operations, which uses \"sub\" as the message function to compute element-wise subtraction of node features and \"mean\" as the reduce function to compute the mean of the aggregated messages from neighboring nodes."
      ],
      "metadata": {
        "id": "Q-IguBttzPua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGEConv4(nn.Module):\n",
        "\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv4, self).__init__()\n",
        "\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "#The forward method of SAGEConv4 takes a DGL graph g and a tensor of node features h as inputs. It first sets the node features in the graph g, then performs message passing and aggregation using the update_all function. It sends messages by applying the \"sub\" message function fn.u_sub_v(\"h\", \"h\", \"m\") to each edge of the graph. The messages are then received and aggregated using the \"mean\" reduce function fn.mean(\"m\", \"h_N\") to compute the mean of the neighbor features for each node.\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.update_all(\n",
        "                message_func = fn.u_sub_v('h', 'h', 'm'),\n",
        "                reduce_func=fn.mean(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "-Jo0384KAXb5"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv4(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv4(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ],
      "metadata": {
        "id": "gSjZ2sneAfkO"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyZQDT73AU7t",
        "outputId": "8613507c-32d7-41cd-a3f9-13effd738631"
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.679 | Valid Score: 0.504\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.504 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 0.660 | Valid Score: 0.388\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.504 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 3/100 | Training Loss: 0.644 | Valid Score: 0.346\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.504 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 4/100 | Training Loss: 0.630 | Valid Score: 0.339\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.504 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 5/100 | Training Loss: 0.620 | Valid Score: 0.336\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.504 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 6/100 | Training Loss: 0.608 | Valid Score: 0.348\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.504 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 7/100 | Training Loss: 0.600 | Valid Score: 0.354\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.504 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 8/100 | Training Loss: 0.590 | Valid Score: 0.367\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.504 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 9/100 | Training Loss: 0.583 | Valid Score: 0.381\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.504 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 10/100 | Training Loss: 0.574 | Valid Score: 0.396\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.504 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 11/100 | Training Loss: 0.566 | Valid Score: 0.414\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.504 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.504 \n",
            "\n",
            "Test Score: 0.404 \n",
            "\n",
            "Execution time: 10.609 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##message mul and reduce mean"
      ],
      "metadata": {
        "id": "aay6ZuCgTUz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " this code defines a SAGEConv5 module for graph convolutional operations, which uses \"mul\" as the message function to compute element-wise multiplication of node features and \"mean\" as the reduce function to compute the mean of the aggregated messages from neighboring nodes."
      ],
      "metadata": {
        "id": "ftZ7WVvk0EFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGEConv5(nn.Module):\n",
        "\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv5, self).__init__()\n",
        "\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "#It performs message forwarding and aggregation using the ``update_all'' function. Sends messages by applying the \"mul\" message function \"fn.u_mul_v(\"h\", \"h\", \"m\")\" to each edge of the graph. The messages are then received and summed using the mean reduction function \"fn.mean(\"m\", \"h_N\")\" to calculate the average of the element-wise multiplied messages from the neighboring nodes.\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.update_all(\n",
        "                message_func = fn.u_mul_v('h', 'h', 'm'),\n",
        "                reduce_func=fn.mean(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "ONCYCFsYA9nM"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv5(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv5(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ],
      "metadata": {
        "id": "48kpNH6-A_iY"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9805b37e-54ad-40d2-c92a-e61cc00f05f6",
        "id": "7s5Jps5JBCmQ"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.654 | Valid Score: 0.276\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.276 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.636 | Valid Score: 0.283\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.283 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.623 | Valid Score: 0.289\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.289 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.614 | Valid Score: 0.295\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.295 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.603 | Valid Score: 0.303\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.303 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.595 | Valid Score: 0.311\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.311 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.587 | Valid Score: 0.322\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.322 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.583 | Valid Score: 0.336\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.336 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.575 | Valid Score: 0.354\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.354 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.564 | Valid Score: 0.381\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.381 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.561 | Valid Score: 0.409\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.409 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.554 | Valid Score: 0.460\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.460 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.549 | Valid Score: 0.501\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.501 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.544 | Valid Score: 0.535\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.535 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.538 | Valid Score: 0.564\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.564 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.531 | Valid Score: 0.610\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.610 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.528 | Valid Score: 0.627\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.627 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.521 | Valid Score: 0.668\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.668 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.517 | Valid Score: 0.685\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.685 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.515 | Valid Score: 0.706\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.706 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.506 | Valid Score: 0.718\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.718 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.504 | Valid Score: 0.744\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.744 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.498 | Valid Score: 0.748\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.748 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.491 | Valid Score: 0.760\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 25/100 | Training Loss: 0.489 | Valid Score: 0.758\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.760 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 0.482 | Valid Score: 0.764\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.764 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.480 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 0.478 | Valid Score: 0.771\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 0.470 | Valid Score: 0.778\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 30/100 | Training Loss: 0.467 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.778 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 31/100 | Training Loss: 0.467 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.782 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 32/100 | Training Loss: 0.463 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.782 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.455 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 0.453 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.783 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.453 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 0.448 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 0.445 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 38/100 | Training Loss: 0.446 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 39/100 | Training Loss: 0.438 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 40/100 | Training Loss: 0.439 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 0.435 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 42/100 | Training Loss: 0.434 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 43/100 | Training Loss: 0.430 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 0.430 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 45/100 | Training Loss: 0.433 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 0.427 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 47/100 | Training Loss: 0.429 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 0.425 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 0.424 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 0.427 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.801 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 51/100 | Training Loss: 0.424 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 52/100 | Training Loss: 0.422 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 0.422 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 54/100 | Training Loss: 0.417 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 55/100 | Training Loss: 0.419 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 0.419 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 0.417 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 58/100 | Training Loss: 0.417 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 59/100 | Training Loss: 0.418 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 0.413 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 61/100 | Training Loss: 0.414 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 0.413 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 63/100 | Training Loss: 0.418 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 0.411 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 0.412 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 66/100 | Training Loss: 0.414 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 67/100 | Training Loss: 0.413 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 0.412 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 0.411 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 70/100 | Training Loss: 0.414 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 71/100 | Training Loss: 0.410 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 72/100 | Training Loss: 0.408 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 73/100 | Training Loss: 0.408 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.809 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 74/100 | Training Loss: 0.409 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 75/100 | Training Loss: 0.410 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 76/100 | Training Loss: 0.412 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 77/100 | Training Loss: 0.409 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 78/100 | Training Loss: 0.415 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 0.408 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 80/100 | Training Loss: 0.410 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 0.408 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 82/100 | Training Loss: 0.413 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 83/100 | Training Loss: 0.407 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 84/100 | Training Loss: 0.407 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 85/100 | Training Loss: 0.408 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 86/100 | Training Loss: 0.405 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 87/100 | Training Loss: 0.405 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 88/100 | Training Loss: 0.408 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 89/100 | Training Loss: 0.404 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 90/100 | Training Loss: 0.406 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 91/100 | Training Loss: 0.403 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 92/100 | Training Loss: 0.406 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 93/100 | Training Loss: 0.406 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 94/100 | Training Loss: 0.403 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 95/100 | Training Loss: 0.402 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 96/100 | Training Loss: 0.406 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 97/100 | Training Loss: 0.402 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 98/100 | Training Loss: 0.401 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 99/100 | Training Loss: 0.402 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 100/100 | Training Loss: 0.402 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.814 \n",
            "\n",
            "Test Score: 0.614 \n",
            "\n",
            "Execution time: 94.291 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##message mul and reduce sum"
      ],
      "metadata": {
        "id": "_04e7u7jTOhw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " this code defines a SAGEConv6 module for graph convolutional operations, which uses \"mul\" as the message function to compute element-wise multiplication of node features and \"sum\" as the reduce function to compute the sum of the aggregated messages from neighboring nodes."
      ],
      "metadata": {
        "id": "pfKb_5v80tWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGEConv6(nn.Module):\n",
        "\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv6, self).__init__()\n",
        "\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.update_all(\n",
        "                message_func = fn.u_mul_v('h', 'h', 'm'),\n",
        "                reduce_func=fn.sum(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "aoMzQIfSHLSJ"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv6(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv6(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ],
      "metadata": {
        "id": "sUUVsfwaHPQv"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea92066-2793-4837-8e70-15c444787b02",
        "id": "pI5LqH4UHRTW"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.719 | Valid Score: 0.639\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.639 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 0.686 | Valid Score: 0.457\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.639 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 3/100 | Training Loss: 0.661 | Valid Score: 0.402\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.639 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 4/100 | Training Loss: 0.641 | Valid Score: 0.399\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.639 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 5/100 | Training Loss: 0.618 | Valid Score: 0.487\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.639 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 6/100 | Training Loss: 0.597 | Valid Score: 0.513\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.639 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 7/100 | Training Loss: 0.578 | Valid Score: 0.529\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.639 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 8/100 | Training Loss: 0.560 | Valid Score: 0.569\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.639 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 9/100 | Training Loss: 0.544 | Valid Score: 0.591\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.639 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 10/100 | Training Loss: 0.533 | Valid Score: 0.622\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.639 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 11/100 | Training Loss: 0.520 | Valid Score: 0.635\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.639 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.639 \n",
            "\n",
            "Test Score: 0.472 \n",
            "\n",
            "Execution time: 10.532 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##message mul and reduce min"
      ],
      "metadata": {
        "id": "ccIU46FJTJ1k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ", the code defines a new `SAGEConv7` module for graph convolutional operations. This module uses \"mul\" as the message function to perform element-wise multiplication between node features, and \"min\" as the reduce function to compute the minimum of the aggregated messages from neighboring nodes.\n"
      ],
      "metadata": {
        "id": "fPomSI1J1S-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dgl.use_libxsmm(False)  # Disable libxsmm\n",
        "\n",
        "class SAGEConv7(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv7, self).__init__()\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.update_all(\n",
        "                message_func=fn.u_mul_v('h', 'h', 'm'),\n",
        "                reduce_func=fn.min(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv7(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv7(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLMs0WYGIQmu",
        "outputId": "68a01294-9a28-42e6-a813-204dec8b88e9"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.673 | Valid Score: 0.311\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.311 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 0.656 | Valid Score: 0.310\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.311 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 3/100 | Training Loss: 0.640 | Valid Score: 0.310\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.311 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 4/100 | Training Loss: 0.628 | Valid Score: 0.310\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.311 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.612 | Valid Score: 0.317\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.317 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.603 | Valid Score: 0.324\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.324 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.591 | Valid Score: 0.331\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.331 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.584 | Valid Score: 0.342\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.342 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.578 | Valid Score: 0.358\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.358 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.571 | Valid Score: 0.380\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.380 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.565 | Valid Score: 0.411\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.411 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.559 | Valid Score: 0.438\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.438 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.555 | Valid Score: 0.475\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.475 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.551 | Valid Score: 0.516\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.516 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.546 | Valid Score: 0.568\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.568 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.540 | Valid Score: 0.589\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.589 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.533 | Valid Score: 0.634\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.634 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.529 | Valid Score: 0.667\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.667 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.524 | Valid Score: 0.686\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.686 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.517 | Valid Score: 0.711\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.711 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.515 | Valid Score: 0.725\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.725 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.510 | Valid Score: 0.744\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.744 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.505 | Valid Score: 0.750\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.750 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.501 | Valid Score: 0.751\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.751 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 0.496 | Valid Score: 0.769\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 26/100 | Training Loss: 0.490 | Valid Score: 0.768\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.769 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.488 | Valid Score: 0.770\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.770 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 28/100 | Training Loss: 0.485 | Valid Score: 0.776\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.776 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 0.479 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.779 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 0.476 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 31/100 | Training Loss: 0.470 | Valid Score: 0.780\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 0.468 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.467 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.788 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 34/100 | Training Loss: 0.464 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.788 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.462 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 0.456 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 0.453 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 0.448 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.450 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 0.446 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 0.445 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.796 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 0.442 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.796 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 0.442 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 0.439 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 45/100 | Training Loss: 0.437 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 46/100 | Training Loss: 0.434 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 47/100 | Training Loss: 0.433 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 0.433 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 0.431 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 50/100 | Training Loss: 0.431 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 51/100 | Training Loss: 0.427 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 52/100 | Training Loss: 0.426 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.802 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 0.428 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 54/100 | Training Loss: 0.426 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 55/100 | Training Loss: 0.424 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 56/100 | Training Loss: 0.423 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 57/100 | Training Loss: 0.422 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 58/100 | Training Loss: 0.423 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 59/100 | Training Loss: 0.420 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.805 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 60/100 | Training Loss: 0.420 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 61/100 | Training Loss: 0.421 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 62/100 | Training Loss: 0.426 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 63/100 | Training Loss: 0.420 | Valid Score: 0.805\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 64/100 | Training Loss: 0.422 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.806 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 0.420 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 66/100 | Training Loss: 0.415 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 67/100 | Training Loss: 0.416 | Valid Score: 0.807\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.807 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 68/100 | Training Loss: 0.416 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.808 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 69/100 | Training Loss: 0.415 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 70/100 | Training Loss: 0.417 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 71/100 | Training Loss: 0.413 | Valid Score: 0.810\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 72/100 | Training Loss: 0.413 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.810 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 0.412 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 74/100 | Training Loss: 0.411 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 75/100 | Training Loss: 0.413 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 76/100 | Training Loss: 0.413 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 77/100 | Training Loss: 0.410 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 78/100 | Training Loss: 0.412 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 79/100 | Training Loss: 0.411 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 80/100 | Training Loss: 0.411 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.811 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 81/100 | Training Loss: 0.407 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 82/100 | Training Loss: 0.408 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 83/100 | Training Loss: 0.409 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 84/100 | Training Loss: 0.411 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 85/100 | Training Loss: 0.406 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 86/100 | Training Loss: 0.407 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 87/100 | Training Loss: 0.406 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 88/100 | Training Loss: 0.407 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 89/100 | Training Loss: 0.408 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 90/100 | Training Loss: 0.406 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 91/100 | Training Loss: 0.405 | Valid Score: 0.811\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 0.813 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 92/100 | Training Loss: 0.406 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 93/100 | Training Loss: 0.410 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 94/100 | Training Loss: 0.404 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 95/100 | Training Loss: 0.405 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 0.814 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 96/100 | Training Loss: 0.404 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 97/100 | Training Loss: 0.408 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 98/100 | Training Loss: 0.406 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 99/100 | Training Loss: 0.403 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 100/100 | Training Loss: 0.400 | Valid Score: 0.815\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 0.815 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.815 \n",
            "\n",
            "Test Score: 0.617 \n",
            "\n",
            "Execution time: 95.197 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##message mul and reduce max"
      ],
      "metadata": {
        "id": "JaSI2JsOTBBs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `forward` method of `SAGEConv8` is similar to the previous SAGEConv layers. It sets the node features in the graph `g`, performs message passing using \"mul\" as the message function, and aggregation using \"max\" as the reduce function. It then retrieves the aggregated neighbor features `h_N` from the graph data, concatenates the original node features `h` with the aggregated neighbor features `h_N`, applies a linear transformation, and returns the result."
      ],
      "metadata": {
        "id": "GR-B7mg24WdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGEConv8(nn.Module):\n",
        "\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv8, self).__init__()\n",
        "\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.update_all(\n",
        "                message_func = fn.u_mul_v('h', 'h', 'm'),\n",
        "                reduce_func=fn.max(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)"
      ],
      "metadata": {
        "id": "jBfOvu8gHnXL"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv8(self.node_feature_size, self.hidden_size)\n",
        "        self.conv2 = SAGEConv8(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n"
      ],
      "metadata": {
        "id": "FdEIsSIIHuXX"
      },
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNi5G8u8Ksjx",
        "outputId": "8cd031f1-9373-45d5-aff7-014d1b12ea76"
      },
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.687 | Valid Score: 0.358\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.358 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 0.666 | Valid Score: 0.322\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.358 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 3/100 | Training Loss: 0.650 | Valid Score: 0.314\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.358 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 4/100 | Training Loss: 0.636 | Valid Score: 0.318\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.358 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 5/100 | Training Loss: 0.622 | Valid Score: 0.325\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.358 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 6/100 | Training Loss: 0.610 | Valid Score: 0.334\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.358 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 7/100 | Training Loss: 0.597 | Valid Score: 0.349\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.358 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.588 | Valid Score: 0.367\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.367 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 9/100 | Training Loss: 0.578 | Valid Score: 0.412\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.412 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.568 | Valid Score: 0.456\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.456 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.559 | Valid Score: 0.501\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.501 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.549 | Valid Score: 0.553\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.553 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.541 | Valid Score: 0.588\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.588 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.529 | Valid Score: 0.608\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.608 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 15/100 | Training Loss: 0.524 | Valid Score: 0.636\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.636 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.517 | Valid Score: 0.671\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.671 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 17/100 | Training Loss: 0.508 | Valid Score: 0.665\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.671 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 18/100 | Training Loss: 0.500 | Valid Score: 0.691\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.691 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.495 | Valid Score: 0.693\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.693 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.491 | Valid Score: 0.703\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.703 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.488 | Valid Score: 0.709\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.709 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.481 | Valid Score: 0.715\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.715 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.477 | Valid Score: 0.721\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.721 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.473 | Valid Score: 0.728\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.728 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 25/100 | Training Loss: 0.471 | Valid Score: 0.735\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.735 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 0.469 | Valid Score: 0.736\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.736 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.462 | Valid Score: 0.741\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.741 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 0.460 | Valid Score: 0.740\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.741 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 29/100 | Training Loss: 0.460 | Valid Score: 0.747\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.747 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 0.456 | Valid Score: 0.750\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.750 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 31/100 | Training Loss: 0.455 | Valid Score: 0.750\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.750 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 0.455 | Valid Score: 0.751\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.751 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 33/100 | Training Loss: 0.447 | Valid Score: 0.753\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.753 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 0.445 | Valid Score: 0.756\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.756 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 35/100 | Training Loss: 0.443 | Valid Score: 0.758\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.758 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 36/100 | Training Loss: 0.443 | Valid Score: 0.758\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.758 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 37/100 | Training Loss: 0.441 | Valid Score: 0.759\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.759 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 38/100 | Training Loss: 0.437 | Valid Score: 0.761\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.761 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.442 | Valid Score: 0.763\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.763 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 40/100 | Training Loss: 0.434 | Valid Score: 0.771\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.771 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 41/100 | Training Loss: 0.435 | Valid Score: 0.768\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.771 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 0.434 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 43/100 | Training Loss: 0.433 | Valid Score: 0.774\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.774 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 44/100 | Training Loss: 0.431 | Valid Score: 0.777\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.777 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 45/100 | Training Loss: 0.429 | Valid Score: 0.777\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.777 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 46/100 | Training Loss: 0.428 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 47/100 | Training Loss: 0.429 | Valid Score: 0.779\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 48/100 | Training Loss: 0.427 | Valid Score: 0.781\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.781 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 49/100 | Training Loss: 0.427 | Valid Score: 0.782\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.782 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 50/100 | Training Loss: 0.422 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 51/100 | Training Loss: 0.423 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 52/100 | Training Loss: 0.423 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.784 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 53/100 | Training Loss: 0.421 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 53/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 54/100 | Training Loss: 0.419 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 54/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 55/100 | Training Loss: 0.420 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 55/100 | Best Valid Score Until Now: 0.786 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 56/100 | Training Loss: 0.418 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 56/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 57/100 | Training Loss: 0.421 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 57/100 | Best Valid Score Until Now: 0.787 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 58/100 | Training Loss: 0.419 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 58/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 59/100 | Training Loss: 0.415 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 59/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 60/100 | Training Loss: 0.420 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 60/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 61/100 | Training Loss: 0.418 | Valid Score: 0.788\n",
            " \n",
            "Epoch: 61/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 62/100 | Training Loss: 0.423 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 62/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 63/100 | Training Loss: 0.414 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 63/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 64/100 | Training Loss: 0.416 | Valid Score: 0.790\n",
            " \n",
            "Epoch: 64/100 | Best Valid Score Until Now: 0.790 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 65/100 | Training Loss: 0.412 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 65/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 66/100 | Training Loss: 0.416 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 66/100 | Best Valid Score Until Now: 0.791 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 67/100 | Training Loss: 0.413 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 67/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 68/100 | Training Loss: 0.416 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 68/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 69/100 | Training Loss: 0.409 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 69/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 70/100 | Training Loss: 0.415 | Valid Score: 0.791\n",
            " \n",
            "Epoch: 70/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 71/100 | Training Loss: 0.412 | Valid Score: 0.793\n",
            " \n",
            "Epoch: 71/100 | Best Valid Score Until Now: 0.793 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 72/100 | Training Loss: 0.409 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 72/100 | Best Valid Score Until Now: 0.794 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 73/100 | Training Loss: 0.408 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 73/100 | Best Valid Score Until Now: 0.795 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 74/100 | Training Loss: 0.409 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 74/100 | Best Valid Score Until Now: 0.795 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 75/100 | Training Loss: 0.414 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 75/100 | Best Valid Score Until Now: 0.795 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 76/100 | Training Loss: 0.410 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 76/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 77/100 | Training Loss: 0.409 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 77/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 78/100 | Training Loss: 0.411 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 78/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 79/100 | Training Loss: 0.413 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 79/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 80/100 | Training Loss: 0.408 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 80/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 81/100 | Training Loss: 0.409 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 81/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 82/100 | Training Loss: 0.408 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 82/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 83/100 | Training Loss: 0.406 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 83/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 84/100 | Training Loss: 0.403 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 84/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 85/100 | Training Loss: 0.410 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 85/100 | Best Valid Score Until Now: 0.797 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 86/100 | Training Loss: 0.405 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 86/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 87/100 | Training Loss: 0.409 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 87/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 88/100 | Training Loss: 0.407 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 88/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 89/100 | Training Loss: 0.404 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 89/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 90/100 | Training Loss: 0.402 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 90/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 91/100 | Training Loss: 0.404 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 91/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 92/100 | Training Loss: 0.405 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 92/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 93/100 | Training Loss: 0.405 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 93/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 94/100 | Training Loss: 0.405 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 94/100 | Best Valid Score Until Now: 0.799 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 95/100 | Training Loss: 0.400 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 95/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 96/100 | Training Loss: 0.401 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 96/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 97/100 | Training Loss: 0.404 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 97/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 98/100 | Training Loss: 0.401 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 98/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 99/100 | Training Loss: 0.399 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 99/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 100/100 | Training Loss: 0.404 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 100/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.800 \n",
            "\n",
            "Test Score: 0.615 \n",
            "\n",
            "Execution time: 96.035 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##add layers"
      ],
      "metadata": {
        "id": "C7KbLLm_S544"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`SAGEConv9`: This class extends the `nn.Module` base class from PyTorch and defines a custom graph convolutional layer using the SAGE (GraphSAGE) algorithm. It takes the input feature size `in_feat` and output feature size `out_feat` as arguments. The `forward` method performs the graph convolution operation using element-wise multiplication as the message function (`fn.u_mul_v`) and sum reduction (`fn.sum`) to aggregate messages from neighboring nodes. The resulting node features are concatenated with the original node features, passed through a linear transformation, and returned.\n",
        "\n",
        "- `GNN`: This class extends the `nn.Module` base class and implements a Graph Neural Network model. It takes a `config` dictionary, `global_size`, and `num_tasks` as arguments. The class defines the architecture of the GNN model, which includes three instances of the `SAGEConv9` layer (`conv1`, `conv2`, `conv3`). It also includes batch normalization layers (`bn1`, `bn2`) between the convolutional layers. The `forward` method performs the forward pass of the model, applying the graph convolutional layers on the input graph `mol_dgl_graph`. It first truncates the node and edge features to the desired sizes, applies the convolutional layers with batch normalization and ReLU activation, and computes the mean of the resulting node features.\n",
        "At first we work with 3 layers and in the next code we work with 4 layers"
      ],
      "metadata": {
        "id": "4rRTfwMhio-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "from dgl.nn import GraphConv\n",
        "import dgl.function as fn\n",
        "from dgl.nn import SAGEConv\n",
        "import time\n",
        "\n",
        "\n",
        "class SAGEConv9(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv9, self).__init__()\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.update_all(\n",
        "                message_func=fn.u_mul_v('h', 'h', 'm'),\n",
        "                reduce_func=fn.sum(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)\n",
        "\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv9(self.node_feature_size, self.hidden_size)\n",
        "        self.bn1 = nn.BatchNorm1d(self.hidden_size)  # Define batch normalization layer bn1\n",
        "        self.conv2 = SAGEConv9(self.hidden_size, self.hidden_size)\n",
        "        self.bn2 = nn.BatchNorm1d(self.hidden_size)  # Define batch normalization layer bn2\n",
        "        self.conv3 = SAGEConv9(self.hidden_size, self.num_tasks)\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = self.bn1(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = self.bn2(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n",
        "\n",
        "config = {}  # Replace with your config\n",
        "gnn = GNN(config, num_tasks=1)  # Set num_tasks to 1 for binary classification\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qyZIzMrECcd",
        "outputId": "2209e096-bc31-4ed1-e4de-3851829a5ee2"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.744 | Valid Score: 0.753\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.753 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 2/100 | Training Loss: 0.649 | Valid Score: 0.722\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.753 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.605 | Valid Score: 0.759\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.759 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 4/100 | Training Loss: 0.586 | Valid Score: 0.737\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.759 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 5/100 | Training Loss: 0.554 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.792 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.525 | Valid Score: 0.835\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.835 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 7/100 | Training Loss: 0.498 | Valid Score: 0.826\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.835 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 8/100 | Training Loss: 0.481 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.835 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 9/100 | Training Loss: 0.457 | Valid Score: 0.814\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.835 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 10/100 | Training Loss: 0.438 | Valid Score: 0.845\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.845 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 11/100 | Training Loss: 0.424 | Valid Score: 0.842\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.845 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 12/100 | Training Loss: 0.412 | Valid Score: 0.856\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.856 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 13/100 | Training Loss: 0.401 | Valid Score: 0.858\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.858 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.396 | Valid Score: 0.862\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.862 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 15/100 | Training Loss: 0.379 | Valid Score: 0.862\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.862 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.377 | Valid Score: 0.867\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.867 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 17/100 | Training Loss: 0.368 | Valid Score: 0.865\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.867 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 18/100 | Training Loss: 0.362 | Valid Score: 0.860\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.867 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 19/100 | Training Loss: 0.362 | Valid Score: 0.865\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.867 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 20/100 | Training Loss: 0.359 | Valid Score: 0.866\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.867 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 21/100 | Training Loss: 0.348 | Valid Score: 0.866\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.867 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 22/100 | Training Loss: 0.337 | Valid Score: 0.860\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.867 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.341 | Valid Score: 0.868\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.868 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 24/100 | Training Loss: 0.338 | Valid Score: 0.864\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.868 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 25/100 | Training Loss: 0.328 | Valid Score: 0.867\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.868 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 26/100 | Training Loss: 0.329 | Valid Score: 0.863\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.868 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 27/100 | Training Loss: 0.329 | Valid Score: 0.863\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.868 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 28/100 | Training Loss: 0.320 | Valid Score: 0.850\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.868 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 29/100 | Training Loss: 0.323 | Valid Score: 0.866\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.868 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 30/100 | Training Loss: 0.312 | Valid Score: 0.846\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.868 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 31/100 | Training Loss: 0.321 | Valid Score: 0.858\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.868 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 32/100 | Training Loss: 0.311 | Valid Score: 0.869\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.869 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 33/100 | Training Loss: 0.310 | Valid Score: 0.866\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.869 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 34/100 | Training Loss: 0.303 | Valid Score: 0.870\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.870 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 35/100 | Training Loss: 0.298 | Valid Score: 0.868\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.870 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 36/100 | Training Loss: 0.298 | Valid Score: 0.868\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.870 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 37/100 | Training Loss: 0.302 | Valid Score: 0.851\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.870 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 38/100 | Training Loss: 0.300 | Valid Score: 0.865\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.870 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 39/100 | Training Loss: 0.302 | Valid Score: 0.869\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.870 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 40/100 | Training Loss: 0.290 | Valid Score: 0.863\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.870 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 41/100 | Training Loss: 0.288 | Valid Score: 0.872\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.872 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 42/100 | Training Loss: 0.288 | Valid Score: 0.879\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.879 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 43/100 | Training Loss: 0.285 | Valid Score: 0.874\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.879 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 44/100 | Training Loss: 0.284 | Valid Score: 0.858\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.879 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 45/100 | Training Loss: 0.286 | Valid Score: 0.875\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.879 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 46/100 | Training Loss: 0.279 | Valid Score: 0.875\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.879 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 47/100 | Training Loss: 0.280 | Valid Score: 0.852\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.879 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 48/100 | Training Loss: 0.274 | Valid Score: 0.870\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.879 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 49/100 | Training Loss: 0.273 | Valid Score: 0.867\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.879 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 50/100 | Training Loss: 0.267 | Valid Score: 0.862\n",
            " \n",
            "Epoch: 50/100 | Best Valid Score Until Now: 0.879 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 51/100 | Training Loss: 0.265 | Valid Score: 0.866\n",
            " \n",
            "Epoch: 51/100 | Best Valid Score Until Now: 0.879 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 52/100 | Training Loss: 0.269 | Valid Score: 0.858\n",
            " \n",
            "Epoch: 52/100 | Best Valid Score Until Now: 0.879 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.879 \n",
            "\n",
            "Test Score: 0.835 \n",
            "\n",
            "Execution time: 56.280 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "from dgl.nn import GraphConv\n",
        "import dgl.function as fn\n",
        "from dgl.nn import SAGEConv\n",
        "import time\n",
        "\n",
        "\n",
        "class SAGEConv9(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv9, self).__init__()\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.update_all(\n",
        "                message_func=fn.u_mul_v('h', 'h', 'm'),\n",
        "                reduce_func=fn.sum(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)\n",
        "\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv9(self.node_feature_size, self.hidden_size)\n",
        "        self.bn1 = nn.BatchNorm1d(self.hidden_size)  # Define batch normalization layer bn1\n",
        "        self.conv2 = SAGEConv9(self.hidden_size, self.hidden_size)\n",
        "        self.bn2 = nn.BatchNorm1d(self.hidden_size)  # Define batch normalization layer bn2\n",
        "        self.conv3 = SAGEConv9(self.hidden_size, self.hidden_size)\n",
        "        self.bn3 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.conv4 = SAGEConv9(self.hidden_size, self.num_tasks)\n",
        "\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = self.bn1(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = self.bn2(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = self.bn3(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n",
        "\n",
        "config = {}  # Replace with your config\n",
        "gnn = GNN(config, num_tasks=1)  # Set num_tasks to 1 for binary classification\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e025152-a81c-468e-ce23-0ddaab60eb26",
        "id": "uWwxc9c8FBrx"
      },
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.737 | Valid Score: 0.443\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.443 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.684 | Valid Score: 0.661\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.661 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.666 | Valid Score: 0.672\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.672 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.673 | Valid Score: 0.683\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.683 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 5/100 | Training Loss: 0.644 | Valid Score: 0.676\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.683 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 6/100 | Training Loss: 0.625 | Valid Score: 0.681\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.683 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 7/100 | Training Loss: 0.593 | Valid Score: 0.686\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.686 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 8/100 | Training Loss: 0.591 | Valid Score: 0.684\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.686 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 9/100 | Training Loss: 0.576 | Valid Score: 0.678\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.686 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 10/100 | Training Loss: 0.584 | Valid Score: 0.678\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.686 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 11/100 | Training Loss: 0.563 | Valid Score: 0.678\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.686 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 12/100 | Training Loss: 0.549 | Valid Score: 0.675\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.686 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 13/100 | Training Loss: 0.542 | Valid Score: 0.676\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.686 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 14/100 | Training Loss: 0.523 | Valid Score: 0.686\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.686 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 15/100 | Training Loss: 0.507 | Valid Score: 0.684\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.686 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.490 | Valid Score: 0.686\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.686 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 17/100 | Training Loss: 0.480 | Valid Score: 0.705\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.705 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 18/100 | Training Loss: 0.469 | Valid Score: 0.697\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.705 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 19/100 | Training Loss: 0.454 | Valid Score: 0.716\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.716 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 20/100 | Training Loss: 0.440 | Valid Score: 0.721\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.721 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 21/100 | Training Loss: 0.429 | Valid Score: 0.730\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.730 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 22/100 | Training Loss: 0.429 | Valid Score: 0.750\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.750 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 23/100 | Training Loss: 0.410 | Valid Score: 0.751\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.751 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 24/100 | Training Loss: 0.397 | Valid Score: 0.754\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.754 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 25/100 | Training Loss: 0.389 | Valid Score: 0.742\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.754 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 26/100 | Training Loss: 0.394 | Valid Score: 0.767\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.767 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 27/100 | Training Loss: 0.394 | Valid Score: 0.795\n",
            " \n",
            "Epoch: 27/100 | Best Valid Score Until Now: 0.795 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 28/100 | Training Loss: 0.391 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 28/100 | Best Valid Score Until Now: 0.795 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 29/100 | Training Loss: 0.371 | Valid Score: 0.775\n",
            " \n",
            "Epoch: 29/100 | Best Valid Score Until Now: 0.795 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 30/100 | Training Loss: 0.360 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 30/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 31/100 | Training Loss: 0.365 | Valid Score: 0.764\n",
            " \n",
            "Epoch: 31/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 32/100 | Training Loss: 0.361 | Valid Score: 0.753\n",
            " \n",
            "Epoch: 32/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 33/100 | Training Loss: 0.348 | Valid Score: 0.773\n",
            " \n",
            "Epoch: 33/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 34/100 | Training Loss: 0.354 | Valid Score: 0.751\n",
            " \n",
            "Epoch: 34/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 35/100 | Training Loss: 0.352 | Valid Score: 0.756\n",
            " \n",
            "Epoch: 35/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 36/100 | Training Loss: 0.349 | Valid Score: 0.796\n",
            " \n",
            "Epoch: 36/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 37/100 | Training Loss: 0.342 | Valid Score: 0.799\n",
            " \n",
            "Epoch: 37/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 38/100 | Training Loss: 0.342 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 38/100 | Best Valid Score Until Now: 0.800 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 39/100 | Training Loss: 0.335 | Valid Score: 0.822\n",
            " \n",
            "Epoch: 39/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 40/100 | Training Loss: 0.329 | Valid Score: 0.786\n",
            " \n",
            "Epoch: 40/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 41/100 | Training Loss: 0.327 | Valid Score: 0.821\n",
            " \n",
            "Epoch: 41/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 42/100 | Training Loss: 0.326 | Valid Score: 0.813\n",
            " \n",
            "Epoch: 42/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 43/100 | Training Loss: 0.316 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 43/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 44/100 | Training Loss: 0.324 | Valid Score: 0.777\n",
            " \n",
            "Epoch: 44/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 45/100 | Training Loss: 0.320 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 45/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 46/100 | Training Loss: 0.311 | Valid Score: 0.809\n",
            " \n",
            "Epoch: 46/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 47/100 | Training Loss: 0.319 | Valid Score: 0.808\n",
            " \n",
            "Epoch: 47/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 48/100 | Training Loss: 0.302 | Valid Score: 0.797\n",
            " \n",
            "Epoch: 48/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 49/100 | Training Loss: 0.305 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 49/100 | Best Valid Score Until Now: 0.822 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.822 \n",
            "\n",
            "Test Score: 0.788 \n",
            "\n",
            "Execution time: 61.389 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the SAGEConv10 class represents a graph convolutional layer that performs message passing using element-wise addition (u_add_v) and aggregation using the maximum operation (max). The resulting features are concatenated with the original node features and transformed by a linear layer to produce the output of the layer."
      ],
      "metadata": {
        "id": "Gok6-9OAjtSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGEConv10(nn.Module):\n",
        "    def __init__(self, in_feat, out_feat):\n",
        "        super(SAGEConv10, self).__init__()\n",
        "        self.linear = nn.Linear(in_feat * 2, out_feat)\n",
        "\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata[\"h\"] = h\n",
        "            g.update_all(\n",
        "                message_func=fn.u_add_v('h', 'h', 'm'),\n",
        "                reduce_func=fn.max(\"m\", \"h_N\"),\n",
        "            )\n",
        "            h_N = g.ndata[\"h_N\"]\n",
        "            h_total = torch.cat([h, h_N], dim=1)\n",
        "            return self.linear(h_total)\n",
        "\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, config, global_size=200, num_tasks=1):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.num_tasks = num_tasks\n",
        "\n",
        "        # Node feature size\n",
        "        self.node_feature_size = self.config.get('node_feature_size', 127)\n",
        "\n",
        "        # Edge feature size\n",
        "        self.edge_feature_size = self.config.get('edge_feature_size', 12)\n",
        "\n",
        "        # Hidden size\n",
        "        self.hidden_size = self.config.get('hidden_size', 100)\n",
        "\n",
        "        self.conv1 = SAGEConv10(self.node_feature_size, self.hidden_size)\n",
        "        self.bn1 = nn.BatchNorm1d(self.hidden_size)  # Define batch normalization layer bn1\n",
        "        self.conv2 = SAGEConv10(self.hidden_size, self.hidden_size)\n",
        "        self.bn2 = nn.BatchNorm1d(self.hidden_size)  # Define batch normalization layer bn2\n",
        "        self.conv3 = SAGEConv10(self.hidden_size, self.hidden_size)\n",
        "        self.bn3 = nn.BatchNorm1d(self.hidden_size)\n",
        "        self.conv4 = SAGEConv10(self.hidden_size, self.num_tasks)\n",
        "\n",
        "\n",
        "    def forward(self, mol_dgl_graph, globals):\n",
        "        mol_dgl_graph.ndata[\"v\"] = mol_dgl_graph.ndata[\"v\"][:, :self.node_feature_size]\n",
        "        mol_dgl_graph.edata[\"e\"] = mol_dgl_graph.edata[\"e\"][:, :self.edge_feature_size]\n",
        "        h = self.conv1(mol_dgl_graph, mol_dgl_graph.ndata[\"v\"])\n",
        "        h = self.bn1(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(mol_dgl_graph, h)\n",
        "        h = self.bn2(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv3(mol_dgl_graph, h)\n",
        "        h = self.bn3(h)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv4(mol_dgl_graph, h)\n",
        "        mol_dgl_graph.ndata[\"h\"] = h\n",
        "        return dgl.mean_nodes(mol_dgl_graph, \"h\")\n",
        "\n",
        "config = {}  # Replace with your config\n",
        "gnn = GNN(config, num_tasks=1)  # Set num_tasks to 1 for binary classification\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "train_evaluate()\n",
        "test_evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a6c0b60-74e0-40fd-d753-f47d819b4b1d",
        "id": "N0z97_RdIgis"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoint\n",
            "Epoch: 1/100 | Training Loss: 0.599 | Valid Score: 0.659\n",
            " \n",
            "Epoch: 1/100 | Best Valid Score Until Now: 0.659 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 2/100 | Training Loss: 0.474 | Valid Score: 0.757\n",
            " \n",
            "Epoch: 2/100 | Best Valid Score Until Now: 0.757 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 3/100 | Training Loss: 0.433 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 3/100 | Best Valid Score Until Now: 0.785 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 4/100 | Training Loss: 0.407 | Valid Score: 0.798\n",
            " \n",
            "Epoch: 4/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 5/100 | Training Loss: 0.379 | Valid Score: 0.783\n",
            " \n",
            "Epoch: 5/100 | Best Valid Score Until Now: 0.798 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 6/100 | Training Loss: 0.367 | Valid Score: 0.803\n",
            " \n",
            "Epoch: 6/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 7/100 | Training Loss: 0.353 | Valid Score: 0.800\n",
            " \n",
            "Epoch: 7/100 | Best Valid Score Until Now: 0.803 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 8/100 | Training Loss: 0.335 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 8/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 9/100 | Training Loss: 0.329 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 9/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 10/100 | Training Loss: 0.321 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 10/100 | Best Valid Score Until Now: 0.804 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 11/100 | Training Loss: 0.314 | Valid Score: 0.812\n",
            " \n",
            "Epoch: 11/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 12/100 | Training Loss: 0.298 | Valid Score: 0.789\n",
            " \n",
            "Epoch: 12/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 13/100 | Training Loss: 0.293 | Valid Score: 0.785\n",
            " \n",
            "Epoch: 13/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 14/100 | Training Loss: 0.283 | Valid Score: 0.792\n",
            " \n",
            "Epoch: 14/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 15/100 | Training Loss: 0.274 | Valid Score: 0.804\n",
            " \n",
            "Epoch: 15/100 | Best Valid Score Until Now: 0.812 \n",
            "\n",
            "Save checkpoint\n",
            "Epoch: 16/100 | Training Loss: 0.271 | Valid Score: 0.818\n",
            " \n",
            "Epoch: 16/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 1\n",
            "Epoch: 17/100 | Training Loss: 0.269 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 17/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 2\n",
            "Epoch: 18/100 | Training Loss: 0.260 | Valid Score: 0.775\n",
            " \n",
            "Epoch: 18/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 3\n",
            "Epoch: 19/100 | Training Loss: 0.250 | Valid Score: 0.802\n",
            " \n",
            "Epoch: 19/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 4\n",
            "Epoch: 20/100 | Training Loss: 0.247 | Valid Score: 0.806\n",
            " \n",
            "Epoch: 20/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 5\n",
            "Epoch: 21/100 | Training Loss: 0.242 | Valid Score: 0.801\n",
            " \n",
            "Epoch: 21/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 6\n",
            "Epoch: 22/100 | Training Loss: 0.241 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 22/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 7\n",
            "Epoch: 23/100 | Training Loss: 0.229 | Valid Score: 0.787\n",
            " \n",
            "Epoch: 23/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 8\n",
            "Epoch: 24/100 | Training Loss: 0.224 | Valid Score: 0.816\n",
            " \n",
            "Epoch: 24/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 9\n",
            "Epoch: 25/100 | Training Loss: 0.222 | Valid Score: 0.794\n",
            " \n",
            "Epoch: 25/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Patience 10\n",
            "Epoch: 26/100 | Training Loss: 0.214 | Valid Score: 0.784\n",
            " \n",
            "Epoch: 26/100 | Best Valid Score Until Now: 0.818 \n",
            "\n",
            "Final results:\n",
            "Average Valid Score: 0.818 \n",
            "\n",
            "Test Score: 0.813 \n",
            "\n",
            "Execution time: 34.850 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}